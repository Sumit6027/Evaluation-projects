{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e164709",
   "metadata": {},
   "source": [
    "# Temperature Forecast Project using ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b9b7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Problem Statement:\n",
    "Data Set Information:\n",
    "\n",
    "This data is for the purpose of bias correction of next-day maximum and minimum air temperatures forecast of the LDAPS model operated by the Korea Meteorological Administration over Seoul, South Korea. This data consists of summer data from 2013 to 2017. The input data is largely composed of the LDAPS model's next-day forecast data, in-situ maximum and minimum temperatures of present-day, and geographic auxiliary variables. There are two outputs (i.e. next-day maximum and minimum air temperatures) in this data. Hindcast validation was conducted for the period from 2015 to 2017\n",
    "\n",
    "Attribute Information:\n",
    "(Local Data Assimilation and Prediction System - (LDAPS) Model)\n",
    "\n",
    "For more information, read [Cho et al, 2020].\n",
    "\n",
    "station - used weather station number: 1 to 25\n",
    "Date - Present day: yyyy-mm-dd ('2013-06-30' to '2017-08-30')\n",
    "Present_Tmax - Maximum air temperature between 0 and 21 h on the present day (Â°C): 20 to 37.6\n",
    "Present_Tmin - Minimum air temperature between 0 and 21 h on the present day (Â°C): 11.3 to 29.9\n",
    "LDAPS_RHmin - LDAPS model forecast of next-day minimum relative humidity (%): 19.8 to 98.5\n",
    "LDAPS_RHmax - LDAPS model forecast of next-day maximum relative humidity (%): 58.9 to 100\n",
    "LDAPS_Tmax_lapse - LDAPS model forecast of next-day maximum air temperature applied lapse rate (Â°C): 17.6 to 38.5\n",
    "LDAPS_Tmin_lapse - LDAPS model forecast of next-day minimum air temperature applied lapse rate (Â°C): 14.3 to 29.6\n",
    "LDAPS_WS - LDAPS model forecast of next-day average wind speed (m/s): 2.9 to 21.9\n",
    "LDAPS_LH - LDAPS model forecast of next-day average latent heat flux (W/m2): -13.6 to 213.4\n",
    "LDAPS_CC1 - LDAPS model forecast of next-day 1st 6-hour split average cloud cover (0-5 h) (%): 0 to 0.97\n",
    "LDAPS_CC2 - LDAPS model forecast of next-day 2nd 6-hour split average cloud cover (6-11 h) (%): 0 to 0.97\n",
    "LDAPS_CC3 - LDAPS model forecast of next-day 3rd 6-hour split average cloud cover (12-17 h) (%): 0 to 0.98\n",
    "LDAPS_CC4 - LDAPS model forecast of next-day 4th 6-hour split average cloud cover (18-23 h) (%): 0 to 0.97\n",
    "LDAPS_PPT1 - LDAPS model forecast of next-day 1st 6-hour split average precipitation (0-5 h) (%): 0 to 23.7\n",
    "LDAPS_PPT2 - LDAPS model forecast of next-day 2nd 6-hour split average precipitation (6-11 h) (%): 0 to 21.6\n",
    "LDAPS_PPT3 - LDAPS model forecast of next-day 3rd 6-hour split average precipitation (12-17 h) (%): 0 to 15.8\n",
    "LDAPS_PPT4 - LDAPS model forecast of next-day 4th 6-hour split average precipitation (18-23 h) (%): 0 to 16.7\n",
    "lat - Latitude (Â°): 37.456 to 37.645\n",
    "lon - Longitude (Â°): 126.826 to 127.135\n",
    "DEM - Elevation (m): 12.4 to 212.3\n",
    "Slope - Slope (Â°): 0.1 to 5.2\n",
    "Solar radiation - Daily incoming solar radiation (wh/m2): 4329.5 to 5992.9\n",
    "Next_Tmax - The next-day maximum air temperature (Â°C): 17.4 to 38.9\n",
    "Next_Tmin - The next-day minimum air temperature (Â°C): 11.3 to 29.8T\n",
    "Please note that there are two target variables here:1) Next_Tmax: Next day maximum temperature\n",
    "Next_Tmin: Next day minimum temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1552298",
   "metadata": {},
   "source": [
    "### Importing require library for performing EDA, Data Wrangling and data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3755cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # for data wrangling purpose\n",
    "import numpy as np # Basic computation library\n",
    "import seaborn as sns # For Visualization \n",
    "import matplotlib.pyplot as plt # ploting package\n",
    "%matplotlib inline\n",
    "import warnings # Filtering warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70436f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Temperature Forecast dataset Csv file using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f96dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('temperature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6505c052",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('No of Rows:',df.shape[0])\n",
    "print('No of Columns:',df.shape[1])\n",
    "pd.set_option('display.max_columns', None) # This will enable us to see truncated columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b91569b",
   "metadata": {},
   "source": [
    "No of Rows: 7752\n",
    "No of Columns: 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e3f82b",
   "metadata": {},
   "source": [
    "\tstation\tDate\tPresent_Tmax\tPresent_Tmin\tLDAPS_RHmin\tLDAPS_RHmax\tLDAPS_Tmax_lapse\tLDAPS_Tmin_lapse\tLDAPS_WS\tLDAPS_LH\tLDAPS_CC1\tLDAPS_CC2\tLDAPS_CC3\tLDAPS_CC4\tLDAPS_PPT1\tLDAPS_PPT2\tLDAPS_PPT3\tLDAPS_PPT4\tlat\tlon\tDEM\tSlope\tSolar radiation\tNext_Tmax\tNext_Tmin\n",
    "0\t1.0\t30-06-2013\t28.7\t21.4\t58.255688\t91.116364\t28.074101\t23.006936\t6.818887\t69.451805\t0.233947\t0.203896\t0.161697\t0.130928\t0.0\t0.0\t0.0\t0.0\t37.6046\t126.991\t212.3350\t2.7850\t5992.895996\t29.1\t21.2\n",
    "1\t2.0\t30-06-2013\t31.9\t21.6\t52.263397\t90.604721\t29.850689\t24.035009\t5.691890\t51.937448\t0.225508\t0.251771\t0.159444\t0.127727\t0.0\t0.0\t0.0\t0.0\t37.6046\t127.032\t44.7624\t0.5141\t5869.312500\t30.5\t22.5\n",
    "2\t3.0\t30-06-2013\t31.6\t23.3\t48.690479\t83.973587\t30.091292\t24.565633\t6.138224\t20.573050\t0.209344\t0.257469\t0.204091\t0.142125\t0.0\t0.0\t0.0\t0.0\t37.5776\t127.058\t33.3068\t0.2661\t5863.555664\t31.1\t23.9\n",
    "3\t4.0\t30-06-2013\t32.0\t23.4\t58.239788\t96.483688\t29.704629\t23.326177\t5.650050\t65.727144\t0.216372\t0.226002\t0.161157\t0.134249\t0.0\t0.0\t0.0\t0.0\t37.6450\t127.022\t45.7160\t2.5348\t5856.964844\t31.7\t24.3\n",
    "4\t5.0\t30-06-2013\t31.4\t21.9\t56.174095\t90.155128\t29.113934\t23.486480\t5.735004\t107.965535\t0.151407\t0.249995\t0.178892\t0.170021\t0.0\t0.0\t0.0\t0.0\t37.5507\t127.135\t35.0380\t0.5055\t5859.552246\t31.2\t22.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d1964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort columns by datatypes\n",
    "df.columns.to_series().groupby(df.dtypes).groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620ebd30",
   "metadata": {},
   "source": [
    "{float64: ['station', 'Present_Tmax', 'Present_Tmin', 'LDAPS_RHmin', 'LDAPS_RHmax', 'LDAPS_Tmax_lapse', 'LDAPS_Tmin_lapse', 'LDAPS_WS', 'LDAPS_LH', 'LDAPS_CC1', 'LDAPS_CC2', 'LDAPS_CC3', 'LDAPS_CC4', 'LDAPS_PPT1', 'LDAPS_PPT2', 'LDAPS_PPT3', 'LDAPS_PPT4', 'lat', 'lon', 'DEM', 'Slope', 'Solar radiation', 'Next_Tmax', 'Next_Tmin'], object: ['Date']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf84fb20",
   "metadata": {},
   "source": [
    "Comment :\n",
    "All variable are Numerical in nature.\n",
    "Next_Tmax and Next_Tmin are Target Variable.\n",
    "This dataset contain 7752 Rows and 25 Columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb72ee96",
   "metadata": {},
   "source": [
    "## Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14483227",
   "metadata": {},
   "source": [
    "###  Since dataset is large, Let check for any entry which is repeated or duplicated in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa22c743",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum() # This will check if any duplicate entry or duplicate row with same value exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4e60b2",
   "metadata": {},
   "source": [
    "0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263ba55c",
   "metadata": {},
   "source": [
    "### Let check if any whitespace, 'NA' or '-' exist in dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c464783",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isin([' ','NA','-']).sum().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b556771f",
   "metadata": {},
   "source": [
    "False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd63b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "Comment:\n",
    "No Duplicate entry in dataset.\n",
    "No whitespace, NA, '-' exist in dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af98258d",
   "metadata": {},
   "source": [
    "## Missing value check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3c7bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding what percentage of data is missing from the dataset\n",
    "missing_values = df.isnull().sum().sort_values(ascending = False)\n",
    "percentage_missing_values =(missing_values/len(df))*100\n",
    "print(pd.concat([missing_values, percentage_missing_values], axis =1, keys =['Missing Values', '% Missing data']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb14224",
   "metadata": {},
   "source": [
    " Missing Values  % Missing data\n",
    "LDAPS_CC3                     75        0.967492\n",
    "LDAPS_WS                      75        0.967492\n",
    "LDAPS_RHmin                   75        0.967492\n",
    "LDAPS_RHmax                   75        0.967492\n",
    "LDAPS_Tmax_lapse              75        0.967492\n",
    "LDAPS_PPT4                    75        0.967492\n",
    "LDAPS_PPT3                    75        0.967492\n",
    "LDAPS_PPT2                    75        0.967492\n",
    "LDAPS_PPT1                    75        0.967492\n",
    "LDAPS_CC4                     75        0.967492\n",
    "LDAPS_Tmin_lapse              75        0.967492\n",
    "LDAPS_CC2                     75        0.967492\n",
    "LDAPS_CC1                     75        0.967492\n",
    "LDAPS_LH                      75        0.967492\n",
    "Present_Tmax                  70        0.902993\n",
    "Present_Tmin                  70        0.902993\n",
    "Next_Tmin                     27        0.348297\n",
    "Next_Tmax                     27        0.348297\n",
    "Date                           2        0.025800\n",
    "station                        2        0.025800\n",
    "lat                            0        0.000000\n",
    "lon                            0        0.000000\n",
    "DEM                            0        0.000000\n",
    "Slope                          0        0.000000\n",
    "Solar radiation                0        0.000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677caca6",
   "metadata": {},
   "source": [
    "### As missing values present are less than 1%. So We can directly drop these missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fe2bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We had {} Rows and {} Columns before dropping null values.\".format(df.shape[0], df.shape[1]))\n",
    "df.dropna(inplace=True)\n",
    "print(\"We have {} Rows and {} Columns after dropping null values.\".format(df.shape[0], df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e914dd86",
   "metadata": {},
   "source": [
    "We had 7752 Rows and 25 Columns before dropping null values.\n",
    "We have 7588 Rows and 25 Columns after dropping null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67c5c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "Comment :\n",
    "Finally, No Missing Value is Present.\n",
    "\n",
    "We are Now Yes To Go Further !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66095dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Date datatypes and spliting date into date, month and year.\n",
    "df['Date']=pd.to_datetime(df['Date'])\n",
    "df['Day']=df['Date'].apply(lambda x:x.day)\n",
    "df['Month']=df['Date'].apply(lambda x:x.month)\n",
    "df['Year']=df['Date'].apply(lambda x:x.year)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38959cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "station\tDate\tPresent_Tmax\tPresent_Tmin\tLDAPS_RHmin\tLDAPS_RHmax\tLDAPS_Tmax_lapse\tLDAPS_Tmin_lapse\tLDAPS_WS\tLDAPS_LH\tLDAPS_CC1\tLDAPS_CC2\tLDAPS_CC3\tLDAPS_CC4\tLDAPS_PPT1\tLDAPS_PPT2\tLDAPS_PPT3\tLDAPS_PPT4\tlat\tlon\tDEM\tSlope\tSolar radiation\tNext_Tmax\tNext_Tmin\tDay\tMonth\tYear\n",
    "0\t1.0\t2013-06-30\t28.7\t21.4\t58.255688\t91.116364\t28.074101\t23.006936\t6.818887\t69.451805\t0.233947\t0.203896\t0.161697\t0.130928\t0.0\t0.0\t0.0\t0.0\t37.6046\t126.991\t212.3350\t2.7850\t5992.895996\t29.1\t21.2\t30\t6\t2013\n",
    "1\t2.0\t2013-06-30\t31.9\t21.6\t52.263397\t90.604721\t29.850689\t24.035009\t5.691890\t51.937448\t0.225508\t0.251771\t0.159444\t0.127727\t0.0\t0.0\t0.0\t0.0\t37.6046\t127.032\t44.7624\t0.5141\t5869.312500\t30.5\t22.5\t30\t6\t2013\n",
    "2\t3.0\t2013-06-30\t31.6\t23.3\t48.690479\t83.973587\t30.091292\t24.565633\t6.138224\t20.573050\t0.209344\t0.257469\t0.204091\t0.142125\t0.0\t0.0\t0.0\t0.0\t37.5776\t127.058\t33.3068\t0.2661\t5863.555664\t31.1\t23.9\t30\t6\t2013\n",
    "3\t4.0\t2013-06-30\t32.0\t23.4\t58.239788\t96.483688\t29.704629\t23.326177\t5.650050\t65.727144\t0.216372\t0.226002\t0.161157\t0.134249\t0.0\t0.0\t0.0\t0.0\t37.6450\t127.022\t45.7160\t2.5348\t5856.964844\t31.7\t24.3\t30\t6\t2013\n",
    "4\t5.0\t2013-06-30\t31.4\t21.9\t56.174095\t90.155128\t29.113934\t23.486480\t5.735004\t107.965535\t0.151407\t0.249995\t0.178892\t0.170021\t0.0\t0.0\t0.0\t0.0\t37.5507\t127.135\t35.0380\t0.5055\t5859.552246\t31.2\t22.5\t30\t6\t2013\n",
    "Now to gain more insight in data, we will create additional columns with location of station in terms of city and respective state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739e6a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Reverse geocoder\n",
    "import reverse_geocoder as rg\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b2c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodata=[]\n",
    "def reverse_geocoordinates(coordinates):\n",
    "    result = rg.search(coordinates)\n",
    "    return (result)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    coordinates = list(zip(df['lat'], df['lon']))\n",
    "    data = reverse_geocoordinates(coordinates)\n",
    "    geodata.append(data)\n",
    "# Creating dataframe for geographical name\n",
    "geo_names = pd.DataFrame(geodata).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2538d068",
   "metadata": {},
   "source": [
    "###  We have gather state and city name as per corresponding to it's latitude and longitude available. Now it is time incorporate state and city columns in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdcc5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['State']= geo_names[0].apply(lambda x:x.get('admin1'))\n",
    "df['City']=geo_names[0].apply(lambda x:x.get('name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798b92f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2440b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\tstation\tDate\tPresent_Tmax\tPresent_Tmin\tLDAPS_RHmin\tLDAPS_RHmax\tLDAPS_Tmax_lapse\tLDAPS_Tmin_lapse\tLDAPS_WS\tLDAPS_LH\tLDAPS_CC1\tLDAPS_CC2\tLDAPS_CC3\tLDAPS_CC4\tLDAPS_PPT1\tLDAPS_PPT2\tLDAPS_PPT3\tLDAPS_PPT4\tlat\tlon\tDEM\tSlope\tSolar radiation\tNext_Tmax\tNext_Tmin\tDay\tMonth\tYear\tState\tCity\n",
    "0\t1.0\t2013-06-30\t28.7\t21.4\t58.255688\t91.116364\t28.074101\t23.006936\t6.818887\t69.451805\t0.233947\t0.203896\t0.161697\t0.130928\t0.0\t0.0\t0.0\t0.0\t37.6046\t126.991\t212.3350\t2.7850\t5992.895996\t29.1\t21.2\t30\t6\t2013\tSeoul\tSeoul\n",
    "1\t2.0\t2013-06-30\t31.9\t21.6\t52.263397\t90.604721\t29.850689\t24.035009\t5.691890\t51.937448\t0.225508\t0.251771\t0.159444\t0.127727\t0.0\t0.0\t0.0\t0.0\t37.6046\t127.032\t44.7624\t0.5141\t5869.312500\t30.5\t22.5\t30\t6\t2013\tSeoul\tSeoul\n",
    "2\t3.0\t2013-06-30\t31.6\t23.3\t48.690479\t83.973587\t30.091292\t24.565633\t6.138224\t20.573050\t0.209344\t0.257469\t0.204091\t0.142125\t0.0\t0.0\t0.0\t0.0\t37.5776\t127.058\t33.3068\t0.2661\t5863.555664\t31.1\t23.9\t30\t6\t2013\tSeoul\tSeoul\n",
    "3\t4.0\t2013-06-30\t32.0\t23.4\t58.239788\t96.483688\t29.704629\t23.326177\t5.650050\t65.727144\t0.216372\t0.226002\t0.161157\t0.134249\t0.0\t0.0\t0.0\t0.0\t37.6450\t127.022\t45.7160\t2.5348\t5856.964844\t31.7\t24.3\t30\t6\t2013\tSeoul\tSeoul\n",
    "4\t5.0\t2013-06-30\t31.4\t21.9\t56.174095\t90.155128\t29.113934\t23.486480\t5.735004\t107.965535\t0.151407\t0.249995\t0.178892\t0.170021\t0.0\t0.0\t0.0\t0.0\t37.5507\t127.135\t35.0380\t0.5055\t5859.552246\t31.2\t22.5\t30\t6\t2013\tGyeonggi-do\tGuri-si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343c72c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51505511",
   "metadata": {},
   "outputs": [],
   "source": [
    "station\tPresent_Tmax\tPresent_Tmin\tLDAPS_RHmin\tLDAPS_RHmax\tLDAPS_Tmax_lapse\tLDAPS_Tmin_lapse\tLDAPS_WS\tLDAPS_LH\tLDAPS_CC1\tLDAPS_CC2\tLDAPS_CC3\tLDAPS_CC4\tLDAPS_PPT1\tLDAPS_PPT2\tLDAPS_PPT3\tLDAPS_PPT4\tlat\tlon\tDEM\tSlope\tSolar radiation\tNext_Tmax\tNext_Tmin\tDay\tMonth\tYear\n",
    "count\t7588.000000\t7588.000000\t7588.000000\t7588.000000\t7588.000000\t7588.000000\t7588.000000\t7588.000000\t7588.000000\t7588.000000\t7588.000000\t7588.000000\t7588.000000\t7588.000000\t7588.000000\t7588.000000\t7588.000000\t7588.000000\t7588.00000\t7588.000000\t7588.000000\t7588.000000\t7588.000000\t7588.000000\t7588.000000\t7588.000000\t7588.000000\n",
    "mean\t13.014101\t29.748366\t23.195809\t56.724969\t88.360823\t29.620128\t23.511786\t7.094097\t62.492606\t0.368510\t0.355528\t0.317546\t0.298268\t0.589008\t0.480738\t0.275007\t0.265373\t37.544792\t126.99142\t61.918136\t1.259755\t5343.724208\t30.241526\t22.910820\t16.337375\t7.068134\t2014.991697\n",
    "std\t7.217858\t2.967401\t2.400880\t14.626559\t7.199456\t2.943496\t2.342579\t2.177034\t33.686158\t0.262260\t0.257922\t0.249833\t0.253392\t1.927577\t1.743327\t1.146087\t1.179661\t0.050428\t0.07922\t54.323529\t1.372748\t429.782561\t3.111807\t2.482256\t8.216880\t2.242389\t1.410877\n",
    "min\t1.000000\t20.000000\t11.300000\t19.794666\t58.936283\t17.624954\t14.272646\t2.882580\t-13.603212\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t37.456200\t126.82600\t12.370000\t0.098500\t4329.520508\t17.400000\t11.300000\t7.000000\t1.000000\t2013.000000\n",
    "25%\t7.000000\t27.800000\t21.600000\t45.960243\t84.203724\t27.673756\t22.086820\t5.675358\t37.206201\t0.146546\t0.140324\t0.100950\t0.081495\t0.000000\t0.000000\t0.000000\t0.000000\t37.510200\t126.93700\t28.700000\t0.271300\t5001.485717\t28.200000\t21.300000\t8.000000\t7.000000\t2014.000000\n",
    "50%\t13.000000\t29.900000\t23.400000\t55.023199\t89.784122\t29.709537\t23.758249\t6.547838\t56.898324\t0.315706\t0.311676\t0.261795\t0.227459\t0.000000\t0.000000\t0.000000\t0.000000\t37.550700\t126.99500\t45.716000\t0.618000\t5441.987305\t30.400000\t23.100000\t16.000000\t7.000000\t2015.000000\n",
    "75%\t19.000000\t32.000000\t24.800000\t67.115099\t93.742725\t31.711109\t25.155660\t8.028960\t84.235666\t0.574174\t0.557164\t0.496444\t0.498127\t0.052594\t0.017735\t0.007855\t0.000017\t37.577600\t127.04200\t59.832400\t1.767800\t5729.485840\t32.600000\t24.600000\t24.000000\t8.000000\t2016.000000\n",
    "max\t25.000000\t37.600000\t29.900000\t98.524734\t100.000153\t38.542255\t29.619342\t21.857621\t213.414006\t0.967277\t0.968353\t0.983789\t0.974710\t23.701544\t21.621661\t15.841235\t16.655469\t37.645000\t127.13500\t212.335000\t5.178200\t5992.895996\t38.900000\t29.800000\t31.000000\t12.000000\t2017.000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23714698",
   "metadata": {},
   "source": [
    "## Start Exploring Present Temperature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedec0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting histogram for present_Tmax and present_Tmin variables\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.histplot(df['Present_Tmax'],kde=True,color='r')\n",
    "plt.subplot(1,2,2)\n",
    "sns.histplot(df['Present_Tmin'],kde=True,color='m')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2864c6",
   "metadata": {},
   "source": [
    "Comment:\n",
    "For majority of reading Present Temperature Maximum varies in between 27.5 to 32.5 degree.\n",
    "For majority of reading Present Temperature Minimum varies in between 22.5 to 26 degree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85cb0b6",
   "metadata": {},
   "source": [
    "## Lets find out maximum and minimum Temperature over period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf4831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Present Maximum Temperature Maxima in year 2013-2016 :',df.Present_Tmax.max())\n",
    "print('Present Maximum Temperature Minima in year 2013-2016 :',df.Present_Tmax.min())\n",
    "print(' Average Present Maximum Temperature in year 2013-2016 :',df.Present_Tmax.mean())\n",
    "print('='*100)\n",
    "print('Present Minimum Temperature Maxima in year 2013-2016 :',df.Present_Tmin.max())\n",
    "print('Present Minimum Temperature Minima in year 2013-2016 :',df.Present_Tmin.min())\n",
    "print('Average Present Minimum Temperature in year 2013-2016 :',df.Present_Tmin.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67239fe0",
   "metadata": {},
   "source": [
    "Present Maximum Temperature Maxima in year 2013-2016 : 37.6\n",
    "Present Maximum Temperature Minima in year 2013-2016 : 20.0\n",
    " Average Present Maximum Temperature in year 2013-2016 : 29.748365840801227\n",
    "====================================================================================================\n",
    "Present Minimum Temperature Maxima in year 2013-2016 : 29.9\n",
    "Present Minimum Temperature Minima in year 2013-2016 : 11.3\n",
    "Average Present Minimum Temperature in year 2013-2016 : 23.195809172377487\n",
    "Checking where actually these minima and maxima occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd1766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df.loc[df.Present_Tmax==df.Present_Tmax.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c26bbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\tstation\tDate\tPresent_Tmax\tPresent_Tmin\tLDAPS_RHmin\tLDAPS_RHmax\tLDAPS_Tmax_lapse\tLDAPS_Tmin_lapse\tLDAPS_WS\tLDAPS_LH\tLDAPS_CC1\tLDAPS_CC2\tLDAPS_CC3\tLDAPS_CC4\tLDAPS_PPT1\tLDAPS_PPT2\tLDAPS_PPT3\tLDAPS_PPT4\tlat\tlon\tDEM\tSlope\tSolar radiation\tNext_Tmax\tNext_Tmin\tDay\tMonth\tYear\tState\tCity\n",
    "5717\t18.0\t2016-11-08\t37.6\t26.8\t44.254253\t87.745514\t34.794021\t27.150764\t6.366598\t111.225118\t0.218892\t0.094288\t0.004283\t0.000343\t0.0\t0.0\t0.0\t0.0\t37.4832\t127.024\t56.4448\t1.2313\t5082.563477\t37.0\t27.8\t8\t11\t2016\tGyeonggi-do\tBucheon-si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bbf4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.Present_Tmax==df.Present_Tmax.min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c7f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "station\tDate\tPresent_Tmax\tPresent_Tmin\tLDAPS_RHmin\tLDAPS_RHmax\tLDAPS_Tmax_lapse\tLDAPS_Tmin_lapse\tLDAPS_WS\tLDAPS_LH\tLDAPS_CC1\tLDAPS_CC2\tLDAPS_CC3\tLDAPS_CC4\tLDAPS_PPT1\tLDAPS_PPT2\tLDAPS_PPT3\tLDAPS_PPT4\tlat\tlon\tDEM\tSlope\tSolar radiation\tNext_Tmax\tNext_Tmin\tDay\tMonth\tYear\tState\tCity\n",
    "7725\t1.0\t2017-08-30\t20.0\t15.1\t35.652172\t89.97319\t24.323737\t16.128899\t7.087329\t108.981108\t0.046182\t0.014955\t0.0\t0.00063\t0.0\t0.0\t0.0\t0.0\t37.6046\t126.991\t212.335\t2.785\t4614.76123\t23.8\t15.1\t30\t8\t2017\tNaN\tNaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58bf3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.Present_Tmin==df.Present_Tmin.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a132cec",
   "metadata": {},
   "source": [
    "station\tDate\tPresent_Tmax\tPresent_Tmin\tLDAPS_RHmin\tLDAPS_RHmax\tLDAPS_Tmax_lapse\tLDAPS_Tmin_lapse\tLDAPS_WS\tLDAPS_LH\tLDAPS_CC1\tLDAPS_CC2\tLDAPS_CC3\tLDAPS_CC4\tLDAPS_PPT1\tLDAPS_PPT2\tLDAPS_PPT3\tLDAPS_PPT4\tlat\tlon\tDEM\tSlope\tSolar radiation\tNext_Tmax\tNext_Tmin\tDay\tMonth\tYear\tState\tCity\n",
    "2397\t23.0\t2014-02-08\t35.3\t29.9\t53.946949\t85.985161\t30.912804\t25.439537\t13.011129\t117.837212\t0.684685\t0.448827\t0.762858\t0.635728\t1.670126\t0.005681\t0.248885\t0.003176\t37.5372\t126.891\t15.5876\t0.1554\t5360.226563\t31.3\t24.8\t8\t2\t2014\tGyeonggi-do\tGuri-si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdfbe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.Present_Tmin==df.Present_Tmin.min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af46c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "station\tDate\tPresent_Tmax\tPresent_Tmin\tLDAPS_RHmin\tLDAPS_RHmax\tLDAPS_Tmax_lapse\tLDAPS_Tmin_lapse\tLDAPS_WS\tLDAPS_LH\tLDAPS_CC1\tLDAPS_CC2\tLDAPS_CC3\tLDAPS_CC4\tLDAPS_PPT1\tLDAPS_PPT2\tLDAPS_PPT3\tLDAPS_PPT4\tlat\tlon\tDEM\tSlope\tSolar radiation\tNext_Tmax\tNext_Tmin\tDay\tMonth\tYear\tState\tCity\n",
    "6116\t17.0\t2016-08-27\t27.1\t11.3\t62.793823\t91.726936\t23.529546\t17.963487\t7.984566\t84.48145\t0.668264\t0.410536\t0.452879\t0.627238\t0.181458\t0.0\t0.405181\t1.015573\t37.6181\t127.099\t53.4712\t0.697\t4539.616699\t24.6\t17.1\t27\t8\t2016\tSeoul\tSeoul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3698e8",
   "metadata": {},
   "source": [
    "Observation:\n",
    "Present Maximum Temperature Maxima over four year span recorded at station 18 on 2016-11-08 with Temp of 37.6 degree. Station 18 Located at Bucheon-si city of Gyeonggido state.\n",
    "Present Maximum Temperature Minima over four year span recorded at station 1 on 2017-08-30 with Temp of 20 degree.\n",
    "Present Maximum Temperature Maxima over four year span recorded at station 23 on 2014-02-08 with Temp of 29.9 degree. The station 23 is located in Gurisi of Gyeonggido state\n",
    "Present Maximum Temperature Minima over four year span recorded at station 17 on 2016-08-27 with Temp of 11.3 degree. The station 17 is located in seoul city.\n",
    "We get high value of solar radiation of high temperature day and Low radiation values at low temperature day.\n",
    "Maximum Humidity occur when global temeperature minima occur. This might implies that humidity and temperature are inversely related.We will try to verify this.\n",
    "Solar radiation has naturally going to have effect on wind speed,precipitation and humidity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b56f728",
   "metadata": {},
   "source": [
    "### Let Visualise & gain insight over this by plotting line plot over all station.\n",
    "Line Plot of Present Temperature Maximum over each Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fcac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.set_style('whitegrid')\n",
    "sns.pointplot(x='station', y='Present_Tmax', data=df, hue='Year',join=False)\n",
    "plt.title('Present Maximum Temperature Per Year for each Station', fontsize=22, fontweight='bold')\n",
    "plt.xlabel('Station ID',{'fontsize':15,'fontweight' :'bold'})\n",
    "plt.ylabel('Present Maximum Temperature',{'fontsize':15,'fontweight' :'bold'})\n",
    "plt.xticks(fontsize=16,fontweight ='bold')\n",
    "plt.yticks(fontsize=16,fontweight ='bold')\n",
    "plt.legend(fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96d4ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "<matplotlib.legend.Legend at 0x17cae7cc9a0>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae8e705",
   "metadata": {},
   "source": [
    "Observation on line plot of Present Maximum Temperature:\n",
    "Over all four year higher temperature recorded at station 18 in compare to rest.\n",
    "Station 1 is coolest station over all timeframe.\n",
    "We can see 2016 is hottest year and 2014 is coolest year. It will be interesting to explore these two year independently.\n",
    "Year 2017 is much cooler compare to Year 2016. Precious relife to people in 2017 !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d18d91b",
   "metadata": {},
   "source": [
    "### Line Plot of Present Temperature Minimum over each Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9c7353",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.set_style('whitegrid')\n",
    "sns.pointplot(x='station', y='Present_Tmin', data=df, hue='Year',join=False)\n",
    "plt.title('Present Minimum Temperature Per Year for each Station', fontsize=22, fontweight='bold')\n",
    "plt.xlabel('Station ID',{'fontsize':15,'fontweight' :'bold'})\n",
    "plt.ylabel('Present Minimum Temperature',{'fontsize':15,'fontweight' :'bold'})\n",
    "plt.xticks(fontsize=16,fontweight ='bold')\n",
    "plt.yticks(fontsize=16,fontweight ='bold')\n",
    "plt.legend(fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228d850e",
   "metadata": {},
   "source": [
    "<matplotlib.legend.Legend at 0x17cb0d37b80>\n",
    "\n",
    "Observation on line plot of Present Minimum Temperature:\n",
    "Year 2014 is coolest year of all time frame.\n",
    "Highest Present Minimum Temperature recorded at Station 24 inspite of Not having Highest Present Maximum Temperature. This is implies that over day period minimum temperature drop recorded at station 24.\n",
    "Station 1 is coolest station of all time followed by station 17. Must be tourist spot in Summer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f397a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=df['Month'], y=df['Solar radiation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e27cc0",
   "metadata": {},
   "source": [
    "<AxesSubplot:xlabel='Month', ylabel='Solar radiation'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98685eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x=df['Next_Tmax'], y=df['Solar radiation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3bcddd",
   "metadata": {},
   "source": [
    "## Exploration of Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7944b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting histogram for target variables\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.histplot(df['Next_Tmax'],kde=True,color='b')\n",
    "plt.subplot(1,2,2)\n",
    "sns.histplot(df['Next_Tmin'],kde=True,color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49015d1a",
   "metadata": {},
   "source": [
    "Comment:\n",
    "We get same result as we get in case of present temperature.\n",
    "\n",
    "For majority of reading Next Temperature Maximum varies in between 27.5 to 32.5 degree.\n",
    "For majority of reading Next Temperature Minimum varies in between 22.5 to 26 degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c1a3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the realtion between station and target variables\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.subplot(2,1,1)\n",
    "sns.boxplot(df['station'],df['Next_Tmax'],data=df,palette=\"bright\")\n",
    "plt.title('Next Maximum Temperature for each Station', fontsize=22, fontweight='bold')\n",
    "plt.subplot(2,1,2)\n",
    "sns.boxplot(df['station'],df['Next_Tmin'],data=df,palette=\"bright\")\n",
    "plt.title('Next Minimum Temperature for each Station', fontsize=22, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e229cc",
   "metadata": {},
   "source": [
    "Observation :\n",
    "From the box plot\n",
    "\n",
    "we can notice the station 18 has highest temperature collection for both Next_Tmax and Next_Tmin targets.\n",
    "Maximum temperature difference at same station occur in station 17."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3869cb19",
   "metadata": {},
   "source": [
    "## Next Maximum Temperature Vs Cloud cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99c4733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing Next day maximnum temperature and next day average cloud cover\n",
    "\n",
    "plt.figure(figsize=(18,16))\n",
    "plt.suptitle('Next_Tmax Vs Next-day average cloud cover',fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('Next day max Temperature Vs Next-day 1st 6-hour cloud cover',fontsize=14, fontweight='bold')\n",
    "sns.scatterplot(x='LDAPS_CC1',y='Next_Tmax',data=df,color=\"blue\")\n",
    "plt.xticks(fontsize=12,fontweight ='bold')\n",
    "plt.yticks(fontsize=12,fontweight ='bold')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('Next day max Temperature Vs next-day 2nd 6-hour cloud cover',fontsize=14, fontweight='bold')\n",
    "sns.scatterplot(x='LDAPS_CC2',y='Next_Tmax',data=df,color='purple')\n",
    "plt.xticks(fontsize=12,fontweight ='bold')\n",
    "plt.yticks(fontsize=12,fontweight ='bold')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title('Next day max Temperature Vs next-day 3rd 6-hour cloud cover',fontsize=14, fontweight='bold')\n",
    "sns.scatterplot(x='LDAPS_CC3',y='Next_Tmax',data=df,color='green')\n",
    "plt.xticks(fontsize=12,fontweight ='bold')\n",
    "plt.yticks(fontsize=12,fontweight ='bold')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.title('Next day max Temperature Vs next_day 4th 6-hour cloud cover',fontsize=14, fontweight='bold')\n",
    "sns.scatterplot(x='LDAPS_CC4',y='Next_Tmax',data=df,color=\"red\")\n",
    "plt.xticks(fontsize=12,fontweight ='bold')\n",
    "plt.yticks(fontsize=12,fontweight ='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97486045",
   "metadata": {},
   "outputs": [],
   "source": [
    "Observation:\n",
    "Irrespective of 6 hr quarter in 24 hr day time, Next-day Temperature Maximum decreases as cloud cover increases beyond 0.6.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9849e0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing Next day minimum temperature and next day average cloud cover\n",
    "\n",
    "plt.figure(figsize=(18,16))\n",
    "plt.suptitle('Next_Tmin Vs Next-day average cloud cover',fontsize=20, fontweight='bold')\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('Next day min Temperature Vs Next-day 1st 6-hour cloud cover',fontsize=14, fontweight='bold')\n",
    "sns.scatterplot(x='LDAPS_CC1',y='Next_Tmin',data=df,color=\"g\")\n",
    "plt.xticks(fontsize=12,fontweight ='bold')\n",
    "plt.yticks(fontsize=12,fontweight ='bold')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('Next day min Temperature Vs next-day 2nd 6-hour cloud cover',fontsize=14, fontweight='bold')\n",
    "sns.scatterplot(x='LDAPS_CC2',y='Next_Tmin',data=df,color='b')\n",
    "plt.xticks(fontsize=12,fontweight ='bold')\n",
    "plt.yticks(fontsize=12,fontweight ='bold')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title('Next day min Temperature Vs next-day 3rd 6-hour cloud cover',fontsize=14, fontweight='bold')\n",
    "sns.scatterplot(x='LDAPS_CC3',y='Next_Tmin',data=df,color='violet')\n",
    "plt.xticks(fontsize=12,fontweight ='bold')\n",
    "plt.yticks(fontsize=12,fontweight ='bold')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.title('Next day min Temperature Vs next_day 4th 6-hour cloud cover',fontsize=14, fontweight='bold')\n",
    "sns.scatterplot(x='LDAPS_CC4',y='Next_Tmin',data=df,color=\"r\")\n",
    "plt.xticks(fontsize=12,fontweight ='bold')\n",
    "plt.yticks(fontsize=12,fontweight ='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c227eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Observation:\n",
    "No significant relation between Next_Tmin and cloud cover in scatterplot.\n",
    "\n",
    "We can say that Next_Tmin remains unaffected by cloud cover.\n",
    "\n",
    "Solar radiation might most impact on Cloud cover and precipitation, its time to explore them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818c0c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing Next day minimum temperature and next day average cloud cover\n",
    "\n",
    "plt.figure(figsize=(18,16))\n",
    "plt.suptitle('Solar Radiation Vs Next-day average cloud cover',fontsize=20, fontweight='bold')\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('Solar radiation Vs Next-day 1st 6-hour cloud cover',fontsize=14, fontweight='bold')\n",
    "sns.scatterplot(x='LDAPS_CC1',y='Solar radiation',data=df,color=\"g\")\n",
    "plt.xticks(fontsize=12,fontweight ='bold')\n",
    "plt.yticks(fontsize=12,fontweight ='bold')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('Solar radiation Vs next-day 2nd 6-hour cloud cover',fontsize=14, fontweight='bold')\n",
    "sns.scatterplot(x='LDAPS_CC2',y='Solar radiation',data=df,color='b')\n",
    "plt.xticks(fontsize=12,fontweight ='bold')\n",
    "plt.yticks(fontsize=12,fontweight ='bold')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title('Solar radiation Vs next-day 3rd 6-hour cloud cover',fontsize=14, fontweight='bold')\n",
    "sns.scatterplot(x='LDAPS_CC3',y='Solar radiation',data=df,color='violet')\n",
    "plt.xticks(fontsize=12,fontweight ='bold')\n",
    "plt.yticks(fontsize=12,fontweight ='bold')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.title('Solar radiation Vs next_day 4th 6-hour cloud cover',fontsize=14, fontweight='bold')\n",
    "sns.scatterplot(x='LDAPS_CC4',y='Solar radiation',data=df,color=\"r\")\n",
    "plt.xticks(fontsize=12,fontweight ='bold')\n",
    "plt.yticks(fontsize=12,fontweight ='bold')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286204ec",
   "metadata": {},
   "source": [
    "Observation:\n",
    "We can definitely say that for cloud cover greater than 0.7 high value solar radiation contributed most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eb39f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Precipitation VS Solar radiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f016adda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing Next day minimum temperature and next day average cloud cover\n",
    "\n",
    "plt.figure(figsize=(18,16))\n",
    "plt.suptitle('Solar Radiation Vs Next-day Precipitation',fontsize=20, fontweight='bold')\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('Solar radiation Vs Next-day 1st 6-hour Precipitation',fontsize=14, fontweight='bold')\n",
    "sns.scatterplot(y='LDAPS_PPT1',x='Solar radiation',data=df,color=\"grey\")\n",
    "plt.xticks(fontsize=12,fontweight ='bold')\n",
    "plt.yticks(fontsize=12,fontweight ='bold')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('Solar radiation Vs next-day 2nd 6-hour Precipitation',fontsize=14, fontweight='bold')\n",
    "sns.scatterplot(y='LDAPS_PPT2',x='Solar radiation',data=df,color='brown')\n",
    "plt.xticks(fontsize=12,fontweight ='bold')\n",
    "plt.yticks(fontsize=12,fontweight ='bold')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title('Solar radiation Vs next-day 3rd 6-hour Precipitation',fontsize=14, fontweight='bold')\n",
    "sns.scatterplot(y='LDAPS_PPT3',x='Solar radiation',data=df,color='blue')\n",
    "plt.xticks(fontsize=12,fontweight ='bold')\n",
    "plt.yticks(fontsize=12,fontweight ='bold')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.title('Solar radiation Vs next_day 4th 6-hour Precipitation',fontsize=14, fontweight='bold')\n",
    "sns.scatterplot(y='LDAPS_PPT4',x='Solar radiation',data=df,color=\"orange\")\n",
    "plt.xticks(fontsize=12,fontweight ='bold')\n",
    "plt.yticks(fontsize=12,fontweight ='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ea0889",
   "metadata": {},
   "source": [
    "Observation:\n",
    "Irrespective of to which 6 hr quarter reading belong, solar radiation value greater than 5500w/m2 leads to higher amount of precipitation (normally greater than 8).\n",
    "if we consider scatterplot of solar radiation vs cloud cover along with above scatter plot, we can draw inference that for higher value of solar radiation cloud cover and precipitation followed each other. In other words higher precipitation means higher cloud cover.\n",
    "This all give rise to few questions here :\n",
    "Where relative humidity and wind speed fit in this equation of precipitation?\n",
    "Latent heat means heat absorption at constant temperature, there has to some effect of latent heat flux variation on relative humidity.\n",
    "Another interesting thing to look forward is wind tend to blow clound. What is wind speed value in relative terms when cloud cover is high?\n",
    "What is variation in precipitation,cloud cover and wind speed over year period?\n",
    "Variation of temperature over duration of one year period?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96cb966",
   "metadata": {},
   "source": [
    "## Lets start investigation from last question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17da6a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.barplot(x=df['Month'], y=df['LDAPS_PPT1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6843ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing Next day minimum temperature and next day average cloud cover\n",
    "\n",
    "plt.figure(figsize=(18,16))\n",
    "plt.suptitle('Temperature Vs Month',fontsize=20, fontweight='bold')\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('Present_Tmax Vs Month',fontsize=14, fontweight='bold')\n",
    "axes=sns.lineplot(y='Present_Tmax',x='Month',data=df)\n",
    "axes.set_ylim([0, 35])\n",
    "plt.xticks(fontsize=12,fontweight ='bold')\n",
    "plt.yticks(fontsize=12,fontweight ='bold')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('Present_Tmin Vs Month',fontsize=14, fontweight='bold')\n",
    "axes=sns.barplot(y='Present_Tmin',x='Month',data=df)\n",
    "axes.set_ylim([0, 35])\n",
    "plt.xticks(fontsize=12,fontweight ='bold')\n",
    "plt.yticks(fontsize=12,fontweight ='bold')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title('Next_Tmax Vs Month',fontsize=14, fontweight='bold')\n",
    "axes=sns.barplot(y='Next_Tmax',x='Month',data=df)\n",
    "axes.set_ylim([0, 35])\n",
    "plt.xticks(fontsize=12,fontweight ='bold')\n",
    "plt.yticks(fontsize=12,fontweight ='bold')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.title('Next_Tmin Vs Month',fontsize=14, fontweight='bold')\n",
    "axes=sns.barplot(y='Next_Tmin',x='Month',data=df)\n",
    "axes.set_ylim([0, 35])\n",
    "plt.xticks(fontsize=12,fontweight ='bold')\n",
    "plt.yticks(fontsize=12,fontweight ='bold')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d6c19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing Next day minimum temperature and next day average cloud cover\n",
    "\n",
    "plt.figure(figsize=(16,14))\n",
    "plt.suptitle('Next-day Precipitation Month Wise',fontsize=20, fontweight='bold')\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('Next-day 1st 6-hour Precipitation Monthwise',fontsize=14, fontweight='bold')\n",
    "sns.barplot(x=df['Month'], y=df['LDAPS_PPT1'],data=df,color=\"grey\")\n",
    "plt.xticks(fontsize=12,fontweight ='bold')\n",
    "plt.yticks(fontsize=12,fontweight ='bold')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('Next-day 2nd 6-hour Precipitation Monthwise',fontsize=14, fontweight='bold')\n",
    "sns.barplot(x=df['Month'], y=df['LDAPS_PPT2'],data=df,color='brown')\n",
    "plt.xticks(fontsize=12,fontweight ='bold')\n",
    "plt.yticks(fontsize=12,fontweight ='bold')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title('Next-day 3rd 6-hour Precipitation Monthwise',fontsize=14, fontweight='bold')\n",
    "sns.barplot(x=df['Month'], y=df['LDAPS_PPT3'],data=df,color='blue')\n",
    "plt.xticks(fontsize=12,fontweight ='bold')\n",
    "plt.yticks(fontsize=12,fontweight ='bold')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.title('Next_day 4th 6-hour Precipitation Monthwise',fontsize=14, fontweight='bold')\n",
    "sns.barplot(x=df['Month'], y=df['LDAPS_PPT4'],data=df,color=\"orange\")\n",
    "plt.xticks(fontsize=12,fontweight ='bold')\n",
    "plt.yticks(fontsize=12,fontweight ='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc6c81a",
   "metadata": {},
   "source": [
    "Comment :\n",
    "In 9th Month highest precipitation observe in 1st quarter of day.\n",
    "In 1th Month highest precipitation observe in 2ed quarter of day.\n",
    "In 11th Month highest precipitation observe in 3rd quarter of day.\n",
    "In 6th Month highest precipitation observe in 4st quarter of day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f931df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.histplot(df['Solar radiation'],kde=True,color='y')\n",
    "print('Minimum Solar radiation :',df['Solar radiation'].min())\n",
    "print('Maximum Solar radiation :',df['Solar radiation'].max())\n",
    "print('Average Solar radiation :',df['Solar radiation'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423ec60b",
   "metadata": {},
   "source": [
    "Minimum Solar radiation : 4329.520508\n",
    "Maximum Solar radiation : 5992.895996\n",
    "Average Solar radiation : 5343.72420785672"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f2f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette('husl')\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(y=df['Solar radiation'], x=df['Month'])\n",
    "plt.title('Solar radiation VS Month',fontsize=18, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c08e06d",
   "metadata": {},
   "source": [
    "Comment :\n",
    "Solar Radiation data is left skewed.\n",
    "It has its minimum value at 4329.52 Wh/m2 and maximum values at 5992.89 Wh/m2.\n",
    "For most of reading solar radiation values lies in the range 5600 to 5850.\n",
    "Minimum solar radiation occur in month of 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abd94a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.histplot(df['LDAPS_WS'],kde=True,color='limegreen')\n",
    "plt.title('Wind Speed Variation')\n",
    "print('Minimum Wind Speed :',df['LDAPS_WS'].min(),'m/s')\n",
    "print('Maximum Wind Speed :',df['LDAPS_WS'].max(),'m/s')\n",
    "print('Average Wind Speed :',df['LDAPS_WS'].mean(),'m/s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352159bc",
   "metadata": {},
   "source": [
    "Minimum Wind Speed : 2.882579625 m/s\n",
    "Maximum Wind Speed : 21.85762099 m/s\n",
    "Average Wind Speed : 7.094096699159837 m/s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13515aca",
   "metadata": {},
   "source": [
    "Comment :\n",
    "It have its minimum value at 2.88m/s and maximum values at 21.85m/s\n",
    "For most of reading values lies in the rabge 5m/s to 8m/s\n",
    "Graph is slightly right skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa06309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(1,2,1)\n",
    "sns.histplot(df['LDAPS_RHmax'],kde=True,color='r')\n",
    "plt.title('Maximum relative humidity (%)',fontsize=14, fontweight='bold')\n",
    "plt.subplot(1,2,2)\n",
    "sns.histplot(df['LDAPS_RHmin'],kde=True,color='b')\n",
    "plt.title('Minimum relative humidity (%)',fontsize=14, fontweight='bold')\n",
    "print('Minimum RHmax is {} % and Maximum RHmax is {} %'.format(df['LDAPS_RHmax'].min(),df['LDAPS_RHmax'].max()))\n",
    "print('Minimum RHmin is {} % and Maximum RHmin is {} %'.format(df['LDAPS_RHmin'].min(),df['LDAPS_RHmin'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fb32d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Minimum RHmax is 58.93628311 % and Maximum RHmax is 100.00015259999999 %\n",
    "Minimum RHmin is 19.79466629 % and Maximum RHmin is 98.5247345 %"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b4ba79",
   "metadata": {},
   "source": [
    "Comment :\n",
    "Data of Maximum Relative humidity is left skewed and Data of Minimum Relative humidity is slightly right skewed.\n",
    "Maximum Relative humidity for most of the days lie in the range 90 to 97\n",
    "Maximum Relative humidity lies in the range 45 to 62."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b248d54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(1,2,1)\n",
    "sns.histplot(df['LDAPS_Tmax_lapse'],kde=True,color='purple')\n",
    "plt.title('Maximum Tmax applied lapse rate',fontsize=14, fontweight='bold')\n",
    "plt.subplot(1,2,2)\n",
    "sns.histplot(df['LDAPS_Tmin_lapse'],kde=True,color='green')\n",
    "plt.title('Minimum Tmin applied lapse rate',fontsize=14, fontweight='bold')\n",
    "print('Minimum Tmax applied lapse rate is {} (Â°C) and Maximum Tmax applied lapse rate is {} (Â°C)'.format(df['LDAPS_Tmax_lapse'].min(),df['LDAPS_Tmax_lapse'].max()))\n",
    "print('Minimum Tmin is applied lapse rate {} (Â°C) and Maximum Tmin applied lapse rate is {} (Â°C)'.format(df['LDAPS_Tmin_lapse'].min(),df['LDAPS_Tmin_lapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd321310",
   "metadata": {},
   "outputs": [],
   "source": [
    "Minimum Tmax applied lapse rate is 17.62495378 (Â°C) and Maximum Tmax applied lapse rate is 38.54225522 (Â°C)\n",
    "Minimum Tmin is applied lapse rate 14.27264631 (Â°C) and Maximum Tmin applied lapse rate is 29.61934244 (Â°C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bc632b",
   "metadata": {},
   "source": [
    "Observation :\n",
    "Tmax and Tmin for applied lapse rate are almost normally distributed.\n",
    "Tmax_lapse for majority of days its values lies in the range 27 to 33 (Â°C).\n",
    "Tmin_lapse for majority of days its values lies in the range 23 to 26 (Â°C)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915e0fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,7))\n",
    "sns.histplot(df['LDAPS_LH'],kde=True,color='blue')\n",
    "plt.title('Next day average Latent Heat Flux',fontsize=18, fontweight='bold')\n",
    "print('Minimum Latent Heat Flux :',df['LDAPS_LH'].min())\n",
    "print('Maximum Latent Heat Flux :',df['LDAPS_LH'].max())\n",
    "print('Average Latent Heat Flux :',df['LDAPS_LH'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0585806",
   "metadata": {},
   "outputs": [],
   "source": [
    "Minimum Latent Heat Flux : -13.60321209\n",
    "Maximum Latent Heat Flux : 213.4140062\n",
    "Average Latent Heat Flux : 62.492606287988046"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eded0f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,7))\n",
    "sns.barplot(y=df['LDAPS_LH'], x=df['Month'])\n",
    "plt.title('Next day average Latent Heat Flux VS Month',fontsize=18, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d55289",
   "metadata": {},
   "source": [
    "## Encoding categorical data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d407c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort columns by datatypes\n",
    "df.columns.to_series().groupby(df.dtypes).groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558151bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "{float64: ['station', 'Present_Tmax', 'Present_Tmin', 'LDAPS_RHmin', 'LDAPS_RHmax', 'LDAPS_Tmax_lapse', 'LDAPS_Tmin_lapse', 'LDAPS_WS', 'LDAPS_LH', 'LDAPS_CC1', 'LDAPS_CC2', 'LDAPS_CC3', 'LDAPS_CC4', 'LDAPS_PPT1', 'LDAPS_PPT2', 'LDAPS_PPT3', 'LDAPS_PPT4', 'lat', 'lon', 'DEM', 'Slope', 'Solar radiation', 'Next_Tmax', 'Next_Tmin'], datetime64[ns]: ['Date'], int64: ['Day', 'Month', 'Year'], object: ['State', 'City']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962c9e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Label Encoder on categorical variable\n",
    "Category = ['State', 'City']\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for i in Category:\n",
    "    df[i] = le.fit_transform(df[i])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618a1051",
   "metadata": {},
   "outputs": [],
   "source": [
    "\tstation\tDate\tPresent_Tmax\tPresent_Tmin\tLDAPS_RHmin\tLDAPS_RHmax\tLDAPS_Tmax_lapse\tLDAPS_Tmin_lapse\tLDAPS_WS\tLDAPS_LH\tLDAPS_CC1\tLDAPS_CC2\tLDAPS_CC3\tLDAPS_CC4\tLDAPS_PPT1\tLDAPS_PPT2\tLDAPS_PPT3\tLDAPS_PPT4\tlat\tlon\tDEM\tSlope\tSolar radiation\tNext_Tmax\tNext_Tmin\tDay\tMonth\tYear\tState\tCity\n",
    "0\t1.0\t2013-06-30\t28.7\t21.4\t58.255688\t91.116364\t28.074101\t23.006936\t6.818887\t69.451805\t0.233947\t0.203896\t0.161697\t0.130928\t0.0\t0.0\t0.0\t0.0\t37.6046\t126.991\t212.3350\t2.7850\t5992.895996\t29.1\t21.2\t30\t6\t2013\t1\t6\n",
    "1\t2.0\t2013-06-30\t31.9\t21.6\t52.263397\t90.604721\t29.850689\t24.035009\t5.691890\t51.937448\t0.225508\t0.251771\t0.159444\t0.127727\t0.0\t0.0\t0.0\t0.0\t37.6046\t127.032\t44.7624\t0.5141\t5869.312500\t30.5\t22.5\t30\t6\t2013\t1\t6\n",
    "2\t3.0\t2013-06-30\t31.6\t23.3\t48.690479\t83.973587\t30.091292\t24.565633\t6.138224\t20.573050\t0.209344\t0.257469\t0.204091\t0.142125\t0.0\t0.0\t0.0\t0.0\t37.5776\t127.058\t33.3068\t0.2661\t5863.555664\t31.1\t23.9\t30\t6\t2013\t1\t6\n",
    "3\t4.0\t2013-06-30\t32.0\t23.4\t58.239788\t96.483688\t29.704629\t23.326177\t5.650050\t65.727144\t0.216372\t0.226002\t0.161157\t0.134249\t0.0\t0.0\t0.0\t0.0\t37.6450\t127.022\t45.7160\t2.5348\t5856.964844\t31.7\t24.3\t30\t6\t2013\t1\t6\n",
    "4\t5.0\t2013-06-30\t31.4\t21.9\t56.174095\t90.155128\t29.113934\t23.486480\t5.735004\t107.965535\t0.151407\t0.249995\t0.178892\t0.170021\t0.0\t0.0\t0.0\t0.0\t37.5507\t127.135\t35.0380\t0.5055\t5859.552246\t31.2\t22.5\t30\t6\t2013\t0\t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c8fed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping unnecessary columns\n",
    "df.drop(['Date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fade1b29",
   "metadata": {},
   "source": [
    "## Feature selection and Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33625415",
   "metadata": {},
   "source": [
    "### 1. Outliers Detection and Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40b92c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e9022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(7588, 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c1deb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,45),facecolor='white')\n",
    "plotnumber=1\n",
    "\n",
    "for column in df:\n",
    "    if plotnumber<=29:\n",
    "        ax=plt.subplot(10,3,plotnumber)\n",
    "        sns.boxplot(df[column],color='g')\n",
    "        plt.xlabel(column,fontsize=20)\n",
    "    plotnumber+=1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6594aafd",
   "metadata": {},
   "source": [
    "## Outliers removal using Zscore method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acc4e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "z = np.abs(zscore(df))\n",
    "threshold = 3\n",
    "df1 = df[(z<3).all(axis = 1)]\n",
    "\n",
    "print (\"Shape of the dataframe before removing outliers: \", df.shape)\n",
    "print (\"Shape of the dataframe after removing outliers: \", df1.shape)\n",
    "print (\"Percentage of data loss post outlier removal: \", (df.shape[0]-df1.shape[0])/df.shape[0]*100)\n",
    "\n",
    "df=df1.copy() # reassigning the changed dataframe name to our original dataframe name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bdc68e",
   "metadata": {},
   "source": [
    "Shape of the dataframe before removing outliers:  (7588, 29)\n",
    "Shape of the dataframe after removing outliers:  (6739, 29)\n",
    "Percentage of data loss post outlier removal:  11.188719030047443\n",
    "We are losing 11.18 % of data. Its big but we can afford it. Considering we have a lot of rows in our datatset for ML model building.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e005cd6d",
   "metadata": {},
   "source": [
    "### 2. Skewness of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de43a9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,40),facecolor='white')\n",
    "sns.set_palette('rainbow')\n",
    "plotnum=1\n",
    "for col in df:\n",
    "    if plotnum<=29:\n",
    "        plt.subplot(10,3,plotnum)\n",
    "        sns.distplot(df[col])\n",
    "        plt.xlabel(col,fontsize=20)\n",
    "    plotnum+=1\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef2f235",
   "metadata": {},
   "outputs": [],
   "source": [
    "Skewness is important feature for continous data. There is no relevence of skweness for discrete numerical feature like month and categorical feature.So we gone ignore skewness present in discrete numerical and categorical feature.\n",
    "\n",
    "We also going to ignore sknewness in target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2abaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01367ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# station            -0.001594\n",
    "Present_Tmax       -0.269936\n",
    "Present_Tmin       -0.221250\n",
    "LDAPS_RHmin         0.309567\n",
    "LDAPS_RHmax        -0.686083\n",
    "LDAPS_Tmax_lapse   -0.110563\n",
    "LDAPS_Tmin_lapse   -0.379269\n",
    "LDAPS_WS            1.085685\n",
    "LDAPS_LH            0.567050\n",
    "LDAPS_CC1           0.594835\n",
    "LDAPS_CC2           0.505774\n",
    "LDAPS_CC3           0.701288\n",
    "LDAPS_CC4           0.708754\n",
    "LDAPS_PPT1          3.724580\n",
    "LDAPS_PPT2          4.854967\n",
    "LDAPS_PPT3          5.516862\n",
    "LDAPS_PPT4          5.924324\n",
    "lat                 0.106983\n",
    "lon                -0.277547\n",
    "DEM                 1.764698\n",
    "Slope               1.590130\n",
    "Solar radiation    -0.520157\n",
    "Next_Tmax          -0.267526\n",
    "Next_Tmin          -0.234328\n",
    "Day                 0.256528\n",
    "Month              -0.680725\n",
    "Year                0.025066\n",
    "State               0.143188\n",
    "City               -0.951530\n",
    "dtype: float64\n",
    "Here some are positively skewed while others are negatively skewed. We gone use yeo-johnson method for transfromation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d847fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the skew less than or equal to +0.5 and -0.5 for better prediction using yeo-johnson method\n",
    "skew=['LDAPS_RHmax','LDAPS_Tmin_lapse','LDAPS_WS','LDAPS_LH','LDAPS_CC3','LDAPS_CC4',\n",
    "      'LDAPS_PPT1','LDAPS_PPT2','LDAPS_PPT3','LDAPS_PPT4','DEM','Slope','Solar radiation','Month']\n",
    "\n",
    "# Importing Powertransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "scaler = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "# Transfroming skew data\n",
    "df[skew] = scaler.fit_transform(df[skew].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94377b42",
   "metadata": {},
   "source": [
    "For LDAPS_PPT1,LDAPS_PPT2,LDAPS_PPT3 and LDAPS_PPT4 skewness has not been removed but it got reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5d33f7",
   "metadata": {},
   "source": [
    "## 3. Corrleation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d859b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1c27ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "station\tPresent_Tmax\tPresent_Tmin\tLDAPS_RHmin\tLDAPS_RHmax\tLDAPS_Tmax_lapse\tLDAPS_Tmin_lapse\tLDAPS_WS\tLDAPS_LH\tLDAPS_CC1\tLDAPS_CC2\tLDAPS_CC3\tLDAPS_CC4\tLDAPS_PPT1\tLDAPS_PPT2\tLDAPS_PPT3\tLDAPS_PPT4\tlat\tlon\tDEM\tSlope\tSolar radiation\tNext_Tmax\tNext_Tmin\tDay\tMonth\tYear\tState\tCity\n",
    "station\t1.000000\t0.110291\t0.133638\t-0.069582\t-0.182354\t0.066863\t0.108664\t0.030231\t-0.135717\t0.008671\t0.006380\t0.006303\t0.011510\t-0.001774\t-0.006798\t-0.004884\t-0.000285\t-0.241811\t-0.122829\t-0.326019\t-0.146034\t-0.034787\t0.106378\t0.129110\t0.005179\t0.003494\t0.006658\t-0.107709\t-0.172313\n",
    "Present_Tmax\t0.110291\t1.000000\t0.610428\t-0.154266\t-0.320074\t0.540680\t0.623443\t-0.071596\t0.119022\t-0.290078\t-0.157917\t-0.061417\t-0.049978\t-0.190222\t-0.097425\t-0.022348\t-0.021344\t-0.052041\t0.011132\t-0.130892\t-0.092409\t-0.099696\t0.586943\t0.615950\t-0.136914\t0.039443\t0.099185\t-0.049572\t-0.028619\n",
    "Present_Tmin\t0.133638\t0.610428\t1.000000\t0.151385\t-0.053421\t0.441577\t0.764041\t0.034364\t-0.008556\t0.090828\t0.117894\t0.043629\t0.000193\t0.068506\t0.090113\t0.035889\t-0.063495\t-0.072707\t-0.043201\t-0.238916\t-0.157839\t-0.047145\t0.438813\t0.785946\t-0.076877\t-0.019387\t0.099222\t-0.073556\t-0.032508\n",
    "LDAPS_RHmin\t-0.069582\t-0.154266\t0.151385\t1.000000\t0.566069\t-0.555583\t0.114069\t0.171684\t-0.002412\t0.574389\t0.713238\t0.636195\t0.459528\t0.410985\t0.510241\t0.405612\t0.244139\t0.090054\t-0.093969\t0.057460\t0.083910\t0.229070\t-0.433872\t0.134518\t-0.070194\t-0.070498\t0.001709\t-0.078498\t-0.060087\n",
    "LDAPS_RHmax\t-0.182354\t-0.320074\t-0.053421\t0.566069\t1.000000\t-0.403634\t-0.182113\t0.060965\t0.285942\t0.425827\t0.372085\t0.143375\t0.046555\t0.420202\t0.368154\t0.219383\t0.118163\t0.232258\t0.013059\t0.174176\t0.209222\t0.154031\t-0.323446\t-0.110402\t-0.009056\t-0.049410\t-0.146019\t-0.039266\t-0.037656\n",
    "LDAPS_Tmax_lapse\t0.066863\t0.540680\t0.441577\t-0.555583\t-0.403634\t1.000000\t0.624572\t-0.154400\t0.005878\t-0.416255\t-0.492392\t-0.468317\t-0.367547\t-0.307565\t-0.344808\t-0.285371\t-0.207369\t-0.038285\t0.106354\t-0.110286\t-0.105094\t-0.034699\t0.816861\t0.553227\t-0.140514\t-0.014191\t0.066794\t-0.033596\t-0.001619\n",
    "LDAPS_Tmin_lapse\t0.108664\t0.623443\t0.764041\t0.114069\t-0.182113\t0.624572\t1.000000\t-0.002164\t-0.143246\t0.023128\t0.087752\t0.032023\t-0.017483\t-0.054475\t0.021320\t-0.018357\t-0.084124\t-0.091796\t-0.025047\t-0.174769\t-0.160165\t0.009890\t0.550810\t0.873678\t-0.141718\t-0.018686\t0.061339\t-0.065932\t-0.024363\n",
    "LDAPS_WS\t0.030231\t-0.071596\t0.034364\t0.171684\t0.060965\t-0.154400\t-0.002164\t1.000000\t-0.056362\t0.203057\t0.156336\t0.065764\t0.090955\t0.197126\t0.166155\t0.089355\t0.167950\t-0.027463\t-0.077686\t0.113157\t0.095385\t0.164626\t-0.205979\t0.023330\t-0.050895\t-0.065461\t-0.119526\t-0.004350\t-0.016754\n",
    "LDAPS_LH\t-0.135717\t0.119022\t-0.008556\t-0.002412\t0.285942\t0.005878\t-0.143246\t-0.056362\t1.000000\t-0.113430\t-0.224377\t-0.213416\t-0.149974\t0.017757\t-0.061339\t0.010756\t0.028329\t0.100486\t0.009790\t0.053275\t0.069892\t-0.032027\t0.151784\t-0.052365\t-0.014488\t-0.017527\t0.054981\t-0.042471\t-0.038202\n",
    "LDAPS_CC1\t0.008671\t-0.290078\t0.090828\t0.574389\t0.425827\t-0.416255\t0.023128\t0.203057\t-0.113430\t1.000000\t0.759430\t0.485809\t0.332623\t0.726938\t0.570382\t0.300876\t0.223193\t-0.006352\t-0.013794\t-0.030080\t-0.032476\t0.235623\t-0.453763\t0.008400\t-0.034100\t-0.106406\t-0.069276\t-0.037880\t-0.025990\n",
    "LDAPS_CC2\t0.006380\t-0.157917\t0.117894\t0.713238\t0.372085\t-0.492392\t0.087752\t0.156336\t-0.224377\t0.759430\t1.000000\t0.690774\t0.488186\t0.462306\t0.666230\t0.387096\t0.237396\t-0.002066\t-0.013838\t-0.027267\t-0.029457\t0.173488\t-0.484796\t0.078871\t-0.013621\t-0.112754\t-0.062914\t-0.029908\t-0.022397\n",
    "LDAPS_CC3\t0.006303\t-0.061417\t0.043629\t0.636195\t0.143375\t-0.468317\t0.032023\t0.065764\t-0.213416\t0.485809\t0.690774\t1.000000\t0.765041\t0.266990\t0.395289\t0.459030\t0.402332\t-0.005810\t0.012323\t-0.006590\t-0.010127\t0.125733\t-0.464998\t0.021743\t-0.034455\t-0.054638\t0.104130\t-0.019029\t-0.013006\n",
    "LDAPS_CC4\t0.011510\t-0.049978\t0.000193\t0.459528\t0.046555\t-0.367547\t-0.017483\t0.090955\t-0.149974\t0.332623\t0.488186\t0.765041\t1.000000\t0.190772\t0.276920\t0.308301\t0.475357\t-0.023834\t-0.016750\t-0.027704\t-0.029013\t0.110737\t-0.415827\t-0.026091\t-0.028077\t-0.019631\t0.123391\t-0.017571\t-0.012878\n",
    "LDAPS_PPT1\t-0.001774\t-0.190222\t0.068506\t0.410985\t0.420202\t-0.307565\t-0.054475\t0.197126\t0.017757\t0.726938\t0.462306\t0.266990\t0.190772\t1.000000\t0.505664\t0.272455\t0.189534\t0.017866\t0.002196\t-0.011255\t-0.005558\t0.169165\t-0.347241\t-0.053093\t-0.005729\t-0.097217\t-0.068796\t-0.038626\t-0.028771\n",
    "LDAPS_PPT2\t-0.006798\t-0.097425\t0.090113\t0.510241\t0.368154\t-0.344808\t0.021320\t0.166155\t-0.061339\t0.570382\t0.666230\t0.395289\t0.276920\t0.505664\t1.000000\t0.385266\t0.180817\t0.030232\t-0.000990\t0.002689\t0.006903\t0.129413\t-0.357330\t-0.006710\t0.025842\t-0.120270\t-0.068552\t-0.027284\t-0.020184\n",
    "LDAPS_PPT3\t-0.004884\t-0.022348\t0.035889\t0.405612\t0.219383\t-0.285371\t-0.018357\t0.089355\t0.010756\t0.300876\t0.387096\t0.459030\t0.308301\t0.272455\t0.385266\t1.000000\t0.427754\t0.034607\t0.009905\t0.025174\t0.037009\t0.006045\t-0.268024\t-0.029908\t-0.032548\t-0.058580\t-0.013736\t-0.027258\t-0.024385\n",
    "LDAPS_PPT4\t-0.000285\t-0.021344\t-0.063495\t0.244139\t0.118163\t-0.207369\t-0.084124\t0.167950\t0.028329\t0.223193\t0.237396\t0.402332\t0.475357\t0.189534\t0.180817\t0.427754\t1.000000\t0.000523\t0.012639\t-0.006950\t-0.005177\t0.033949\t-0.217651\t-0.100787\t-0.030304\t-0.034223\t0.022889\t0.002054\t-0.004424\n",
    "lat\t-0.241811\t-0.052041\t-0.072707\t0.090054\t0.232258\t-0.038285\t-0.091796\t-0.027463\t0.100486\t-0.006352\t-0.002066\t-0.005810\t-0.023834\t0.017866\t0.030232\t0.034607\t0.000523\t1.000000\t0.286414\t0.034116\t0.105511\t0.048285\t-0.048616\t-0.076705\t-0.005683\t0.006193\t0.001499\t-0.042537\t-0.060883\n",
    "lon\t-0.122829\t0.011132\t-0.043201\t-0.093969\t0.013059\t0.106354\t-0.025047\t-0.077686\t0.009790\t-0.013794\t-0.013838\t0.012323\t-0.016750\t0.002196\t-0.000990\t0.009905\t0.012639\t0.286414\t1.000000\t0.186841\t0.114267\t0.011724\t0.010567\t-0.041574\t-0.003444\t-0.000341\t-0.005863\t0.029594\t0.023476\n",
    "DEM\t-0.326019\t-0.130892\t-0.238916\t0.057460\t0.174176\t-0.110286\t-0.174769\t0.113157\t0.053275\t-0.030080\t-0.027267\t-0.006590\t-0.027704\t-0.011255\t0.002689\t0.025174\t-0.006950\t0.034116\t0.186841\t1.000000\t0.779420\t0.060194\t-0.117146\t-0.238249\t-0.007739\t-0.000803\t0.000613\t0.063881\t0.035397\n",
    "Slope\t-0.146034\t-0.092409\t-0.157839\t0.083910\t0.209222\t-0.105094\t-0.160165\t0.095385\t0.069892\t-0.032476\t-0.029457\t-0.010127\t-0.029013\t-0.005558\t0.006903\t0.037009\t-0.005177\t0.105511\t0.114267\t0.779420\t1.000000\t0.037988\t-0.084174\t-0.158030\t-0.007098\t0.000118\t0.000939\t0.036267\t-0.002818\n",
    "Solar radiation\t-0.034787\t-0.099696\t-0.047145\t0.229070\t0.154031\t-0.034699\t0.009890\t0.164626\t-0.032027\t0.235623\t0.173488\t0.125733\t0.110737\t0.169165\t0.129413\t0.006045\t0.033949\t0.048285\t0.011724\t0.060194\t0.037988\t1.000000\t-0.061064\t0.012532\t-0.377246\t-0.282285\t0.025585\t-0.065657\t-0.033396\n",
    "Next_Tmax\t0.106378\t0.586943\t0.438813\t-0.433872\t-0.323446\t0.816861\t0.550810\t-0.205979\t0.151784\t-0.453763\t-0.484796\t-0.464998\t-0.415827\t-0.347241\t-0.357330\t-0.268024\t-0.217651\t-0.048616\t0.010567\t-0.117146\t-0.084174\t-0.061064\t1.000000\t0.580951\t-0.105005\t-0.016328\t0.101615\t-0.054571\t-0.025503\n",
    "Next_Tmin\t0.129110\t0.615950\t0.785946\t0.134518\t-0.110402\t0.553227\t0.873678\t0.023330\t-0.052365\t0.008400\t0.078871\t0.021743\t-0.026091\t-0.053093\t-0.006710\t-0.029908\t-0.100787\t-0.076705\t-0.041574\t-0.238249\t-0.158030\t0.012532\t0.580951\t1.000000\t-0.099202\t-0.029336\t0.069291\t-0.091937\t-0.038001\n",
    "Day\t0.005179\t-0.136914\t-0.076877\t-0.070194\t-0.009056\t-0.140514\t-0.141718\t-0.050895\t-0.014488\t-0.034100\t-0.013621\t-0.034455\t-0.028077\t-0.005729\t0.025842\t-0.032548\t-0.030304\t-0.005683\t-0.003444\t-0.007739\t-0.007098\t-0.377246\t-0.105005\t-0.099202\t1.000000\t0.084333\t-0.050717\t0.050090\t0.022369\n",
    "Month\t0.003494\t0.039443\t-0.019387\t-0.070498\t-0.049410\t-0.014191\t-0.018686\t-0.065461\t-0.017527\t-0.106406\t-0.112754\t-0.054638\t-0.019631\t-0.097217\t-0.120270\t-0.058580\t-0.034223\t0.006193\t-0.000341\t-0.000803\t0.000118\t-0.282285\t-0.016328\t-0.029336\t0.084333\t1.000000\t0.031258\t0.017346\t0.007015\n",
    "Year\t0.006658\t0.099185\t0.099222\t0.001709\t-0.146019\t0.066794\t0.061339\t-0.119526\t0.054981\t-0.069276\t-0.062914\t0.104130\t0.123391\t-0.068796\t-0.068552\t-0.013736\t0.022889\t0.001499\t-0.005863\t0.000613\t0.000939\t0.025585\t0.101615\t0.069291\t-0.050717\t0.031258\t1.000000\t0.060540\t0.029458\n",
    "State\t-0.107709\t-0.049572\t-0.073556\t-0.078498\t-0.039266\t-0.033596\t-0.065932\t-0.004350\t-0.042471\t-0.037880\t-0.029908\t-0.019029\t-0.017571\t-0.038626\t-0.027284\t-0.027258\t0.002054\t-0.042537\t0.029594\t0.063881\t0.036267\t-0.065657\t-0.054571\t-0.091937\t0.050090\t0.017346\t0.060540\t1.000000\t0.842886\n",
    "City\t-0.172313\t-0.028619\t-0.032508\t-0.060087\t-0.037656\t-0.001619\t-0.024363\t-0.016754\t-0.038202\t-0.025990\t-0.022397\t-0.013006\t-0.012878\t-0.028771\t-0.020184\t-0.024385\t-0.004424\t-0.060883\t0.023476\t0.035397\t-0.002818\t-0.033396\t-0.025503\t-0.038001\t0.022369\t0.007015\t0.029458\t0.842886\t1.000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d5e0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,15))\n",
    "sns.heatmap(df.corr(), vmin=-1, vmax=1, annot=True, square=True, fmt='0.3f', \n",
    "            annot_kws={'size':10}, cmap=\"gist_stern\")\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e08c503",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (18,6))\n",
    "df.corr()['Next_Tmax'].drop(['Next_Tmax']).sort_values(ascending=False).plot(kind='bar',color = 'purple')\n",
    "plt.xlabel('Features',fontsize=15,fontweight='bold')\n",
    "plt.ylabel('Next_Tmax',fontsize=15,fontweight='bold')\n",
    "plt.title('Correlation of features with Target Variable Next_Tmax',fontsize = 20,fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d7301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (18,6))\n",
    "df.corr()['Next_Tmin'].drop(['Next_Tmin']).sort_values(ascending=False).plot(kind='bar',color = 'purple')\n",
    "plt.xlabel('Features',fontsize=15,fontweight='bold')\n",
    "plt.ylabel('Next_Tmin',fontsize=15,fontweight='bold')\n",
    "plt.title('Correlation of features with Target Variable Next_Tmin',fontsize = 20,fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ce5c0c",
   "metadata": {},
   "source": [
    "## Machine Learning Model Building For Next_Tmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826c1458",
   "metadata": {},
   "source": [
    "## Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3f0e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data in target and dependent feature\n",
    "X = df.drop(['Next_Tmax'], axis =1)\n",
    "Y = df['Next_Tmax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60c7239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler= StandardScaler()\n",
    "X_scale = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b054ab6",
   "metadata": {},
   "source": [
    "## Checking Multicollinearity between features using variance_inflation_factor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7dc3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF values\"] = [variance_inflation_factor(X_scale,i) for i in range(len(X.columns))]\n",
    "vif[\"Features\"] = X.columns\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c31f7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIF values\tFeatures\n",
    "0\t1.353177\tstation\n",
    "1\t2.849784\tPresent_Tmax\n",
    "2\t3.383435\tPresent_Tmin\n",
    "3\t6.077961\tLDAPS_RHmin\n",
    "4\t2.614712\tLDAPS_RHmax\n",
    "5\t6.650091\tLDAPS_Tmax_lapse\n",
    "6\t8.235731\tLDAPS_Tmin_lapse\n",
    "7\t1.225322\tLDAPS_WS\n",
    "8\t1.523389\tLDAPS_LH\n",
    "9\t4.874106\tLDAPS_CC1\n",
    "10\t5.533647\tLDAPS_CC2\n",
    "11\t4.567857\tLDAPS_CC3\n",
    "12\t2.792518\tLDAPS_CC4\n",
    "13\t2.601274\tLDAPS_PPT1\n",
    "14\t2.174592\tLDAPS_PPT2\n",
    "15\t1.592341\tLDAPS_PPT3\n",
    "16\t1.601009\tLDAPS_PPT4\n",
    "17\t1.310633\tlat\n",
    "18\t1.225664\tlon\n",
    "19\t3.382228\tDEM\n",
    "20\t2.876560\tSlope\n",
    "21\t1.487825\tSolar radiation\n",
    "22\t5.674284\tNext_Tmin\n",
    "23\t1.259835\tDay\n",
    "24\t1.122200\tMonth\n",
    "25\t1.136580\tYear\n",
    "26\t3.615665\tState\n",
    "27\t3.641816\tCity\n",
    "Independent feature VIF is within permissible limit of 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f1716e",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de08f26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "#plot the graph to find the principal components\n",
    "x_pca = pca.fit_transform(X_scale)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_), 'ro-')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance %')\n",
    "plt.title('Explained variance Ratio')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a313d962",
   "metadata": {},
   "source": [
    "Comment -\n",
    "AS per the graph, we can see that 15 principal components attribute for 90% of variation in the data. We shall pick the first 15 components for our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579a2e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_new = PCA(n_components=15)\n",
    "x_new = pca_new.fit_transform(X_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ed0b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "principle_x=pd.DataFrame(x_new,columns=np.arange(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087dec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import  GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import  Ridge\n",
    "from sklearn.linear_model import  Lasso\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db02247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(principle_x, Y, random_state=42, test_size=.33)\n",
    "print('Training feature matrix size:',X_train.shape)\n",
    "print('Training target vector size:',Y_train.shape)\n",
    "print('Test feature matrix size:',X_test.shape)\n",
    "print('Test target vector size:',Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c33c6e3",
   "metadata": {},
   "source": [
    "Training feature matrix size: (4515, 15)\n",
    "Training target vector size: (4515,)\n",
    "Test feature matrix size: (2224, 15)\n",
    "Test target vector size: (2224,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c387703",
   "metadata": {},
   "source": [
    "## Finding best Random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b76027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "maxR2_score=0\n",
    "maxRS=0\n",
    "for i in range(1,500):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_scale, Y, random_state=i, test_size=.33)\n",
    "    lin_reg=LinearRegression()\n",
    "    lin_reg.fit(X_train,Y_train)\n",
    "    y_pred=lin_reg.predict(X_test)\n",
    "    R2=r2_score(Y_test,y_pred)\n",
    "    if R2>maxR2_score:\n",
    "        maxR2_score=R2\n",
    "        maxRS=i\n",
    "print('Best R2 Score is', maxR2_score ,'on Random_state', maxRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82d0f7b",
   "metadata": {},
   "source": [
    "Best R2 Score is 0.8018242128804313 on Random_state 108"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d34af94",
   "metadata": {},
   "source": [
    "## Linear Regression Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50750e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scale, Y, random_state=108, test_size=.33)\n",
    "lin_reg=LinearRegression()\n",
    "lin_reg.fit(X_train,Y_train)\n",
    "lin_reg.score(X_train,Y_train)\n",
    "y_pred=lin_reg.predict(X_test)\n",
    "print('\\033[1m'+'Predicted Wins:'+'\\033[0m\\n',y_pred)\n",
    "print('\\n')\n",
    "print('\\033[1m'+'Actual Wins:'+'\\033[0m\\n',Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae32a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predicted Wins:\n",
    " [31.91671752 30.15944717 29.11536556 ... 25.88094278 25.16676324\n",
    " 32.69812886]\n",
    "Actual Wins:\n",
    " 934     32.0\n",
    "4582    30.1\n",
    "7277    27.8\n",
    "4776    27.6\n",
    "3755    29.8\n",
    "        ... \n",
    "7096    36.7\n",
    "7148    35.4\n",
    "7667    28.4\n",
    "5063    24.0\n",
    "4239    32.6\n",
    "Name: Next_Tmax, Length: 2224, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c86ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\033[1m'+' Error :'+'\\033[0m')\n",
    "print('Mean absolute error :', mean_absolute_error(Y_test,y_pred))\n",
    "print('Mean squared error :', mean_squared_error(Y_test,y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(Y_test,y_pred)))\n",
    "print('\\n')\n",
    "from sklearn.metrics import r2_score\n",
    "print('\\033[1m'+' R2 Score :'+'\\033[0m')\n",
    "print(r2_score(Y_test,y_pred,multioutput='variance_weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359e1640",
   "metadata": {},
   "outputs": [],
   "source": [
    "Error :\n",
    "Mean absolute error : 1.0149506546261187\n",
    "Mean squared error : 1.7458225720970808\n",
    "Root Mean Squared Error: 1.3212957928098767\n",
    "\n",
    "\n",
    " R2 Score :\n",
    "0.8018242128804313"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b3c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "score = cross_val_score(lin_reg, X_scale, Y, cv =3)\n",
    "print('\\033[1m'+'Cross Validation Score :',lin_reg,\":\"+'\\033[0m\\n')\n",
    "print(\"Mean CV Score :\",score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2008be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cross Validation Score : LinearRegression() :\n",
    "\n",
    "Mean CV Score : 0.6695150338239116"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4723295a",
   "metadata": {},
   "source": [
    "## Applying other ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299341de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22f7506",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "dtc = DecisionTreeRegressor()\n",
    "XT = ExtraTreesRegressor()\n",
    "BR = BaggingRegressor()\n",
    "adb=AdaBoostRegressor()\n",
    "gradb=GradientBoostingRegressor()\n",
    "xgb=XGBRegressor()\n",
    "model = [rf,XT,dtc,adb,gradb,xgb]\n",
    "\n",
    "for m in model:\n",
    "    m.fit(X_train,Y_train)\n",
    "    m.score(X_train,Y_train)\n",
    "    y_pred = m.predict(X_test)\n",
    "    print('\\n')                                        \n",
    "    print('\\033[1m'+' Error of ', m, ':' +'\\033[0m')\n",
    "    print('Mean absolute error :', mean_absolute_error(Y_test,y_pred))\n",
    "    print('Mean squared error :', mean_squared_error(Y_test,y_pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(mean_squared_error(Y_test,y_pred)))\n",
    "    print('\\n')\n",
    "\n",
    "    print('\\033[1m'+' R2 Score :'+'\\033[0m')\n",
    "    print(r2_score(Y_test,y_pred)) \n",
    "    print('==============================================================================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbd4ce1",
   "metadata": {},
   "source": [
    "Error of  RandomForestRegressor() :\n",
    "Mean absolute error : 0.7020692446043173\n",
    "Mean squared error : 0.875475215827339\n",
    "Root Mean Squared Error: 0.9356683257582994\n",
    "\n",
    "\n",
    " R2 Score :\n",
    "0.9006210638049824\n",
    "==============================================================================================================\n",
    "\n",
    "\n",
    " Error of  ExtraTreesRegressor() :\n",
    "Mean absolute error : 0.6066164568345326\n",
    "Mean squared error : 0.6488773700539571\n",
    "Root Mean Squared Error: 0.8055292484161932\n",
    "\n",
    "\n",
    " R2 Score :\n",
    "0.9263431544477889\n",
    "==============================================================================================================\n",
    "\n",
    "\n",
    " Error of  DecisionTreeRegressor() :\n",
    "Mean absolute error : 1.0559352517985612\n",
    "Mean squared error : 2.1271942446043166\n",
    "Root Mean Squared Error: 1.458490399215681\n",
    "\n",
    "\n",
    " R2 Score :\n",
    "0.7585330831905208\n",
    "==============================================================================================================\n",
    "\n",
    "\n",
    " Error of  AdaBoostRegressor() :\n",
    "Mean absolute error : 1.169215747020395\n",
    "Mean squared error : 2.0431813991148924\n",
    "Root Mean Squared Error: 1.4293989642905485\n",
    "\n",
    "\n",
    " R2 Score :\n",
    "0.768069740608704\n",
    "==============================================================================================================\n",
    "\n",
    "\n",
    " Error of  GradientBoostingRegressor() :\n",
    "Mean absolute error : 0.8353868172385825\n",
    "Mean squared error : 1.1568282799336678\n",
    "Root Mean Squared Error: 1.0755595194751744\n",
    "\n",
    "\n",
    " R2 Score :\n",
    "0.8686834741386978\n",
    "==============================================================================================================\n",
    "\n",
    "\n",
    " Error of  XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
    "             gamma=0, gpu_id=-1, importance_type=None,\n",
    "             interaction_constraints='', learning_rate=0.300000012,\n",
    "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
    "             monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
    "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
    "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
    "             validate_parameters=1, verbosity=None) :\n",
    "Mean absolute error : 0.6273982643223495\n",
    "Mean squared error : 0.6735959870874334\n",
    "Root Mean Squared Error: 0.8207289364262925\n",
    "\n",
    "\n",
    " R2 Score :\n",
    "0.9235372385056939\n",
    "=============================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5708603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "model = [rf,XT,dtc,adb,gradb,xgb]\n",
    "\n",
    "for m in model:\n",
    "    score = cross_val_score(m, X_scale, Y, cv =5)\n",
    "    print('\\n')\n",
    "    print('\\033[1m'+'Cross Validation Score :',m,\":\"+'\\033[0m\\n')\n",
    "    print(\"Mean CV Score :\",score.mean())\n",
    "    print('==============================================================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cf468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cross Validation Score : RandomForestRegressor() :\n",
    "\n",
    "Mean CV Score : 0.6865244852532029\n",
    "==============================================================================================================\n",
    "\n",
    "\n",
    "Cross Validation Score : ExtraTreesRegressor() :\n",
    "\n",
    "Mean CV Score : 0.6918645976111802\n",
    "==============================================================================================================\n",
    "\n",
    "\n",
    "Cross Validation Score : DecisionTreeRegressor() :\n",
    "\n",
    "Mean CV Score : 0.42756791215050444\n",
    "==============================================================================================================\n",
    "\n",
    "\n",
    "Cross Validation Score : AdaBoostRegressor() :\n",
    "\n",
    "Mean CV Score : 0.6469825145218542\n",
    "==============================================================================================================\n",
    "\n",
    "\n",
    "Cross Validation Score : GradientBoostingRegressor() :\n",
    "\n",
    "Mean CV Score : 0.7068599096853964\n",
    "==============================================================================================================\n",
    "\n",
    "\n",
    "Cross Validation Score : XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
    "             gamma=0, gpu_id=-1, importance_type=None,\n",
    "             interaction_constraints='', learning_rate=0.300000012,\n",
    "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
    "             monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
    "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
    "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
    "             validate_parameters=1, verbosity=None) :\n",
    "\n",
    "Mean CV Score : 0.6849967558135764\n",
    "=============================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926d6440",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning : GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302659ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76227cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = {'n_estimators':[200,400,500,600],'gamma':np.arange(0,0.2,0.1),\n",
    "              'booster' : ['gbtree','dart','gblinear'], 'max_depth':[4,6,8,10],\n",
    "              'eta' : [0.001, 0.01, 0.1] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c76e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCV = GridSearchCV(XGBRegressor(),parameter,verbose =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c191234",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCV.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e048df5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
    "[CV 1/5; 1/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 1/5; 1/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50;, score=-91.031 total time=   1.1s\n",
    "[CV 2/5; 1/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 2/5; 1/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50;, score=-92.596 total time=   0.5s\n",
    "[CV 3/5; 1/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 3/5; 1/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50;, score=-106.168 total time=   0.5s\n",
    "[CV 4/5; 1/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 4/5; 1/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50;, score=-101.546 total time=   0.5s\n",
    "[CV 5/5; 1/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 5/5; 1/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50;, score=-96.690 total time=   0.5s\n",
    "[CV 1/5; 2/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 1/5; 2/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75;, score=-86.537 total time=   0.5s\n",
    "[CV 2/5; 2/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 2/5; 2/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75;, score=-88.045 total time=   0.6s\n",
    "[CV 3/5; 2/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 3/5; 2/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75;, score=-100.984 total time=   0.6s\n",
    "[CV 4/5; 2/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 4/5; 2/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75;, score=-96.581 total time=   0.8s\n",
    "[CV 5/5; 2/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 5/5; 2/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75;, score=-91.953 total time=   0.7s\n",
    "[CV 1/5; 3/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 1/5; 3/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100;, score=-82.264 total time=   0.8s\n",
    "[CV 2/5; 3/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 2/5; 3/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100;, score=-83.717 total time=   1.0s\n",
    "[CV 3/5; 3/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 3/5; 3/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100;, score=-96.055 total time=   0.8s\n",
    "[CV 4/5; 3/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 4/5; 3/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100;, score=-91.857 total time=   0.8s\n",
    "[CV 5/5; 3/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 5/5; 3/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100;, score=-87.447 total time=   0.8s\n",
    "[CV 1/5; 4/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 1/5; 4/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50;, score=-91.031 total time=   0.4s\n",
    "[CV 2/5; 4/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 2/5; 4/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50;, score=-92.596 total time=   0.4s\n",
    "[CV 3/5; 4/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 3/5; 4/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50;, score=-106.168 total time=   0.4s\n",
    "[CV 4/5; 4/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 4/5; 4/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50;, score=-101.546 total time=   0.4s\n",
    "[CV 5/5; 4/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 5/5; 4/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50;, score=-96.690 total time=   0.4s\n",
    "[CV 1/5; 5/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 1/5; 5/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75;, score=-86.537 total time=   0.6s\n",
    "[CV 2/5; 5/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 2/5; 5/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75;, score=-88.045 total time=   0.6s\n",
    "[CV 3/5; 5/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 3/5; 5/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75;, score=-100.984 total time=   0.6s\n",
    "[CV 4/5; 5/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 4/5; 5/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75;, score=-96.581 total time=   0.6s\n",
    "[CV 5/5; 5/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 5/5; 5/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75;, score=-91.953 total time=   0.5s\n",
    "[CV 1/5; 6/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 1/5; 6/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100;, score=-82.264 total time=   0.8s\n",
    "[CV 2/5; 6/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 2/5; 6/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100;, score=-83.717 total time=   0.9s\n",
    "[CV 3/5; 6/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 3/5; 6/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100;, score=-96.055 total time=   0.8s\n",
    "[CV 4/5; 6/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 4/5; 6/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100;, score=-91.857 total time=   0.8s\n",
    "[CV 5/5; 6/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 5/5; 6/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100;, score=-87.447 total time=   1.8s\n",
    "[CV 1/5; 7/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 1/5; 7/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50;, score=-91.031 total time=   0.8s\n",
    "[CV 2/5; 7/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 2/5; 7/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50;, score=-92.596 total time=   0.6s\n",
    "[CV 3/5; 7/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 3/5; 7/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50;, score=-106.168 total time=   0.4s\n",
    "[CV 4/5; 7/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 4/5; 7/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50;, score=-101.546 total time=   0.5s\n",
    "[CV 5/5; 7/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 5/5; 7/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50;, score=-96.690 total time=   0.5s\n",
    "[CV 1/5; 8/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 1/5; 8/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75;, score=-86.537 total time=   0.8s\n",
    "[CV 2/5; 8/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 2/5; 8/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75;, score=-88.045 total time=   0.7s\n",
    "[CV 3/5; 8/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 3/5; 8/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75;, score=-100.984 total time=   0.6s\n",
    "[CV 4/5; 8/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 4/5; 8/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75;, score=-96.581 total time=   0.6s\n",
    "[CV 5/5; 8/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 5/5; 8/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75;, score=-91.953 total time=   0.8s\n",
    "[CV 1/5; 9/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 1/5; 9/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100;, score=-82.264 total time=   1.0s\n",
    "[CV 2/5; 9/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 2/5; 9/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100;, score=-83.717 total time=   1.0s\n",
    "[CV 3/5; 9/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 3/5; 9/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100;, score=-96.055 total time=   0.8s\n",
    "[CV 4/5; 9/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 4/5; 9/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100;, score=-91.857 total time=   0.8s\n",
    "[CV 5/5; 9/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 5/5; 9/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100;, score=-87.447 total time=   0.9s\n",
    "[CV 1/5; 10/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 1/5; 10/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50;, score=-91.031 total time=   0.6s\n",
    "[CV 2/5; 10/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 2/5; 10/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50;, score=-92.596 total time=   0.4s\n",
    "[CV 3/5; 10/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 3/5; 10/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50;, score=-106.168 total time=   0.3s\n",
    "[CV 4/5; 10/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 4/5; 10/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50;, score=-101.546 total time=   0.4s\n",
    "[CV 5/5; 10/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 5/5; 10/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50;, score=-96.690 total time=   0.6s\n",
    "[CV 1/5; 11/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 1/5; 11/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75;, score=-86.537 total time=   0.8s\n",
    "[CV 2/5; 11/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 2/5; 11/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75;, score=-88.045 total time=   0.9s\n",
    "[CV 3/5; 11/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 3/5; 11/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75;, score=-100.984 total time=   0.8s\n",
    "[CV 4/5; 11/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 4/5; 11/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75;, score=-96.581 total time=   0.7s\n",
    "[CV 5/5; 11/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 5/5; 11/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75;, score=-91.953 total time=   0.6s\n",
    "[CV 1/5; 12/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 1/5; 12/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100;, score=-82.264 total time=   0.9s\n",
    "[CV 2/5; 12/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 2/5; 12/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100;, score=-83.717 total time=   1.0s\n",
    "[CV 3/5; 12/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 3/5; 12/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100;, score=-96.055 total time=   1.2s\n",
    "[CV 4/5; 12/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 4/5; 12/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100;, score=-91.857 total time=   0.9s\n",
    "[CV 5/5; 12/216] START booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 5/5; 12/216] END booster=gbtree, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100;, score=-87.447 total time=   0.9s\n",
    "[CV 1/5; 13/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 1/5; 13/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50;, score=-91.031 total time=   0.3s\n",
    "[CV 2/5; 13/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 2/5; 13/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50;, score=-92.596 total time=   0.4s\n",
    "[CV 3/5; 13/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 3/5; 13/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50;, score=-106.168 total time=   0.3s\n",
    "[CV 4/5; 13/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 4/5; 13/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50;, score=-101.546 total time=   0.4s\n",
    "[CV 5/5; 13/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 5/5; 13/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50;, score=-96.690 total time=   0.4s\n",
    "[CV 1/5; 14/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 1/5; 14/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75;, score=-86.537 total time=   0.8s\n",
    "[CV 2/5; 14/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 2/5; 14/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75;, score=-88.045 total time=   0.6s\n",
    "[CV 3/5; 14/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 3/5; 14/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75;, score=-100.984 total time=   0.6s\n",
    "[CV 4/5; 14/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 4/5; 14/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75;, score=-96.581 total time=   0.7s\n",
    "[CV 5/5; 14/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 5/5; 14/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75;, score=-91.953 total time=   0.9s\n",
    "[CV 1/5; 15/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 1/5; 15/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100;, score=-82.264 total time=   1.1s\n",
    "[CV 2/5; 15/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 2/5; 15/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100;, score=-83.717 total time=   0.9s\n",
    "[CV 3/5; 15/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 3/5; 15/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100;, score=-96.055 total time=   0.9s\n",
    "[CV 4/5; 15/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 4/5; 15/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100;, score=-91.857 total time=   1.0s\n",
    "[CV 5/5; 15/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 5/5; 15/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100;, score=-87.447 total time=   1.1s\n",
    "[CV 1/5; 16/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 1/5; 16/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50;, score=-91.031 total time=   0.4s\n",
    "[CV 2/5; 16/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 2/5; 16/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50;, score=-92.596 total time=   0.4s\n",
    "[CV 3/5; 16/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 3/5; 16/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50;, score=-106.168 total time=   0.4s\n",
    "[CV 4/5; 16/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 4/5; 16/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50;, score=-101.546 total time=   0.3s\n",
    "[CV 5/5; 16/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 5/5; 16/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50;, score=-96.690 total time=   0.4s\n",
    "[CV 1/5; 17/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 1/5; 17/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75;, score=-86.537 total time=   0.6s\n",
    "[CV 2/5; 17/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 2/5; 17/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75;, score=-88.045 total time=   0.6s\n",
    "[CV 3/5; 17/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 3/5; 17/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75;, score=-100.984 total time=   0.8s\n",
    "[CV 4/5; 17/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 4/5; 17/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75;, score=-96.581 total time=   0.6s\n",
    "[CV 5/5; 17/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 5/5; 17/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75;, score=-91.953 total time=   0.7s\n",
    "[CV 1/5; 18/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 1/5; 18/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100;, score=-82.264 total time=   0.9s\n",
    "[CV 2/5; 18/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 2/5; 18/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100;, score=-83.717 total time=   1.1s\n",
    "[CV 3/5; 18/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 3/5; 18/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100;, score=-96.055 total time=   0.9s\n",
    "[CV 4/5; 18/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 4/5; 18/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100;, score=-91.857 total time=   1.2s\n",
    "[CV 5/5; 18/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 5/5; 18/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100;, score=-87.447 total time=   0.9s\n",
    "[CV 1/5; 19/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 1/5; 19/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50;, score=-91.031 total time=   0.3s\n",
    "[CV 2/5; 19/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 2/5; 19/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50;, score=-92.596 total time=   0.5s\n",
    "[CV 3/5; 19/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 3/5; 19/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50;, score=-106.168 total time=   0.3s\n",
    "[CV 4/5; 19/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 4/5; 19/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50;, score=-101.546 total time=   0.3s\n",
    "[CV 5/5; 19/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 5/5; 19/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50;, score=-96.690 total time=   0.4s\n",
    "[CV 1/5; 20/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 1/5; 20/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75;, score=-86.537 total time=   0.5s\n",
    "[CV 2/5; 20/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 2/5; 20/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75;, score=-88.045 total time=   0.5s\n",
    "[CV 3/5; 20/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 3/5; 20/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75;, score=-100.984 total time=   0.5s\n",
    "[CV 4/5; 20/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 4/5; 20/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75;, score=-96.581 total time=   0.5s\n",
    "[CV 5/5; 20/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 5/5; 20/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75;, score=-91.953 total time=   0.6s\n",
    "[CV 1/5; 21/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 1/5; 21/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100;, score=-82.264 total time=   0.7s\n",
    "[CV 2/5; 21/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 2/5; 21/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100;, score=-83.717 total time=   0.8s\n",
    "[CV 3/5; 21/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 3/5; 21/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100;, score=-96.055 total time=   1.0s\n",
    "[CV 4/5; 21/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 4/5; 21/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100;, score=-91.857 total time=   0.9s\n",
    "[CV 5/5; 21/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 5/5; 21/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100;, score=-87.447 total time=   0.8s\n",
    "[CV 1/5; 22/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 1/5; 22/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50;, score=-91.031 total time=   0.5s\n",
    "[CV 2/5; 22/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 2/5; 22/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50;, score=-92.596 total time=   0.5s\n",
    "[CV 3/5; 22/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 3/5; 22/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50;, score=-106.168 total time=   0.5s\n",
    "[CV 4/5; 22/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 4/5; 22/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50;, score=-101.546 total time=   0.4s\n",
    "[CV 5/5; 22/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 5/5; 22/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50;, score=-96.690 total time=   0.3s\n",
    "[CV 1/5; 23/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 1/5; 23/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75;, score=-86.537 total time=   0.7s\n",
    "[CV 2/5; 23/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 2/5; 23/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75;, score=-88.045 total time=   0.7s\n",
    "[CV 3/5; 23/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 3/5; 23/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75;, score=-100.984 total time=   0.8s\n",
    "[CV 4/5; 23/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 4/5; 23/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75;, score=-96.581 total time=   0.6s\n",
    "[CV 5/5; 23/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 5/5; 23/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75;, score=-91.953 total time=   0.6s\n",
    "[CV 1/5; 24/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 1/5; 24/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100;, score=-82.264 total time=   1.2s\n",
    "[CV 2/5; 24/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 2/5; 24/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100;, score=-83.717 total time=   1.1s\n",
    "[CV 3/5; 24/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 3/5; 24/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100;, score=-96.055 total time=   0.9s\n",
    "[CV 4/5; 24/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 4/5; 24/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100;, score=-91.857 total time=   0.9s\n",
    "[CV 5/5; 24/216] START booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 5/5; 24/216] END booster=gbtree, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100;, score=-87.447 total time=   1.1s\n",
    "[CV 1/5; 25/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 1/5; 25/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50;, score=-36.265 total time=   0.4s\n",
    "[CV 2/5; 25/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 2/5; 25/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50;, score=-37.045 total time=   0.4s\n",
    "[CV 3/5; 25/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 3/5; 25/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50;, score=-42.823 total time=   0.4s\n",
    "[CV 4/5; 25/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 4/5; 25/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50;, score=-40.879 total time=   0.5s\n",
    "[CV 5/5; 25/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 5/5; 25/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50;, score=-38.837 total time=   0.5s\n",
    "[CV 1/5; 26/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 1/5; 26/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75;, score=-21.601 total time=   0.9s\n",
    "[CV 2/5; 26/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 2/5; 26/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75;, score=-22.118 total time=   0.9s\n",
    "[CV 3/5; 26/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 3/5; 26/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75;, score=-25.732 total time=   0.8s\n",
    "[CV 4/5; 26/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 4/5; 26/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75;, score=-24.528 total time=   0.9s\n",
    "[CV 5/5; 26/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 5/5; 26/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75;, score=-23.269 total time=   1.4s\n",
    "[CV 1/5; 27/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 1/5; 27/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100;, score=-12.750 total time=   1.5s\n",
    "[CV 2/5; 27/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 2/5; 27/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100;, score=-13.080 total time=   1.0s\n",
    "[CV 3/5; 27/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 3/5; 27/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100;, score=-15.352 total time=   0.9s\n",
    "[CV 4/5; 27/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 4/5; 27/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100;, score=-14.605 total time=   1.0s\n",
    "[CV 5/5; 27/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 5/5; 27/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100;, score=-13.825 total time=   0.9s\n",
    "[CV 1/5; 28/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 1/5; 28/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50;, score=-36.265 total time=   0.5s\n",
    "[CV 2/5; 28/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 2/5; 28/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50;, score=-37.045 total time=   0.4s\n",
    "[CV 3/5; 28/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 3/5; 28/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50;, score=-42.823 total time=   0.5s\n",
    "[CV 4/5; 28/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 4/5; 28/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50;, score=-40.879 total time=   0.5s\n",
    "[CV 5/5; 28/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 5/5; 28/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50;, score=-38.838 total time=   0.5s\n",
    "[CV 1/5; 29/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 1/5; 29/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75;, score=-21.600 total time=   0.8s\n",
    "[CV 2/5; 29/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 2/5; 29/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75;, score=-22.124 total time=   0.9s\n",
    "[CV 3/5; 29/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 3/5; 29/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75;, score=-25.725 total time=   0.9s\n",
    "[CV 4/5; 29/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 4/5; 29/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75;, score=-24.529 total time=   0.9s\n",
    "[CV 5/5; 29/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 5/5; 29/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75;, score=-23.267 total time=   1.0s\n",
    "[CV 1/5; 30/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 1/5; 30/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100;, score=-12.753 total time=   1.4s\n",
    "[CV 2/5; 30/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 2/5; 30/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100;, score=-13.085 total time=   1.6s\n",
    "[CV 3/5; 30/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 3/5; 30/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100;, score=-15.339 total time=   1.2s\n",
    "[CV 4/5; 30/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 4/5; 30/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100;, score=-14.606 total time=   1.2s\n",
    "[CV 5/5; 30/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 5/5; 30/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100;, score=-13.818 total time=   1.1s\n",
    "[CV 1/5; 31/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 1/5; 31/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50;, score=-36.265 total time=   0.7s\n",
    "[CV 2/5; 31/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 2/5; 31/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50;, score=-37.045 total time=   0.4s\n",
    "[CV 3/5; 31/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 3/5; 31/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50;, score=-42.823 total time=   0.4s\n",
    "[CV 4/5; 31/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 4/5; 31/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50;, score=-40.879 total time=   0.5s\n",
    "[CV 5/5; 31/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 5/5; 31/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50;, score=-38.838 total time=   0.4s\n",
    "[CV 1/5; 32/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 1/5; 32/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75;, score=-21.600 total time=   0.6s\n",
    "[CV 2/5; 32/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 2/5; 32/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75;, score=-22.124 total time=   0.7s\n",
    "[CV 3/5; 32/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 3/5; 32/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75;, score=-25.725 total time=   0.6s\n",
    "[CV 4/5; 32/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 4/5; 32/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75;, score=-24.529 total time=   0.7s\n",
    "[CV 5/5; 32/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 5/5; 32/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75;, score=-23.267 total time=   0.7s\n",
    "[CV 1/5; 33/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 1/5; 33/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100;, score=-12.753 total time=   1.1s\n",
    "[CV 2/5; 33/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 2/5; 33/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100;, score=-13.086 total time=   1.5s\n",
    "[CV 3/5; 33/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 3/5; 33/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100;, score=-15.339 total time=   1.5s\n",
    "[CV 4/5; 33/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 4/5; 33/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100;, score=-14.607 total time=   1.2s\n",
    "[CV 5/5; 33/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 5/5; 33/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100;, score=-13.819 total time=   1.1s\n",
    "[CV 1/5; 34/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 1/5; 34/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50;, score=-36.265 total time=   0.5s\n",
    "[CV 2/5; 34/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 2/5; 34/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50;, score=-37.045 total time=   0.5s\n",
    "[CV 3/5; 34/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 3/5; 34/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50;, score=-42.823 total time=   0.5s\n",
    "[CV 4/5; 34/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 4/5; 34/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50;, score=-40.879 total time=   0.5s\n",
    "[CV 5/5; 34/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 5/5; 34/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50;, score=-38.838 total time=   0.5s\n",
    "[CV 1/5; 35/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 1/5; 35/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75;, score=-21.600 total time=   0.8s\n",
    "[CV 2/5; 35/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 2/5; 35/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75;, score=-22.124 total time=   1.1s\n",
    "[CV 3/5; 35/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 3/5; 35/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75;, score=-25.725 total time=   1.2s\n",
    "[CV 4/5; 35/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 4/5; 35/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75;, score=-24.529 total time=   0.9s\n",
    "[CV 5/5; 35/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 5/5; 35/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75;, score=-23.267 total time=   1.0s\n",
    "[CV 1/5; 36/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 1/5; 36/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100;, score=-12.753 total time=   1.2s\n",
    "[CV 2/5; 36/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 2/5; 36/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100;, score=-13.086 total time=   2.6s\n",
    "[CV 3/5; 36/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 3/5; 36/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100;, score=-15.339 total time=   1.5s\n",
    "[CV 4/5; 36/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 4/5; 36/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100;, score=-14.607 total time=   1.2s\n",
    "[CV 5/5; 36/216] START booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 5/5; 36/216] END booster=gbtree, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100;, score=-13.818 total time=   1.4s\n",
    "[CV 1/5; 37/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 1/5; 37/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50;, score=-36.265 total time=   0.4s\n",
    "[CV 2/5; 37/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 2/5; 37/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50;, score=-37.045 total time=   0.6s\n",
    "[CV 3/5; 37/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 3/5; 37/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50;, score=-42.823 total time=   0.5s\n",
    "[CV 4/5; 37/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 4/5; 37/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50;, score=-40.879 total time=   0.5s\n",
    "[CV 5/5; 37/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 5/5; 37/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50;, score=-38.839 total time=   0.5s\n",
    "[CV 1/5; 38/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 1/5; 38/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75;, score=-21.601 total time=   0.9s\n",
    "[CV 2/5; 38/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 2/5; 38/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75;, score=-22.118 total time=   0.7s\n",
    "[CV 3/5; 38/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 3/5; 38/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75;, score=-25.732 total time=   0.8s\n",
    "[CV 4/5; 38/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 4/5; 38/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75;, score=-24.528 total time=   0.7s\n",
    "[CV 5/5; 38/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 5/5; 38/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75;, score=-23.269 total time=   0.8s\n",
    "[CV 1/5; 39/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 1/5; 39/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100;, score=-12.750 total time=   1.0s\n",
    "[CV 2/5; 39/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 2/5; 39/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100;, score=-13.080 total time=   1.2s\n",
    "[CV 3/5; 39/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 3/5; 39/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100;, score=-15.352 total time=   1.2s\n",
    "[CV 4/5; 39/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 4/5; 39/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100;, score=-14.605 total time=   1.2s\n",
    "[CV 5/5; 39/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 5/5; 39/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100;, score=-13.827 total time=   1.0s\n",
    "[CV 1/5; 40/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 1/5; 40/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50;, score=-36.265 total time=   0.5s\n",
    "[CV 2/5; 40/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 2/5; 40/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50;, score=-37.045 total time=   0.4s\n",
    "[CV 3/5; 40/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 3/5; 40/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50;, score=-42.823 total time=   0.5s\n",
    "[CV 4/5; 40/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 4/5; 40/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50;, score=-40.879 total time=   0.4s\n",
    "[CV 5/5; 40/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 5/5; 40/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50;, score=-38.838 total time=   0.5s\n",
    "[CV 1/5; 41/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 1/5; 41/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75;, score=-21.600 total time=   0.7s\n",
    "[CV 2/5; 41/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 2/5; 41/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75;, score=-22.124 total time=   0.7s\n",
    "[CV 3/5; 41/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 3/5; 41/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75;, score=-25.725 total time=   0.7s\n",
    "[CV 4/5; 41/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 4/5; 41/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75;, score=-24.529 total time=   0.7s\n",
    "[CV 5/5; 41/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 5/5; 41/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75;, score=-23.267 total time=   0.7s\n",
    "[CV 1/5; 42/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 1/5; 42/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100;, score=-12.753 total time=   1.0s\n",
    "[CV 2/5; 42/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 2/5; 42/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100;, score=-13.085 total time=   1.1s\n",
    "[CV 3/5; 42/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 3/5; 42/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100;, score=-15.339 total time=   1.0s\n",
    "[CV 4/5; 42/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 4/5; 42/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100;, score=-14.606 total time=   1.0s\n",
    "[CV 5/5; 42/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 5/5; 42/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100;, score=-13.817 total time=   1.0s\n",
    "[CV 1/5; 43/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 1/5; 43/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50;, score=-36.265 total time=   0.4s\n",
    "[CV 2/5; 43/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 2/5; 43/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50;, score=-37.045 total time=   0.4s\n",
    "[CV 3/5; 43/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 3/5; 43/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50;, score=-42.823 total time=   0.6s\n",
    "[CV 4/5; 43/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 4/5; 43/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50;, score=-40.879 total time=   0.5s\n",
    "[CV 5/5; 43/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 5/5; 43/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50;, score=-38.838 total time=   0.5s\n",
    "[CV 1/5; 44/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 1/5; 44/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75;, score=-21.600 total time=   0.7s\n",
    "[CV 2/5; 44/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 2/5; 44/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75;, score=-22.124 total time=   0.8s\n",
    "[CV 3/5; 44/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 3/5; 44/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75;, score=-25.725 total time=   0.8s\n",
    "[CV 4/5; 44/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 4/5; 44/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75;, score=-24.529 total time=   0.9s\n",
    "[CV 5/5; 44/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 5/5; 44/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75;, score=-23.267 total time=   0.9s\n",
    "[CV 1/5; 45/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 1/5; 45/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100;, score=-12.753 total time=   1.9s\n",
    "[CV 2/5; 45/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 2/5; 45/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100;, score=-13.086 total time=   1.2s\n",
    "[CV 3/5; 45/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 3/5; 45/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100;, score=-15.339 total time=   1.4s\n",
    "[CV 4/5; 45/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 4/5; 45/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100;, score=-14.607 total time=   1.3s\n",
    "[CV 5/5; 45/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 5/5; 45/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100;, score=-13.817 total time=   0.9s\n",
    "[CV 1/5; 46/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 1/5; 46/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50;, score=-36.265 total time=   0.4s\n",
    "[CV 2/5; 46/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 2/5; 46/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50;, score=-37.045 total time=   0.4s\n",
    "[CV 3/5; 46/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 3/5; 46/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50;, score=-42.823 total time=   0.4s\n",
    "[CV 4/5; 46/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 4/5; 46/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50;, score=-40.879 total time=   0.5s\n",
    "[CV 5/5; 46/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 5/5; 46/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50;, score=-38.838 total time=   0.5s\n",
    "[CV 1/5; 47/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 1/5; 47/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75;, score=-21.600 total time=   0.8s\n",
    "[CV 2/5; 47/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 2/5; 47/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75;, score=-22.124 total time=   0.8s\n",
    "[CV 3/5; 47/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 3/5; 47/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75;, score=-25.725 total time=   0.8s\n",
    "[CV 4/5; 47/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 4/5; 47/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75;, score=-24.529 total time=   0.8s\n",
    "[CV 5/5; 47/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 5/5; 47/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75;, score=-23.267 total time=   1.2s\n",
    "[CV 1/5; 48/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 1/5; 48/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100;, score=-12.753 total time=   1.0s\n",
    "[CV 2/5; 48/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 2/5; 48/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100;, score=-13.086 total time=   1.3s\n",
    "[CV 3/5; 48/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 3/5; 48/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100;, score=-15.339 total time=   1.2s\n",
    "[CV 4/5; 48/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 4/5; 48/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100;, score=-14.607 total time=   1.4s\n",
    "[CV 5/5; 48/216] START booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 5/5; 48/216] END booster=gbtree, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100;, score=-13.817 total time=   1.2s\n",
    "[CV 1/5; 49/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 1/5; 49/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50;, score=0.843 total time=   0.5s\n",
    "[CV 2/5; 49/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 2/5; 49/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50;, score=0.838 total time=   0.6s\n",
    "[CV 3/5; 49/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 3/5; 49/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50;, score=0.837 total time=   0.6s\n",
    "[CV 4/5; 49/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 4/5; 49/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50;, score=0.833 total time=   0.7s\n",
    "[CV 5/5; 49/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 5/5; 49/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50;, score=0.842 total time=   0.7s\n",
    "[CV 1/5; 50/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 1/5; 50/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75;, score=0.866 total time=   0.9s\n",
    "[CV 2/5; 50/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 2/5; 50/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75;, score=0.855 total time=   1.1s\n",
    "[CV 3/5; 50/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 3/5; 50/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75;, score=0.869 total time=   1.0s\n",
    "[CV 4/5; 50/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 4/5; 50/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75;, score=0.857 total time=   0.8s\n",
    "[CV 5/5; 50/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 5/5; 50/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75;, score=0.868 total time=   0.8s\n",
    "[CV 1/5; 51/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 1/5; 51/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100;, score=0.879 total time=   1.2s\n",
    "[CV 2/5; 51/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 2/5; 51/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100;, score=0.869 total time=   1.1s\n",
    "[CV 3/5; 51/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 3/5; 51/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100;, score=0.883 total time=   1.2s\n",
    "[CV 4/5; 51/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 4/5; 51/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100;, score=0.872 total time=   1.1s\n",
    "[CV 5/5; 51/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 5/5; 51/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100;, score=0.882 total time=   1.0s\n",
    "[CV 1/5; 52/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 1/5; 52/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50;, score=0.875 total time=   0.7s\n",
    "[CV 2/5; 52/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 2/5; 52/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50;, score=0.872 total time=   0.9s\n",
    "[CV 3/5; 52/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 3/5; 52/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50;, score=0.879 total time=   1.0s\n",
    "[CV 4/5; 52/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 4/5; 52/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50;, score=0.877 total time=   0.8s\n",
    "[CV 5/5; 52/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 5/5; 52/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50;, score=0.875 total time=   0.8s\n",
    "[CV 1/5; 53/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 1/5; 53/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75;, score=0.895 total time=   1.9s\n",
    "[CV 2/5; 53/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 2/5; 53/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75;, score=0.888 total time=   1.4s\n",
    "[CV 3/5; 53/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 3/5; 53/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75;, score=0.902 total time=   1.4s\n",
    "[CV 4/5; 53/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 4/5; 53/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75;, score=0.898 total time=   1.3s\n",
    "[CV 5/5; 53/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 5/5; 53/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75;, score=0.898 total time=   1.4s\n",
    "[CV 1/5; 54/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 1/5; 54/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100;, score=0.907 total time=   1.8s\n",
    "[CV 2/5; 54/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 2/5; 54/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100;, score=0.898 total time=   1.7s\n",
    "[CV 3/5; 54/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 3/5; 54/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100;, score=0.910 total time=   2.1s\n",
    "[CV 4/5; 54/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 4/5; 54/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100;, score=0.906 total time=   1.8s\n",
    "[CV 5/5; 54/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 5/5; 54/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100;, score=0.904 total time=   2.6s\n",
    "[CV 1/5; 55/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 1/5; 55/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50;, score=0.889 total time=   1.5s\n",
    "[CV 2/5; 55/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 2/5; 55/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50;, score=0.889 total time=   1.2s\n",
    "[CV 3/5; 55/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 3/5; 55/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50;, score=0.882 total time=   1.3s\n",
    "[CV 4/5; 55/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 4/5; 55/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50;, score=0.890 total time=   1.3s\n",
    "[CV 5/5; 55/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 5/5; 55/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50;, score=0.891 total time=   1.0s\n",
    "[CV 1/5; 56/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 1/5; 56/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75;, score=0.904 total time=   1.7s\n",
    "[CV 2/5; 56/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 2/5; 56/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75;, score=0.903 total time=   1.8s\n",
    "[CV 3/5; 56/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 3/5; 56/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75;, score=0.904 total time=   1.8s\n",
    "[CV 4/5; 56/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 4/5; 56/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75;, score=0.908 total time=   2.8s\n",
    "[CV 5/5; 56/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 5/5; 56/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75;, score=0.909 total time=   2.2s\n",
    "[CV 1/5; 57/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 1/5; 57/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100;, score=0.910 total time=   2.4s\n",
    "[CV 2/5; 57/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 2/5; 57/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100;, score=0.909 total time=   2.4s\n",
    "[CV 3/5; 57/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 3/5; 57/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100;, score=0.911 total time=   2.6s\n",
    "[CV 4/5; 57/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 4/5; 57/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100;, score=0.914 total time=   2.4s\n",
    "[CV 5/5; 57/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 5/5; 57/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100;, score=0.914 total time=   2.7s\n",
    "[CV 1/5; 58/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 1/5; 58/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50;, score=0.896 total time=   1.6s\n",
    "[CV 2/5; 58/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 2/5; 58/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50;, score=0.894 total time=   1.3s\n",
    "[CV 3/5; 58/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 3/5; 58/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50;, score=0.889 total time=   1.5s\n",
    "[CV 4/5; 58/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 4/5; 58/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50;, score=0.895 total time=   1.4s\n",
    "[CV 5/5; 58/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 5/5; 58/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50;, score=0.896 total time=   1.5s\n",
    "[CV 1/5; 59/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 1/5; 59/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75;, score=0.909 total time=   2.0s\n",
    "[CV 2/5; 59/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 2/5; 59/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75;, score=0.906 total time=   2.0s\n",
    "[CV 3/5; 59/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 3/5; 59/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75;, score=0.908 total time=   1.9s\n",
    "[CV 4/5; 59/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 4/5; 59/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75;, score=0.912 total time=   2.3s\n",
    "[CV 5/5; 59/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 5/5; 59/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75;, score=0.912 total time=   2.0s\n",
    "[CV 1/5; 60/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 1/5; 60/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100;, score=0.912 total time=   2.7s\n",
    "[CV 2/5; 60/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 2/5; 60/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100;, score=0.909 total time=   2.9s\n",
    "[CV 3/5; 60/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 3/5; 60/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100;, score=0.912 total time=   2.7s\n",
    "[CV 4/5; 60/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 4/5; 60/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100;, score=0.915 total time=   2.7s\n",
    "[CV 5/5; 60/216] START booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 5/5; 60/216] END booster=gbtree, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100;, score=0.915 total time=   3.1s\n",
    "[CV 1/5; 61/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 1/5; 61/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50;, score=0.844 total time=   0.5s\n",
    "[CV 2/5; 61/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 2/5; 61/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50;, score=0.838 total time=   0.5s\n",
    "[CV 3/5; 61/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 3/5; 61/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50;, score=0.837 total time=   0.5s\n",
    "[CV 4/5; 61/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 4/5; 61/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50;, score=0.833 total time=   0.5s\n",
    "[CV 5/5; 61/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 5/5; 61/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50;, score=0.842 total time=   0.5s\n",
    "[CV 1/5; 62/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 1/5; 62/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75;, score=0.865 total time=   0.7s\n",
    "[CV 2/5; 62/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 2/5; 62/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75;, score=0.854 total time=   0.7s\n",
    "[CV 3/5; 62/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 3/5; 62/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75;, score=0.868 total time=   0.8s\n",
    "[CV 4/5; 62/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 4/5; 62/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75;, score=0.858 total time=   0.7s\n",
    "[CV 5/5; 62/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 5/5; 62/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75;, score=0.868 total time=   0.7s\n",
    "[CV 1/5; 63/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 1/5; 63/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100;, score=0.879 total time=   1.0s\n",
    "[CV 2/5; 63/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 2/5; 63/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100;, score=0.867 total time=   1.0s\n",
    "[CV 3/5; 63/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 3/5; 63/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100;, score=0.884 total time=   1.2s\n",
    "[CV 4/5; 63/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 4/5; 63/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100;, score=0.871 total time=   1.1s\n",
    "[CV 5/5; 63/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 5/5; 63/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100;, score=0.880 total time=   1.0s\n",
    "[CV 1/5; 64/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 1/5; 64/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50;, score=0.878 total time=   0.7s\n",
    "[CV 2/5; 64/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 2/5; 64/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50;, score=0.874 total time=   0.9s\n",
    "[CV 3/5; 64/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 3/5; 64/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50;, score=0.876 total time=   0.9s\n",
    "[CV 4/5; 64/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 4/5; 64/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50;, score=0.876 total time=   0.8s\n",
    "[CV 5/5; 64/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 5/5; 64/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50;, score=0.877 total time=   0.8s\n",
    "[CV 1/5; 65/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 1/5; 65/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75;, score=0.897 total time=   1.1s\n",
    "[CV 2/5; 65/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 2/5; 65/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75;, score=0.890 total time=   1.1s\n",
    "[CV 3/5; 65/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 3/5; 65/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75;, score=0.901 total time=   1.2s\n",
    "[CV 4/5; 65/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 4/5; 65/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75;, score=0.897 total time=   1.1s\n",
    "[CV 5/5; 65/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 5/5; 65/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75;, score=0.898 total time=   1.1s\n",
    "[CV 1/5; 66/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 1/5; 66/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100;, score=0.905 total time=   1.5s\n",
    "[CV 2/5; 66/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 2/5; 66/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100;, score=0.899 total time=   1.5s\n",
    "[CV 3/5; 66/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 3/5; 66/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100;, score=0.910 total time=   1.5s\n",
    "[CV 4/5; 66/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 4/5; 66/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100;, score=0.904 total time=   1.5s\n",
    "[CV 5/5; 66/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 5/5; 66/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100;, score=0.907 total time=   2.3s\n",
    "[CV 1/5; 67/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 1/5; 67/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50;, score=0.889 total time=   0.9s\n",
    "[CV 2/5; 67/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 2/5; 67/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50;, score=0.886 total time=   0.9s\n",
    "[CV 3/5; 67/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 3/5; 67/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50;, score=0.892 total time=   0.9s\n",
    "[CV 4/5; 67/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 4/5; 67/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50;, score=0.892 total time=   0.9s\n",
    "[CV 5/5; 67/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 5/5; 67/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50;, score=0.893 total time=   1.0s\n",
    "[CV 1/5; 68/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 1/5; 68/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75;, score=0.903 total time=   1.5s\n",
    "[CV 2/5; 68/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 2/5; 68/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75;, score=0.902 total time=   1.5s\n",
    "[CV 3/5; 68/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 3/5; 68/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75;, score=0.910 total time=   1.5s\n",
    "[CV 4/5; 68/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 4/5; 68/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75;, score=0.908 total time=   1.5s\n",
    "[CV 5/5; 68/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 5/5; 68/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75;, score=0.911 total time=   1.5s\n",
    "[CV 1/5; 69/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 1/5; 69/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100;, score=0.908 total time=   2.4s\n",
    "[CV 2/5; 69/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 2/5; 69/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100;, score=0.908 total time=   2.1s\n",
    "[CV 3/5; 69/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 3/5; 69/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100;, score=0.916 total time=   2.2s\n",
    "[CV 4/5; 69/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 4/5; 69/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100;, score=0.912 total time=   2.4s\n",
    "[CV 5/5; 69/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 5/5; 69/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100;, score=0.917 total time=   2.6s\n",
    "[CV 1/5; 70/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 1/5; 70/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50;, score=0.894 total time=   1.5s\n",
    "[CV 2/5; 70/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 2/5; 70/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50;, score=0.892 total time=   1.6s\n",
    "[CV 3/5; 70/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 3/5; 70/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50;, score=0.889 total time=   1.9s\n",
    "[CV 4/5; 70/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 4/5; 70/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50;, score=0.891 total time=   1.7s\n",
    "[CV 5/5; 70/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 5/5; 70/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50;, score=0.896 total time=   1.4s\n",
    "[CV 1/5; 71/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 1/5; 71/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75;, score=0.909 total time=   2.7s\n",
    "[CV 2/5; 71/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 2/5; 71/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75;, score=0.904 total time=   3.1s\n",
    "[CV 3/5; 71/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 3/5; 71/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75;, score=0.906 total time=   2.6s\n",
    "[CV 4/5; 71/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 4/5; 71/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75;, score=0.907 total time=   2.5s\n",
    "[CV 5/5; 71/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 5/5; 71/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75;, score=0.913 total time=   2.4s\n",
    "[CV 1/5; 72/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 1/5; 72/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100;, score=0.911 total time=   2.8s\n",
    "[CV 2/5; 72/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 2/5; 72/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100;, score=0.907 total time=   3.1s\n",
    "[CV 3/5; 72/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 3/5; 72/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100;, score=0.910 total time=   3.6s\n",
    "[CV 4/5; 72/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 4/5; 72/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100;, score=0.910 total time=   3.2s\n",
    "[CV 5/5; 72/216] START booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 5/5; 72/216] END booster=gbtree, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100;, score=0.916 total time=   4.1s\n",
    "[CV 1/5; 73/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 1/5; 73/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50;, score=-91.031 total time=   1.3s\n",
    "[CV 2/5; 73/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 2/5; 73/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50;, score=-92.596 total time=   1.0s\n",
    "[CV 3/5; 73/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 3/5; 73/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50;, score=-106.168 total time=   1.0s\n",
    "[CV 4/5; 73/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 4/5; 73/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50;, score=-101.546 total time=   0.9s\n",
    "[CV 5/5; 73/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 5/5; 73/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50;, score=-96.690 total time=   1.3s\n",
    "[CV 1/5; 74/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 1/5; 74/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75;, score=-86.537 total time=   2.1s\n",
    "[CV 2/5; 74/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 2/5; 74/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75;, score=-88.045 total time=   2.0s\n",
    "[CV 3/5; 74/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 3/5; 74/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75;, score=-100.984 total time=   2.1s\n",
    "[CV 4/5; 74/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 4/5; 74/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75;, score=-96.581 total time=   2.3s\n",
    "[CV 5/5; 74/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 5/5; 74/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75;, score=-91.953 total time=   1.8s\n",
    "[CV 1/5; 75/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 1/5; 75/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100;, score=-82.264 total time=   2.9s\n",
    "[CV 2/5; 75/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 2/5; 75/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100;, score=-83.717 total time=   3.2s\n",
    "[CV 3/5; 75/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 3/5; 75/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100;, score=-96.055 total time=   3.4s\n",
    "[CV 4/5; 75/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 4/5; 75/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100;, score=-91.857 total time=   4.1s\n",
    "[CV 5/5; 75/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 5/5; 75/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100;, score=-87.447 total time=   3.6s\n",
    "[CV 1/5; 76/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 1/5; 76/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50;, score=-91.031 total time=   0.9s\n",
    "[CV 2/5; 76/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 2/5; 76/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50;, score=-92.596 total time=   1.0s\n",
    "[CV 3/5; 76/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 3/5; 76/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50;, score=-106.168 total time=   1.3s\n",
    "[CV 4/5; 76/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 4/5; 76/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50;, score=-101.546 total time=   1.2s\n",
    "[CV 5/5; 76/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 5/5; 76/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50;, score=-96.690 total time=   1.0s\n",
    "[CV 1/5; 77/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 1/5; 77/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75;, score=-86.537 total time=   2.2s\n",
    "[CV 2/5; 77/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 2/5; 77/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75;, score=-88.045 total time=   2.4s\n",
    "[CV 3/5; 77/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 3/5; 77/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75;, score=-100.984 total time=   2.4s\n",
    "[CV 4/5; 77/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 4/5; 77/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75;, score=-96.581 total time=   2.0s\n",
    "[CV 5/5; 77/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 5/5; 77/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75;, score=-91.953 total time=   2.2s\n",
    "[CV 1/5; 78/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 1/5; 78/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100;, score=-82.264 total time=   3.4s\n",
    "[CV 2/5; 78/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 2/5; 78/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100;, score=-83.717 total time=   3.7s\n",
    "[CV 3/5; 78/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 3/5; 78/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100;, score=-96.055 total time=   4.2s\n",
    "[CV 4/5; 78/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 4/5; 78/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100;, score=-91.857 total time=   3.1s\n",
    "[CV 5/5; 78/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 5/5; 78/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100;, score=-87.447 total time=   2.6s\n",
    "[CV 1/5; 79/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 1/5; 79/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50;, score=-91.031 total time=   0.8s\n",
    "[CV 2/5; 79/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 2/5; 79/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50;, score=-92.596 total time=   0.8s\n",
    "[CV 3/5; 79/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 3/5; 79/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50;, score=-106.168 total time=   0.8s\n",
    "[CV 4/5; 79/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 4/5; 79/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50;, score=-101.546 total time=   0.8s\n",
    "[CV 5/5; 79/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 5/5; 79/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50;, score=-96.690 total time=   0.8s\n",
    "[CV 1/5; 80/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 1/5; 80/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75;, score=-86.537 total time=   1.5s\n",
    "[CV 2/5; 80/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 2/5; 80/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75;, score=-88.045 total time=   2.0s\n",
    "[CV 3/5; 80/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 3/5; 80/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75;, score=-100.984 total time=   1.6s\n",
    "[CV 4/5; 80/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 4/5; 80/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75;, score=-96.581 total time=   1.5s\n",
    "[CV 5/5; 80/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 5/5; 80/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75;, score=-91.953 total time=   2.1s\n",
    "[CV 1/5; 81/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 1/5; 81/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100;, score=-82.264 total time=   3.5s\n",
    "[CV 2/5; 81/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 2/5; 81/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100;, score=-83.717 total time=   3.2s\n",
    "[CV 3/5; 81/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 3/5; 81/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100;, score=-96.055 total time=   4.0s\n",
    "[CV 4/5; 81/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 4/5; 81/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100;, score=-91.857 total time=   3.7s\n",
    "[CV 5/5; 81/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 5/5; 81/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100;, score=-87.447 total time=   3.1s\n",
    "[CV 1/5; 82/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 1/5; 82/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50;, score=-91.031 total time=   0.9s\n",
    "[CV 2/5; 82/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 2/5; 82/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50;, score=-92.596 total time=   1.0s\n",
    "[CV 3/5; 82/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 3/5; 82/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50;, score=-106.168 total time=   0.9s\n",
    "[CV 4/5; 82/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 4/5; 82/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50;, score=-101.546 total time=   1.3s\n",
    "[CV 5/5; 82/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 5/5; 82/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50;, score=-96.690 total time=   1.1s\n",
    "[CV 1/5; 83/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 1/5; 83/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75;, score=-86.537 total time=   2.3s\n",
    "[CV 2/5; 83/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 2/5; 83/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75;, score=-88.045 total time=   2.2s\n",
    "[CV 3/5; 83/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 3/5; 83/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75;, score=-100.984 total time=   2.4s\n",
    "[CV 4/5; 83/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 4/5; 83/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75;, score=-96.581 total time=   1.8s\n",
    "[CV 5/5; 83/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 5/5; 83/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75;, score=-91.953 total time=   1.8s\n",
    "[CV 1/5; 84/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 1/5; 84/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100;, score=-82.264 total time=   3.3s\n",
    "[CV 2/5; 84/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 2/5; 84/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100;, score=-83.717 total time=   4.4s\n",
    "[CV 3/5; 84/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 3/5; 84/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100;, score=-96.055 total time=   3.9s\n",
    "[CV 4/5; 84/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 4/5; 84/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100;, score=-91.857 total time=   3.2s\n",
    "[CV 5/5; 84/216] START booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 5/5; 84/216] END booster=dart, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100;, score=-87.447 total time=   2.9s\n",
    "[CV 1/5; 85/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 1/5; 85/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50;, score=-91.031 total time=   1.2s\n",
    "[CV 2/5; 85/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 2/5; 85/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50;, score=-92.596 total time=   1.0s\n",
    "[CV 3/5; 85/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 3/5; 85/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50;, score=-106.168 total time=   0.9s\n",
    "[CV 4/5; 85/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 4/5; 85/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50;, score=-101.546 total time=   1.5s\n",
    "[CV 5/5; 85/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 5/5; 85/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50;, score=-96.690 total time=   1.5s\n",
    "[CV 1/5; 86/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 1/5; 86/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75;, score=-86.537 total time=   2.1s\n",
    "[CV 2/5; 86/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 2/5; 86/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75;, score=-88.045 total time=   2.3s\n",
    "[CV 3/5; 86/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 3/5; 86/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75;, score=-100.984 total time=   1.9s\n",
    "[CV 4/5; 86/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 4/5; 86/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75;, score=-96.581 total time=   1.8s\n",
    "[CV 5/5; 86/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 5/5; 86/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75;, score=-91.953 total time=   2.5s\n",
    "[CV 1/5; 87/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 1/5; 87/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100;, score=-82.264 total time=   4.4s\n",
    "[CV 2/5; 87/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 2/5; 87/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100;, score=-83.717 total time=   3.5s\n",
    "[CV 3/5; 87/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 3/5; 87/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100;, score=-96.055 total time=   4.0s\n",
    "[CV 4/5; 87/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 4/5; 87/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100;, score=-91.857 total time=   3.5s\n",
    "[CV 5/5; 87/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 5/5; 87/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100;, score=-87.447 total time=   4.5s\n",
    "[CV 1/5; 88/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 1/5; 88/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50;, score=-91.031 total time=   1.2s\n",
    "[CV 2/5; 88/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 2/5; 88/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50;, score=-92.596 total time=   0.9s\n",
    "[CV 3/5; 88/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 3/5; 88/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50;, score=-106.168 total time=   0.9s\n",
    "[CV 4/5; 88/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 4/5; 88/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50;, score=-101.546 total time=   0.9s\n",
    "[CV 5/5; 88/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 5/5; 88/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50;, score=-96.690 total time=   1.1s\n",
    "[CV 1/5; 89/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 1/5; 89/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75;, score=-86.537 total time=   2.1s\n",
    "[CV 2/5; 89/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 2/5; 89/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75;, score=-88.045 total time=   2.4s\n",
    "[CV 3/5; 89/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 3/5; 89/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75;, score=-100.984 total time=   2.4s\n",
    "[CV 4/5; 89/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 4/5; 89/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75;, score=-96.581 total time=   3.1s\n",
    "[CV 5/5; 89/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 5/5; 89/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75;, score=-91.953 total time=   2.0s\n",
    "[CV 1/5; 90/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 1/5; 90/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100;, score=-82.264 total time=   3.6s\n",
    "[CV 2/5; 90/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 2/5; 90/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100;, score=-83.717 total time=   4.2s\n",
    "[CV 3/5; 90/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 3/5; 90/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100;, score=-96.055 total time=   3.5s\n",
    "[CV 4/5; 90/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 4/5; 90/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100;, score=-91.857 total time=   3.6s\n",
    "[CV 5/5; 90/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 5/5; 90/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100;, score=-87.447 total time=   3.9s\n",
    "[CV 1/5; 91/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 1/5; 91/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50;, score=-91.031 total time=   1.4s\n",
    "[CV 2/5; 91/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 2/5; 91/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50;, score=-92.596 total time=   1.1s\n",
    "[CV 3/5; 91/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 3/5; 91/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50;, score=-106.168 total time=   0.9s\n",
    "[CV 4/5; 91/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 4/5; 91/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50;, score=-101.546 total time=   0.9s\n",
    "[CV 5/5; 91/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 5/5; 91/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50;, score=-96.690 total time=   0.9s\n",
    "[CV 1/5; 92/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 1/5; 92/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75;, score=-86.537 total time=   1.8s\n",
    "[CV 2/5; 92/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 2/5; 92/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75;, score=-88.045 total time=   2.2s\n",
    "[CV 3/5; 92/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 3/5; 92/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75;, score=-100.984 total time=   1.8s\n",
    "[CV 4/5; 92/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 4/5; 92/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75;, score=-96.581 total time=   1.9s\n",
    "[CV 5/5; 92/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 5/5; 92/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75;, score=-91.953 total time=   1.8s\n",
    "[CV 1/5; 93/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 1/5; 93/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100;, score=-82.264 total time=   2.9s\n",
    "[CV 2/5; 93/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 2/5; 93/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100;, score=-83.717 total time=   3.0s\n",
    "[CV 3/5; 93/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 3/5; 93/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100;, score=-96.055 total time=   3.2s\n",
    "[CV 4/5; 93/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 4/5; 93/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100;, score=-91.857 total time=   3.2s\n",
    "[CV 5/5; 93/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 5/5; 93/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100;, score=-87.447 total time=   3.5s\n",
    "[CV 1/5; 94/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 1/5; 94/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50;, score=-91.031 total time=   1.4s\n",
    "[CV 2/5; 94/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 2/5; 94/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50;, score=-92.596 total time=   1.0s\n",
    "[CV 3/5; 94/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 3/5; 94/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50;, score=-106.168 total time=   1.0s\n",
    "[CV 4/5; 94/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 4/5; 94/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50;, score=-101.546 total time=   1.0s\n",
    "[CV 5/5; 94/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 5/5; 94/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50;, score=-96.690 total time=   1.0s\n",
    "[CV 1/5; 95/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 1/5; 95/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75;, score=-86.537 total time=   2.3s\n",
    "[CV 2/5; 95/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 2/5; 95/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75;, score=-88.045 total time=   2.6s\n",
    "[CV 3/5; 95/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 3/5; 95/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75;, score=-100.984 total time=   1.8s\n",
    "[CV 4/5; 95/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 4/5; 95/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75;, score=-96.581 total time=   2.2s\n",
    "[CV 5/5; 95/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 5/5; 95/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75;, score=-91.953 total time=   2.4s\n",
    "[CV 1/5; 96/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 1/5; 96/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100;, score=-82.264 total time=   4.0s\n",
    "[CV 2/5; 96/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 2/5; 96/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100;, score=-83.717 total time=   4.3s\n",
    "[CV 3/5; 96/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 3/5; 96/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100;, score=-96.055 total time=   3.3s\n",
    "[CV 4/5; 96/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 4/5; 96/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100;, score=-91.857 total time=   3.6s\n",
    "[CV 5/5; 96/216] START booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 5/5; 96/216] END booster=dart, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100;, score=-87.447 total time=   3.9s\n",
    "[CV 1/5; 97/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 1/5; 97/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50;, score=-36.265 total time=   1.1s\n",
    "[CV 2/5; 97/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 2/5; 97/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50;, score=-37.045 total time=   1.0s\n",
    "[CV 3/5; 97/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 3/5; 97/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50;, score=-42.823 total time=   1.1s\n",
    "[CV 4/5; 97/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 4/5; 97/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50;, score=-40.879 total time=   1.3s\n",
    "[CV 5/5; 97/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 5/5; 97/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50;, score=-38.837 total time=   0.8s\n",
    "[CV 1/5; 98/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 1/5; 98/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75;, score=-21.601 total time=   2.1s\n",
    "[CV 2/5; 98/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 2/5; 98/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75;, score=-22.118 total time=   2.2s\n",
    "[CV 3/5; 98/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 3/5; 98/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75;, score=-25.732 total time=   2.7s\n",
    "[CV 4/5; 98/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 4/5; 98/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75;, score=-24.528 total time=   1.8s\n",
    "[CV 5/5; 98/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 5/5; 98/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75;, score=-23.269 total time=   1.7s\n",
    "[CV 1/5; 99/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 1/5; 99/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100;, score=-12.750 total time=   4.1s\n",
    "[CV 2/5; 99/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 2/5; 99/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100;, score=-13.080 total time=   3.0s\n",
    "[CV 3/5; 99/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 3/5; 99/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100;, score=-15.352 total time=   3.1s\n",
    "[CV 4/5; 99/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 4/5; 99/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100;, score=-14.605 total time=   3.9s\n",
    "[CV 5/5; 99/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 5/5; 99/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100;, score=-13.825 total time=   4.3s\n",
    "[CV 1/5; 100/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 1/5; 100/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50;, score=-36.265 total time=   1.4s\n",
    "[CV 2/5; 100/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 2/5; 100/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50;, score=-37.045 total time=   1.2s\n",
    "[CV 3/5; 100/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 3/5; 100/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50;, score=-42.823 total time=   1.2s\n",
    "[CV 4/5; 100/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 4/5; 100/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50;, score=-40.879 total time=   0.9s\n",
    "[CV 5/5; 100/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 5/5; 100/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50;, score=-38.838 total time=   1.0s\n",
    "[CV 1/5; 101/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 1/5; 101/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75;, score=-21.600 total time=   2.4s\n",
    "[CV 2/5; 101/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 2/5; 101/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75;, score=-22.124 total time=   2.5s\n",
    "[CV 3/5; 101/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 3/5; 101/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75;, score=-25.725 total time=   2.3s\n",
    "[CV 4/5; 101/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 4/5; 101/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75;, score=-24.529 total time=   3.7s\n",
    "[CV 5/5; 101/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 5/5; 101/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75;, score=-23.267 total time=   2.6s\n",
    "[CV 1/5; 102/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 1/5; 102/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100;, score=-12.753 total time=   3.8s\n",
    "[CV 2/5; 102/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 2/5; 102/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100;, score=-13.085 total time=   3.8s\n",
    "[CV 3/5; 102/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 3/5; 102/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100;, score=-15.339 total time=   4.4s\n",
    "[CV 4/5; 102/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 4/5; 102/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100;, score=-14.606 total time=   4.0s\n",
    "[CV 5/5; 102/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 5/5; 102/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100;, score=-13.818 total time=   4.0s\n",
    "[CV 1/5; 103/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 1/5; 103/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50;, score=-36.265 total time=   1.0s\n",
    "[CV 2/5; 103/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 2/5; 103/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50;, score=-37.045 total time=   1.6s\n",
    "[CV 3/5; 103/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 3/5; 103/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50;, score=-42.823 total time=   1.1s\n",
    "[CV 4/5; 103/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 4/5; 103/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50;, score=-40.879 total time=   1.0s\n",
    "[CV 5/5; 103/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 5/5; 103/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50;, score=-38.838 total time=   1.4s\n",
    "[CV 1/5; 104/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 1/5; 104/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75;, score=-21.600 total time=   2.7s\n",
    "[CV 2/5; 104/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 2/5; 104/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75;, score=-22.124 total time=   2.2s\n",
    "[CV 3/5; 104/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 3/5; 104/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75;, score=-25.725 total time=   2.2s\n",
    "[CV 4/5; 104/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 4/5; 104/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75;, score=-24.529 total time=   3.0s\n",
    "[CV 5/5; 104/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 5/5; 104/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75;, score=-23.267 total time=   2.4s\n",
    "[CV 1/5; 105/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 1/5; 105/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100;, score=-12.753 total time=   4.1s\n",
    "[CV 2/5; 105/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 2/5; 105/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100;, score=-13.086 total time=   3.6s\n",
    "[CV 3/5; 105/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 3/5; 105/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100;, score=-15.339 total time=   3.9s\n",
    "[CV 4/5; 105/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 4/5; 105/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100;, score=-14.607 total time=   4.0s\n",
    "[CV 5/5; 105/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 5/5; 105/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100;, score=-13.819 total time=   5.4s\n",
    "[CV 1/5; 106/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 1/5; 106/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50;, score=-36.265 total time=   1.2s\n",
    "[CV 2/5; 106/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 2/5; 106/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50;, score=-37.045 total time=   1.1s\n",
    "[CV 3/5; 106/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 3/5; 106/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50;, score=-42.823 total time=   1.0s\n",
    "[CV 4/5; 106/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 4/5; 106/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50;, score=-40.879 total time=   1.2s\n",
    "[CV 5/5; 106/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 5/5; 106/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50;, score=-38.838 total time=   1.0s\n",
    "[CV 1/5; 107/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 1/5; 107/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75;, score=-21.600 total time=   2.0s\n",
    "[CV 2/5; 107/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 2/5; 107/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75;, score=-22.124 total time=   2.1s\n",
    "[CV 3/5; 107/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 3/5; 107/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75;, score=-25.725 total time=   2.6s\n",
    "[CV 4/5; 107/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 4/5; 107/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75;, score=-24.529 total time=   3.8s\n",
    "[CV 5/5; 107/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 5/5; 107/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75;, score=-23.267 total time=   2.0s\n",
    "[CV 1/5; 108/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 1/5; 108/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100;, score=-12.753 total time=   4.1s\n",
    "[CV 2/5; 108/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 2/5; 108/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100;, score=-13.086 total time=   4.0s\n",
    "[CV 3/5; 108/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 3/5; 108/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100;, score=-15.339 total time=   4.3s\n",
    "[CV 4/5; 108/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 4/5; 108/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100;, score=-14.607 total time=   4.1s\n",
    "[CV 5/5; 108/216] START booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 5/5; 108/216] END booster=dart, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100;, score=-13.818 total time=   4.2s\n",
    "[CV 1/5; 109/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 1/5; 109/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50;, score=-36.265 total time=   1.0s\n",
    "[CV 2/5; 109/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 2/5; 109/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50;, score=-37.045 total time=   1.0s\n",
    "[CV 3/5; 109/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 3/5; 109/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50;, score=-42.823 total time=   0.9s\n",
    "[CV 4/5; 109/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 4/5; 109/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50;, score=-40.879 total time=   1.2s\n",
    "[CV 5/5; 109/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 5/5; 109/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50;, score=-38.839 total time=   1.1s\n",
    "[CV 1/5; 110/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 1/5; 110/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75;, score=-21.601 total time=   2.3s\n",
    "[CV 2/5; 110/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 2/5; 110/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75;, score=-22.118 total time=   2.7s\n",
    "[CV 3/5; 110/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 3/5; 110/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75;, score=-25.732 total time=   2.4s\n",
    "[CV 4/5; 110/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 4/5; 110/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75;, score=-24.528 total time=   3.1s\n",
    "[CV 5/5; 110/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 5/5; 110/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75;, score=-23.269 total time=   2.6s\n",
    "[CV 1/5; 111/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 1/5; 111/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100;, score=-12.750 total time=   4.3s\n",
    "[CV 2/5; 111/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 2/5; 111/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100;, score=-13.080 total time=   3.8s\n",
    "[CV 3/5; 111/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 3/5; 111/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100;, score=-15.352 total time=   4.1s\n",
    "[CV 4/5; 111/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 4/5; 111/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100;, score=-14.605 total time=   4.3s\n",
    "[CV 5/5; 111/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 5/5; 111/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100;, score=-13.827 total time=   5.1s\n",
    "[CV 1/5; 112/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 1/5; 112/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50;, score=-36.265 total time=   1.3s\n",
    "[CV 2/5; 112/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 2/5; 112/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50;, score=-37.045 total time=   1.3s\n",
    "[CV 3/5; 112/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 3/5; 112/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50;, score=-42.823 total time=   1.3s\n",
    "[CV 4/5; 112/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 4/5; 112/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50;, score=-40.879 total time=   1.3s\n",
    "[CV 5/5; 112/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 5/5; 112/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50;, score=-38.838 total time=   1.3s\n",
    "[CV 1/5; 113/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 1/5; 113/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75;, score=-21.600 total time=   2.4s\n",
    "[CV 2/5; 113/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 2/5; 113/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75;, score=-22.124 total time=   2.3s\n",
    "[CV 3/5; 113/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 3/5; 113/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75;, score=-25.725 total time=   3.0s\n",
    "[CV 4/5; 113/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 4/5; 113/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75;, score=-24.529 total time=   2.8s\n",
    "[CV 5/5; 113/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 5/5; 113/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75;, score=-23.267 total time=   2.4s\n",
    "[CV 1/5; 114/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 1/5; 114/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100;, score=-12.753 total time=   3.6s\n",
    "[CV 2/5; 114/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 2/5; 114/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100;, score=-13.085 total time=   3.7s\n",
    "[CV 3/5; 114/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 3/5; 114/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100;, score=-15.339 total time=   4.3s\n",
    "[CV 4/5; 114/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 4/5; 114/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100;, score=-14.606 total time=   4.0s\n",
    "[CV 5/5; 114/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 5/5; 114/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100;, score=-13.817 total time=   3.6s\n",
    "[CV 1/5; 115/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 1/5; 115/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50;, score=-36.265 total time=   1.0s\n",
    "[CV 2/5; 115/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 2/5; 115/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50;, score=-37.045 total time=   1.0s\n",
    "[CV 3/5; 115/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 3/5; 115/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50;, score=-42.823 total time=   1.1s\n",
    "[CV 4/5; 115/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 4/5; 115/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50;, score=-40.879 total time=   1.4s\n",
    "[CV 5/5; 115/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 5/5; 115/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50;, score=-38.838 total time=   1.1s\n",
    "[CV 1/5; 116/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 1/5; 116/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75;, score=-21.600 total time=   2.0s\n",
    "[CV 2/5; 116/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 2/5; 116/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75;, score=-22.124 total time=   2.4s\n",
    "[CV 3/5; 116/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 3/5; 116/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75;, score=-25.725 total time=   2.4s\n",
    "[CV 4/5; 116/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 4/5; 116/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75;, score=-24.529 total time=   2.5s\n",
    "[CV 5/5; 116/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 5/5; 116/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75;, score=-23.267 total time=   3.0s\n",
    "[CV 1/5; 117/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 1/5; 117/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100;, score=-12.753 total time=   4.1s\n",
    "[CV 2/5; 117/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 2/5; 117/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100;, score=-13.086 total time=   3.7s\n",
    "[CV 3/5; 117/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 3/5; 117/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100;, score=-15.339 total time=   3.8s\n",
    "[CV 4/5; 117/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 4/5; 117/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100;, score=-14.607 total time=   4.0s\n",
    "[CV 5/5; 117/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 5/5; 117/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100;, score=-13.817 total time=   4.5s\n",
    "[CV 1/5; 118/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 1/5; 118/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50;, score=-36.265 total time=   1.4s\n",
    "[CV 2/5; 118/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 2/5; 118/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50;, score=-37.045 total time=   1.1s\n",
    "[CV 3/5; 118/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 3/5; 118/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50;, score=-42.823 total time=   1.4s\n",
    "[CV 4/5; 118/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 4/5; 118/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50;, score=-40.879 total time=   1.3s\n",
    "[CV 5/5; 118/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 5/5; 118/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50;, score=-38.838 total time=   1.3s\n",
    "[CV 1/5; 119/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 1/5; 119/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75;, score=-21.600 total time=   2.6s\n",
    "[CV 2/5; 119/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 2/5; 119/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75;, score=-22.124 total time=   2.3s\n",
    "[CV 3/5; 119/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 3/5; 119/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75;, score=-25.725 total time=   3.0s\n",
    "[CV 4/5; 119/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 4/5; 119/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75;, score=-24.529 total time=   2.1s\n",
    "[CV 5/5; 119/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 5/5; 119/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75;, score=-23.267 total time=   2.0s\n",
    "[CV 1/5; 120/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 1/5; 120/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100;, score=-12.753 total time=   3.3s\n",
    "[CV 2/5; 120/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 2/5; 120/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100;, score=-13.086 total time=   3.3s\n",
    "[CV 3/5; 120/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 3/5; 120/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100;, score=-15.339 total time=   3.9s\n",
    "[CV 4/5; 120/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 4/5; 120/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100;, score=-14.607 total time=   3.4s\n",
    "[CV 5/5; 120/216] START booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 5/5; 120/216] END booster=dart, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100;, score=-13.817 total time=   3.4s\n",
    "[CV 1/5; 121/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 1/5; 121/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50;, score=0.843 total time=   1.0s\n",
    "[CV 2/5; 121/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 2/5; 121/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50;, score=0.838 total time=   1.1s\n",
    "[CV 3/5; 121/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 3/5; 121/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50;, score=0.837 total time=   1.0s\n",
    "[CV 4/5; 121/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 4/5; 121/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50;, score=0.833 total time=   1.0s\n",
    "[CV 5/5; 121/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[CV 5/5; 121/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50;, score=0.842 total time=   1.2s\n",
    "[CV 1/5; 122/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 1/5; 122/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75;, score=0.866 total time=   2.6s\n",
    "[CV 2/5; 122/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 2/5; 122/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75;, score=0.855 total time=   2.0s\n",
    "[CV 3/5; 122/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 3/5; 122/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75;, score=0.869 total time=   2.0s\n",
    "[CV 4/5; 122/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 4/5; 122/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75;, score=0.857 total time=   2.0s\n",
    "[CV 5/5; 122/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[CV 5/5; 122/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75;, score=0.868 total time=   2.0s\n",
    "[CV 1/5; 123/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 1/5; 123/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100;, score=0.879 total time=   3.3s\n",
    "[CV 2/5; 123/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 2/5; 123/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100;, score=0.869 total time=   3.9s\n",
    "[CV 3/5; 123/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 3/5; 123/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100;, score=0.883 total time=   4.0s\n",
    "[CV 4/5; 123/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 4/5; 123/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100;, score=0.872 total time=   4.2s\n",
    "[CV 5/5; 123/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[CV 5/5; 123/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100;, score=0.882 total time=   3.3s\n",
    "[CV 1/5; 124/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 1/5; 124/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50;, score=0.875 total time=   1.4s\n",
    "[CV 2/5; 124/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 2/5; 124/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50;, score=0.872 total time=   1.7s\n",
    "[CV 3/5; 124/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 3/5; 124/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50;, score=0.879 total time=   1.4s\n",
    "[CV 4/5; 124/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 4/5; 124/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50;, score=0.877 total time=   1.6s\n",
    "[CV 5/5; 124/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[CV 5/5; 124/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50;, score=0.875 total time=   1.6s\n",
    "[CV 1/5; 125/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 1/5; 125/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75;, score=0.895 total time=   2.8s\n",
    "[CV 2/5; 125/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 2/5; 125/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75;, score=0.888 total time=   2.7s\n",
    "[CV 3/5; 125/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 3/5; 125/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75;, score=0.902 total time=   3.6s\n",
    "[CV 4/5; 125/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 4/5; 125/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75;, score=0.898 total time=   3.7s\n",
    "[CV 5/5; 125/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[CV 5/5; 125/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75;, score=0.898 total time=   3.0s\n",
    "[CV 1/5; 126/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 1/5; 126/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100;, score=0.907 total time=   4.8s\n",
    "[CV 2/5; 126/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 2/5; 126/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100;, score=0.898 total time=   5.0s\n",
    "[CV 3/5; 126/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 3/5; 126/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100;, score=0.910 total time=   5.1s\n",
    "[CV 4/5; 126/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 4/5; 126/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100;, score=0.906 total time=   6.0s\n",
    "[CV 5/5; 126/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[CV 5/5; 126/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100;, score=0.904 total time=   6.1s\n",
    "[CV 1/5; 127/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 1/5; 127/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50;, score=0.889 total time=   2.3s\n",
    "[CV 2/5; 127/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 2/5; 127/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50;, score=0.889 total time=   2.1s\n",
    "[CV 3/5; 127/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 3/5; 127/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50;, score=0.882 total time=   2.2s\n",
    "[CV 4/5; 127/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 4/5; 127/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50;, score=0.890 total time=   1.8s\n",
    "[CV 5/5; 127/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[CV 5/5; 127/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50;, score=0.891 total time=   1.7s\n",
    "[CV 1/5; 128/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 1/5; 128/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75;, score=0.904 total time=   3.0s\n",
    "[CV 2/5; 128/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 2/5; 128/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75;, score=0.903 total time=   3.6s\n",
    "[CV 3/5; 128/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 3/5; 128/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75;, score=0.904 total time=   2.9s\n",
    "[CV 4/5; 128/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 4/5; 128/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75;, score=0.908 total time=   3.0s\n",
    "[CV 5/5; 128/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[CV 5/5; 128/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75;, score=0.909 total time=   3.0s\n",
    "[CV 1/5; 129/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 1/5; 129/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100;, score=0.910 total time=   5.2s\n",
    "[CV 2/5; 129/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 2/5; 129/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100;, score=0.909 total time=   4.7s\n",
    "[CV 3/5; 129/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 3/5; 129/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100;, score=0.911 total time=   4.6s\n",
    "[CV 4/5; 129/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 4/5; 129/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100;, score=0.914 total time=   4.8s\n",
    "[CV 5/5; 129/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[CV 5/5; 129/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100;, score=0.914 total time=   4.9s\n",
    "[CV 1/5; 130/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 1/5; 130/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50;, score=0.896 total time=   1.8s\n",
    "[CV 2/5; 130/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 2/5; 130/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50;, score=0.894 total time=   1.8s\n",
    "[CV 3/5; 130/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 3/5; 130/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50;, score=0.889 total time=   1.9s\n",
    "[CV 4/5; 130/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 4/5; 130/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50;, score=0.895 total time=   2.1s\n",
    "[CV 5/5; 130/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[CV 5/5; 130/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50;, score=0.896 total time=   1.9s\n",
    "[CV 1/5; 131/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 1/5; 131/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75;, score=0.909 total time=   4.4s\n",
    "[CV 2/5; 131/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 2/5; 131/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75;, score=0.906 total time=   3.9s\n",
    "[CV 3/5; 131/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 3/5; 131/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75;, score=0.908 total time=   3.5s\n",
    "[CV 4/5; 131/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 4/5; 131/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75;, score=0.912 total time=   3.4s\n",
    "[CV 5/5; 131/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[CV 5/5; 131/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75;, score=0.912 total time=   4.3s\n",
    "[CV 1/5; 132/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 1/5; 132/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100;, score=0.912 total time=   5.3s\n",
    "[CV 2/5; 132/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 2/5; 132/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100;, score=0.909 total time=   4.6s\n",
    "[CV 3/5; 132/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 3/5; 132/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100;, score=0.912 total time=   5.1s\n",
    "[CV 4/5; 132/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 4/5; 132/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100;, score=0.915 total time=   4.5s\n",
    "[CV 5/5; 132/216] START booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[CV 5/5; 132/216] END booster=dart, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100;, score=0.915 total time=   4.6s\n",
    "[CV 1/5; 133/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 1/5; 133/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50;, score=0.844 total time=   0.9s\n",
    "[CV 2/5; 133/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 2/5; 133/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50;, score=0.838 total time=   0.9s\n",
    "[CV 3/5; 133/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 3/5; 133/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50;, score=0.837 total time=   0.9s\n",
    "[CV 4/5; 133/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 4/5; 133/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50;, score=0.833 total time=   1.1s\n",
    "[CV 5/5; 133/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[CV 5/5; 133/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50;, score=0.842 total time=   1.1s\n",
    "[CV 1/5; 134/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 1/5; 134/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75;, score=0.865 total time=   1.7s\n",
    "[CV 2/5; 134/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 2/5; 134/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75;, score=0.854 total time=   1.7s\n",
    "[CV 3/5; 134/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 3/5; 134/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75;, score=0.868 total time=   1.7s\n",
    "[CV 4/5; 134/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 4/5; 134/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75;, score=0.858 total time=   1.8s\n",
    "[CV 5/5; 134/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[CV 5/5; 134/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75;, score=0.868 total time=   1.7s\n",
    "[CV 1/5; 135/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 1/5; 135/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100;, score=0.879 total time=   2.8s\n",
    "[CV 2/5; 135/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 2/5; 135/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100;, score=0.867 total time=   3.7s\n",
    "[CV 3/5; 135/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 3/5; 135/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100;, score=0.884 total time=   2.9s\n",
    "[CV 4/5; 135/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 4/5; 135/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100;, score=0.871 total time=   2.8s\n",
    "[CV 5/5; 135/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[CV 5/5; 135/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100;, score=0.880 total time=   2.8s\n",
    "[CV 1/5; 136/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 1/5; 136/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50;, score=0.878 total time=   1.1s\n",
    "[CV 2/5; 136/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 2/5; 136/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50;, score=0.874 total time=   1.1s\n",
    "[CV 3/5; 136/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 3/5; 136/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50;, score=0.876 total time=   1.1s\n",
    "[CV 4/5; 136/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 4/5; 136/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50;, score=0.876 total time=   1.2s\n",
    "[CV 5/5; 136/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[CV 5/5; 136/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50;, score=0.877 total time=   1.6s\n",
    "[CV 1/5; 137/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 1/5; 137/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75;, score=0.897 total time=   2.3s\n",
    "[CV 2/5; 137/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 2/5; 137/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75;, score=0.890 total time=   2.1s\n",
    "[CV 3/5; 137/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 3/5; 137/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75;, score=0.901 total time=   2.2s\n",
    "[CV 4/5; 137/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 4/5; 137/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75;, score=0.897 total time=   2.1s\n",
    "[CV 5/5; 137/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[CV 5/5; 137/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75;, score=0.898 total time=   2.2s\n",
    "[CV 1/5; 138/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 1/5; 138/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100;, score=0.905 total time=   3.4s\n",
    "[CV 2/5; 138/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 2/5; 138/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100;, score=0.899 total time=   3.8s\n",
    "[CV 3/5; 138/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 3/5; 138/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100;, score=0.910 total time=   3.4s\n",
    "[CV 4/5; 138/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 4/5; 138/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100;, score=0.904 total time=   3.3s\n",
    "[CV 5/5; 138/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[CV 5/5; 138/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100;, score=0.907 total time=   3.4s\n",
    "[CV 1/5; 139/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 1/5; 139/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50;, score=0.889 total time=   1.4s\n",
    "[CV 2/5; 139/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 2/5; 139/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50;, score=0.886 total time=   1.9s\n",
    "[CV 3/5; 139/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 3/5; 139/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50;, score=0.892 total time=   1.4s\n",
    "[CV 4/5; 139/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 4/5; 139/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50;, score=0.892 total time=   1.3s\n",
    "[CV 5/5; 139/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[CV 5/5; 139/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50;, score=0.893 total time=   1.4s\n",
    "[CV 1/5; 140/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 1/5; 140/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75;, score=0.903 total time=   2.5s\n",
    "[CV 2/5; 140/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 2/5; 140/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75;, score=0.902 total time=   2.5s\n",
    "[CV 3/5; 140/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 3/5; 140/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75;, score=0.910 total time=   2.6s\n",
    "[CV 4/5; 140/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 4/5; 140/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75;, score=0.908 total time=   2.9s\n",
    "[CV 5/5; 140/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[CV 5/5; 140/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75;, score=0.911 total time=   2.5s\n",
    "[CV 1/5; 141/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 1/5; 141/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100;, score=0.908 total time=   3.9s\n",
    "[CV 2/5; 141/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 2/5; 141/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100;, score=0.908 total time=   3.9s\n",
    "[CV 3/5; 141/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 3/5; 141/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100;, score=0.916 total time=   4.1s\n",
    "[CV 4/5; 141/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 4/5; 141/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100;, score=0.912 total time=   4.3s\n",
    "[CV 5/5; 141/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[CV 5/5; 141/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100;, score=0.917 total time=   3.9s\n",
    "[CV 1/5; 142/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 1/5; 142/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50;, score=0.894 total time=   1.6s\n",
    "[CV 2/5; 142/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 2/5; 142/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50;, score=0.892 total time=   1.6s\n",
    "[CV 3/5; 142/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 3/5; 142/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50;, score=0.889 total time=   1.6s\n",
    "[CV 4/5; 142/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 4/5; 142/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50;, score=0.891 total time=   1.6s\n",
    "[CV 5/5; 142/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[CV 5/5; 142/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50;, score=0.896 total time=   2.0s\n",
    "[CV 1/5; 143/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 1/5; 143/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75;, score=0.909 total time=   3.0s\n",
    "[CV 2/5; 143/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 2/5; 143/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75;, score=0.904 total time=   2.9s\n",
    "[CV 3/5; 143/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 3/5; 143/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75;, score=0.906 total time=   3.0s\n",
    "[CV 4/5; 143/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 4/5; 143/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75;, score=0.907 total time=   3.0s\n",
    "[CV 5/5; 143/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[CV 5/5; 143/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75;, score=0.913 total time=   3.3s\n",
    "[CV 1/5; 144/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 1/5; 144/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100;, score=0.911 total time=   4.6s\n",
    "[CV 2/5; 144/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 2/5; 144/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100;, score=0.907 total time=   4.9s\n",
    "[CV 3/5; 144/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 3/5; 144/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100;, score=0.910 total time=   4.6s\n",
    "[CV 4/5; 144/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 4/5; 144/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100;, score=0.910 total time=   5.0s\n",
    "[CV 5/5; 144/216] START booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[CV 5/5; 144/216] END booster=dart, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100;, score=0.916 total time=   4.6s\n",
    "[CV 1/5; 145/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[20:16:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 145/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50;, score=-91.000 total time=   0.1s\n",
    "[CV 2/5; 145/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[20:16:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 145/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50;, score=-92.408 total time=   0.0s\n",
    "[CV 3/5; 145/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[20:16:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 145/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50;, score=-105.856 total time=   0.0s\n",
    "[CV 4/5; 145/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[20:16:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 145/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50;, score=-101.283 total time=   0.0s\n",
    "[CV 5/5; 145/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[20:16:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 145/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=50;, score=-96.467 total time=   0.0s\n",
    "[CV 1/5; 146/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[20:16:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 146/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75;, score=-86.521 total time=   0.1s\n",
    "[CV 2/5; 146/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[20:16:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 146/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75;, score=-87.806 total time=   0.1s\n",
    "[CV 3/5; 146/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[20:16:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 146/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75;, score=-100.575 total time=   0.1s\n",
    "[CV 4/5; 146/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[20:16:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 146/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75;, score=-96.237 total time=   0.1s\n",
    "[CV 5/5; 146/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[20:16:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 146/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=75;, score=-91.667 total time=   0.1s\n",
    "[CV 1/5; 147/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[20:16:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 147/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100;, score=-82.273 total time=   0.1s\n",
    "[CV 2/5; 147/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[20:16:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 147/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100;, score=-83.444 total time=   0.2s\n",
    "[CV 3/5; 147/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[20:16:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 147/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100;, score=-95.572 total time=   0.1s\n",
    "[CV 4/5; 147/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[20:16:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 147/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100;, score=-91.457 total time=   0.1s\n",
    "[CV 5/5; 147/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[20:16:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 147/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=4, n_estimators=100;, score=-87.121 total time=   0.2s\n",
    "[CV 1/5; 148/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[20:16:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 148/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50;, score=-91.000 total time=   0.0s\n",
    "[CV 2/5; 148/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[20:16:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 148/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50;, score=-92.408 total time=   0.0s\n",
    "[CV 3/5; 148/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[20:16:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 148/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50;, score=-105.856 total time=   0.0s\n",
    "[CV 4/5; 148/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[20:16:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 148/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50;, score=-101.283 total time=   0.0s\n",
    "[CV 5/5; 148/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[20:16:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 148/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=50;, score=-96.467 total time=   0.0s\n",
    "[CV 1/5; 149/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[20:16:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 149/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75;, score=-86.521 total time=   0.1s\n",
    "[CV 2/5; 149/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[20:16:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 149/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75;, score=-87.806 total time=   0.1s\n",
    "[CV 3/5; 149/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[20:16:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 149/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75;, score=-100.575 total time=   0.1s\n",
    "[CV 4/5; 149/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[20:16:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 149/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75;, score=-96.237 total time=   0.1s\n",
    "[CV 5/5; 149/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[20:16:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 149/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=75;, score=-91.667 total time=   0.1s\n",
    "[CV 1/5; 150/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[20:16:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 150/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100;, score=-82.273 total time=   0.1s\n",
    "[CV 2/5; 150/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[20:16:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 150/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100;, score=-83.444 total time=   0.2s\n",
    "[CV 3/5; 150/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[20:16:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 150/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100;, score=-95.572 total time=   0.1s\n",
    "[CV 4/5; 150/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[20:16:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 150/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100;, score=-91.457 total time=   0.1s\n",
    "[CV 5/5; 150/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[20:16:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 150/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=6, n_estimators=100;, score=-87.121 total time=   0.1s\n",
    "[CV 1/5; 151/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[20:16:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 151/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50;, score=-91.000 total time=   0.0s\n",
    "[CV 2/5; 151/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[20:16:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 151/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50;, score=-92.408 total time=   0.1s\n",
    "[CV 3/5; 151/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[20:16:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 151/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50;, score=-105.856 total time=   0.0s\n",
    "[CV 4/5; 151/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[20:16:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 151/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50;, score=-101.283 total time=   0.0s\n",
    "[CV 5/5; 151/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[20:16:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 151/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=50;, score=-96.467 total time=   0.0s\n",
    "[CV 1/5; 152/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[20:16:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 152/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75;, score=-86.521 total time=   0.1s\n",
    "[CV 2/5; 152/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[20:16:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 152/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75;, score=-87.806 total time=   0.1s\n",
    "[CV 3/5; 152/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[20:16:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 152/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75;, score=-100.575 total time=   0.1s\n",
    "[CV 4/5; 152/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[20:16:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 152/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75;, score=-96.237 total time=   0.1s\n",
    "[CV 5/5; 152/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[20:16:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 152/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=75;, score=-91.667 total time=   0.1s\n",
    "[CV 1/5; 153/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[20:16:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 153/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100;, score=-82.273 total time=   0.1s\n",
    "[CV 2/5; 153/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[20:16:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 153/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100;, score=-83.444 total time=   0.1s\n",
    "[CV 3/5; 153/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[20:16:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 153/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100;, score=-95.572 total time=   0.1s\n",
    "[CV 4/5; 153/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[20:16:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 153/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100;, score=-91.457 total time=   0.1s\n",
    "[CV 5/5; 153/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[20:16:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 153/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=8, n_estimators=100;, score=-87.121 total time=   0.1s\n",
    "[CV 1/5; 154/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[20:16:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 154/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50;, score=-91.000 total time=   0.0s\n",
    "[CV 2/5; 154/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[20:16:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 154/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50;, score=-92.408 total time=   0.0s\n",
    "[CV 3/5; 154/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[20:16:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 154/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50;, score=-105.856 total time=   0.0s\n",
    "[CV 4/5; 154/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[20:16:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 154/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50;, score=-101.283 total time=   0.0s\n",
    "[CV 5/5; 154/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[20:16:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 154/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=50;, score=-96.467 total time=   0.0s\n",
    "[CV 1/5; 155/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[20:16:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 155/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75;, score=-86.521 total time=   0.1s\n",
    "[CV 2/5; 155/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[20:16:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 155/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75;, score=-87.806 total time=   0.1s\n",
    "[CV 3/5; 155/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[20:16:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 155/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75;, score=-100.575 total time=   0.1s\n",
    "[CV 4/5; 155/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[20:16:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 155/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75;, score=-96.237 total time=   0.1s\n",
    "[CV 5/5; 155/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[20:16:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 155/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=75;, score=-91.667 total time=   0.1s\n",
    "[CV 1/5; 156/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[20:16:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 156/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100;, score=-82.273 total time=   0.1s\n",
    "[CV 2/5; 156/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[20:16:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 156/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100;, score=-83.444 total time=   0.1s\n",
    "[CV 3/5; 156/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[20:16:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 156/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100;, score=-95.572 total time=   0.1s\n",
    "[CV 4/5; 156/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[20:16:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 156/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100;, score=-91.457 total time=   0.1s\n",
    "[CV 5/5; 156/216] START booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[20:16:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 156/216] END booster=gblinear, eta=0.001, gamma=0.0, max_depth=10, n_estimators=100;, score=-87.121 total time=   0.1s\n",
    "[CV 1/5; 157/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[20:16:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 157/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50;, score=-91.000 total time=   0.0s\n",
    "[CV 2/5; 157/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[20:16:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 157/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50;, score=-92.408 total time=   0.0s\n",
    "[CV 3/5; 157/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[20:16:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 157/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50;, score=-105.856 total time=   0.1s\n",
    "[CV 4/5; 157/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[20:16:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 157/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50;, score=-101.283 total time=   0.0s\n",
    "[CV 5/5; 157/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[20:16:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 157/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=50;, score=-96.467 total time=   0.0s\n",
    "[CV 1/5; 158/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[20:16:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 158/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75;, score=-86.521 total time=   0.1s\n",
    "[CV 2/5; 158/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[20:16:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 158/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75;, score=-87.806 total time=   0.1s\n",
    "[CV 3/5; 158/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[20:16:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 158/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75;, score=-100.575 total time=   0.1s\n",
    "[CV 4/5; 158/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[20:16:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 158/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75;, score=-96.237 total time=   0.1s\n",
    "[CV 5/5; 158/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[20:16:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 158/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=75;, score=-91.667 total time=   0.1s\n",
    "[CV 1/5; 159/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[20:16:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 159/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100;, score=-82.273 total time=   0.1s\n",
    "[CV 2/5; 159/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[20:16:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 159/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100;, score=-83.444 total time=   0.1s\n",
    "[CV 3/5; 159/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[20:16:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 159/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100;, score=-95.572 total time=   0.1s\n",
    "[CV 4/5; 159/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[20:16:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 159/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100;, score=-91.457 total time=   0.1s\n",
    "[CV 5/5; 159/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[20:16:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 159/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=4, n_estimators=100;, score=-87.121 total time=   0.1s\n",
    "[CV 1/5; 160/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[20:16:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 160/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50;, score=-91.000 total time=   0.0s\n",
    "[CV 2/5; 160/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[20:16:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 160/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50;, score=-92.408 total time=   0.0s\n",
    "[CV 3/5; 160/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[20:16:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 160/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50;, score=-105.856 total time=   0.0s\n",
    "[CV 4/5; 160/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[20:16:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 160/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50;, score=-101.283 total time=   0.0s\n",
    "[CV 5/5; 160/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[20:16:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 160/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=50;, score=-96.467 total time=   0.0s\n",
    "[CV 1/5; 161/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[20:16:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 161/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75;, score=-86.521 total time=   0.1s\n",
    "[CV 2/5; 161/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[20:16:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 161/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75;, score=-87.806 total time=   0.1s\n",
    "[CV 3/5; 161/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[20:16:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 161/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75;, score=-100.575 total time=   0.1s\n",
    "[CV 4/5; 161/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[20:16:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 161/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75;, score=-96.237 total time=   0.1s\n",
    "[CV 5/5; 161/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[20:16:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 161/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=75;, score=-91.667 total time=   0.1s\n",
    "[CV 1/5; 162/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[20:16:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 162/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100;, score=-82.273 total time=   0.2s\n",
    "[CV 2/5; 162/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[20:16:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 162/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100;, score=-83.444 total time=   0.1s\n",
    "[CV 3/5; 162/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[20:16:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 162/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100;, score=-95.572 total time=   0.1s\n",
    "[CV 4/5; 162/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[20:16:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 162/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100;, score=-91.457 total time=   0.1s\n",
    "[CV 5/5; 162/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[20:16:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 162/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=6, n_estimators=100;, score=-87.121 total time=   0.1s\n",
    "[CV 1/5; 163/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[20:16:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 163/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50;, score=-91.000 total time=   0.0s\n",
    "[CV 2/5; 163/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[20:16:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 163/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50;, score=-92.408 total time=   0.0s\n",
    "[CV 3/5; 163/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[20:16:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 163/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50;, score=-105.856 total time=   0.0s\n",
    "[CV 4/5; 163/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[20:16:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 163/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50;, score=-101.283 total time=   0.0s\n",
    "[CV 5/5; 163/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[20:16:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 163/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=50;, score=-96.467 total time=   0.1s\n",
    "[CV 1/5; 164/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[20:16:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 164/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75;, score=-86.521 total time=   0.1s\n",
    "[CV 2/5; 164/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[20:16:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 164/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75;, score=-87.806 total time=   0.1s\n",
    "[CV 3/5; 164/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[20:16:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 164/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75;, score=-100.575 total time=   0.1s\n",
    "[CV 4/5; 164/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[20:16:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 164/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75;, score=-96.237 total time=   0.1s\n",
    "[CV 5/5; 164/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[20:16:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 164/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=75;, score=-91.667 total time=   0.1s\n",
    "[CV 1/5; 165/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[20:16:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 165/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100;, score=-82.273 total time=   0.1s\n",
    "[CV 2/5; 165/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[20:16:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 165/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100;, score=-83.444 total time=   0.1s\n",
    "[CV 3/5; 165/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[20:16:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 165/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100;, score=-95.572 total time=   0.1s\n",
    "[CV 4/5; 165/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[20:16:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 165/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100;, score=-91.457 total time=   0.1s\n",
    "[CV 5/5; 165/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[20:16:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 165/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=8, n_estimators=100;, score=-87.121 total time=   0.1s\n",
    "[CV 1/5; 166/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[20:16:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 166/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50;, score=-91.000 total time=   0.0s\n",
    "[CV 2/5; 166/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[20:16:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 166/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50;, score=-92.408 total time=   0.0s\n",
    "[CV 3/5; 166/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[20:16:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 166/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50;, score=-105.856 total time=   0.0s\n",
    "[CV 4/5; 166/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[20:16:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 166/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50;, score=-101.283 total time=   0.0s\n",
    "[CV 5/5; 166/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[20:16:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 166/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=50;, score=-96.467 total time=   0.0s\n",
    "[CV 1/5; 167/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[20:16:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 167/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75;, score=-86.521 total time=   0.1s\n",
    "[CV 2/5; 167/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[20:16:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 167/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75;, score=-87.806 total time=   0.1s\n",
    "[CV 3/5; 167/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[20:16:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 167/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75;, score=-100.575 total time=   0.1s\n",
    "[CV 4/5; 167/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[20:16:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 167/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75;, score=-96.237 total time=   0.1s\n",
    "[CV 5/5; 167/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[20:16:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 167/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=75;, score=-91.667 total time=   0.1s\n",
    "[CV 1/5; 168/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[20:16:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 168/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100;, score=-82.273 total time=   0.2s\n",
    "[CV 2/5; 168/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[20:16:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 168/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100;, score=-83.444 total time=   0.1s\n",
    "[CV 3/5; 168/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[20:16:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 168/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100;, score=-95.572 total time=   0.1s\n",
    "[CV 4/5; 168/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[20:16:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 168/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100;, score=-91.457 total time=   0.1s\n",
    "[CV 5/5; 168/216] START booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[20:16:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 168/216] END booster=gblinear, eta=0.001, gamma=0.1, max_depth=10, n_estimators=100;, score=-87.121 total time=   0.2s\n",
    "[CV 1/5; 169/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[20:16:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 169/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50;, score=-36.583 total time=   0.0s\n",
    "[CV 2/5; 169/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[20:16:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 169/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50;, score=-36.832 total time=   0.0s\n",
    "[CV 3/5; 169/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[20:16:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 169/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50;, score=-42.387 total time=   0.1s\n",
    "[CV 4/5; 169/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[20:16:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 169/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50;, score=-40.571 total time=   0.0s\n",
    "[CV 5/5; 169/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[20:16:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 169/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=50;, score=-38.664 total time=   0.0s\n",
    "[CV 1/5; 170/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[20:16:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 170/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75;, score=-21.881 total time=   0.1s\n",
    "[CV 2/5; 170/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[20:16:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 170/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75;, score=-21.966 total time=   0.1s\n",
    "[CV 3/5; 170/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[20:16:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 170/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75;, score=-25.496 total time=   0.1s\n",
    "[CV 4/5; 170/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[20:16:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 170/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75;, score=-24.373 total time=   0.2s\n",
    "[CV 5/5; 170/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[20:16:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 170/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=75;, score=-23.218 total time=   0.1s\n",
    "[CV 1/5; 171/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[20:16:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 171/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100;, score=-12.950 total time=   0.1s\n",
    "[CV 2/5; 171/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[20:16:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 171/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100;, score=-12.971 total time=   0.2s\n",
    "[CV 3/5; 171/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[20:16:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 171/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100;, score=-15.249 total time=   0.1s\n",
    "[CV 4/5; 171/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[20:16:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 171/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100;, score=-14.543 total time=   0.1s\n",
    "[CV 5/5; 171/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[20:16:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 171/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=4, n_estimators=100;, score=-13.843 total time=   0.1s\n",
    "[CV 1/5; 172/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[20:16:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 172/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50;, score=-36.583 total time=   0.0s\n",
    "[CV 2/5; 172/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[20:16:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 172/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50;, score=-36.832 total time=   0.0s\n",
    "[CV 3/5; 172/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[20:16:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 172/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50;, score=-42.387 total time=   0.0s\n",
    "[CV 4/5; 172/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[20:16:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 172/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50;, score=-40.572 total time=   0.0s\n",
    "[CV 5/5; 172/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[20:16:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 172/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=50;, score=-38.664 total time=   0.1s\n",
    "[CV 1/5; 173/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[20:16:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 173/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75;, score=-21.881 total time=   0.1s\n",
    "[CV 2/5; 173/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[20:16:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 173/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75;, score=-21.966 total time=   0.1s\n",
    "[CV 3/5; 173/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[20:16:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 173/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75;, score=-25.496 total time=   0.1s\n",
    "[CV 4/5; 173/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[20:16:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 173/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75;, score=-24.374 total time=   0.1s\n",
    "[CV 5/5; 173/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[20:16:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 173/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=75;, score=-23.218 total time=   0.1s\n",
    "[CV 1/5; 174/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[20:16:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 174/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100;, score=-12.950 total time=   0.1s\n",
    "[CV 2/5; 174/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[20:16:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 174/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100;, score=-12.971 total time=   0.1s\n",
    "[CV 3/5; 174/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[20:16:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 174/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100;, score=-15.249 total time=   0.1s\n",
    "[CV 4/5; 174/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[20:16:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 174/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100;, score=-14.543 total time=   0.1s\n",
    "[CV 5/5; 174/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[20:16:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 174/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=6, n_estimators=100;, score=-13.843 total time=   0.1s\n",
    "[CV 1/5; 175/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[20:16:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 175/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50;, score=-36.583 total time=   0.0s\n",
    "[CV 2/5; 175/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[20:16:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 175/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50;, score=-36.832 total time=   0.0s\n",
    "[CV 3/5; 175/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[20:16:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 175/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50;, score=-42.387 total time=   0.0s\n",
    "[CV 4/5; 175/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[20:16:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 175/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50;, score=-40.572 total time=   0.0s\n",
    "[CV 5/5; 175/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[20:16:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 175/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=50;, score=-38.664 total time=   0.0s\n",
    "[CV 1/5; 176/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[20:16:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 176/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75;, score=-21.881 total time=   0.1s\n",
    "[CV 2/5; 176/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[20:16:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 176/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75;, score=-21.966 total time=   0.1s\n",
    "[CV 3/5; 176/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[20:16:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 176/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75;, score=-25.496 total time=   0.1s\n",
    "[CV 4/5; 176/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[20:16:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 176/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75;, score=-24.374 total time=   0.1s\n",
    "[CV 5/5; 176/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[20:16:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 176/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=75;, score=-23.218 total time=   0.1s\n",
    "[CV 1/5; 177/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[20:16:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 177/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100;, score=-12.950 total time=   0.1s\n",
    "[CV 2/5; 177/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[20:16:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 177/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100;, score=-12.971 total time=   0.1s\n",
    "[CV 3/5; 177/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[20:16:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 177/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100;, score=-15.249 total time=   0.2s\n",
    "[CV 4/5; 177/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[20:16:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 177/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100;, score=-14.543 total time=   0.1s\n",
    "[CV 5/5; 177/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[20:16:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 177/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=8, n_estimators=100;, score=-13.843 total time=   0.1s\n",
    "[CV 1/5; 178/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[20:16:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 178/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50;, score=-36.583 total time=   0.1s\n",
    "[CV 2/5; 178/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[20:16:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 178/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50;, score=-36.832 total time=   0.0s\n",
    "[CV 3/5; 178/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[20:16:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 178/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50;, score=-42.387 total time=   0.0s\n",
    "[CV 4/5; 178/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[20:16:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 178/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50;, score=-40.572 total time=   0.0s\n",
    "[CV 5/5; 178/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[20:16:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 178/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=50;, score=-38.664 total time=   0.0s\n",
    "[CV 1/5; 179/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[20:16:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 179/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75;, score=-21.881 total time=   0.1s\n",
    "[CV 2/5; 179/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[20:16:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 179/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75;, score=-21.966 total time=   0.1s\n",
    "[CV 3/5; 179/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[20:16:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 179/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75;, score=-25.496 total time=   0.1s\n",
    "[CV 4/5; 179/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[20:16:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 179/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75;, score=-24.374 total time=   0.1s\n",
    "[CV 5/5; 179/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[20:16:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 179/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=75;, score=-23.218 total time=   0.1s\n",
    "[CV 1/5; 180/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[20:16:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 180/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100;, score=-12.950 total time=   0.1s\n",
    "[CV 2/5; 180/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[20:16:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 180/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100;, score=-12.971 total time=   0.1s\n",
    "[CV 3/5; 180/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[20:16:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 180/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100;, score=-15.249 total time=   0.1s\n",
    "[CV 4/5; 180/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[20:16:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 180/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100;, score=-14.543 total time=   0.1s\n",
    "[CV 5/5; 180/216] START booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[20:16:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 180/216] END booster=gblinear, eta=0.01, gamma=0.0, max_depth=10, n_estimators=100;, score=-13.843 total time=   0.2s\n",
    "[CV 1/5; 181/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[20:16:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 181/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50;, score=-36.583 total time=   0.0s\n",
    "[CV 2/5; 181/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[20:16:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 181/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50;, score=-36.832 total time=   0.0s\n",
    "[CV 3/5; 181/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[20:16:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 181/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50;, score=-42.387 total time=   0.0s\n",
    "[CV 4/5; 181/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[20:16:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 181/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50;, score=-40.572 total time=   0.0s\n",
    "[CV 5/5; 181/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[20:16:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 181/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=50;, score=-38.664 total time=   0.0s\n",
    "[CV 1/5; 182/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[20:16:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 182/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75;, score=-21.881 total time=   0.1s\n",
    "[CV 2/5; 182/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[20:16:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 182/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75;, score=-21.966 total time=   0.1s\n",
    "[CV 3/5; 182/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[20:16:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 182/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75;, score=-25.496 total time=   0.1s\n",
    "[CV 4/5; 182/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[20:16:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 182/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75;, score=-24.373 total time=   0.1s\n",
    "[CV 5/5; 182/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[20:16:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 182/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=75;, score=-23.218 total time=   0.1s\n",
    "[CV 1/5; 183/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[20:16:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 183/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100;, score=-12.950 total time=   0.1s\n",
    "[CV 2/5; 183/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[20:16:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 183/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100;, score=-12.971 total time=   0.1s\n",
    "[CV 3/5; 183/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[20:16:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 183/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100;, score=-15.249 total time=   0.2s\n",
    "[CV 4/5; 183/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[20:16:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 183/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100;, score=-14.543 total time=   0.1s\n",
    "[CV 5/5; 183/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[20:16:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 183/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=4, n_estimators=100;, score=-13.843 total time=   0.1s\n",
    "[CV 1/5; 184/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[20:16:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 184/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50;, score=-36.583 total time=   0.0s\n",
    "[CV 2/5; 184/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[20:16:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 184/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50;, score=-36.832 total time=   0.0s\n",
    "[CV 3/5; 184/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[20:16:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 184/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50;, score=-42.387 total time=   0.1s\n",
    "[CV 4/5; 184/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[20:16:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 184/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50;, score=-40.572 total time=   0.0s\n",
    "[CV 5/5; 184/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[20:16:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 184/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=50;, score=-38.664 total time=   0.0s\n",
    "[CV 1/5; 185/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[20:16:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 185/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75;, score=-21.881 total time=   0.1s\n",
    "[CV 2/5; 185/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[20:16:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 185/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75;, score=-21.966 total time=   0.1s\n",
    "[CV 3/5; 185/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[20:16:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 185/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75;, score=-25.496 total time=   0.1s\n",
    "[CV 4/5; 185/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[20:16:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 185/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75;, score=-24.374 total time=   0.1s\n",
    "[CV 5/5; 185/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[20:16:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 185/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=75;, score=-23.218 total time=   0.1s\n",
    "[CV 1/5; 186/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[20:16:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 186/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100;, score=-12.950 total time=   0.1s\n",
    "[CV 2/5; 186/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[20:16:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 186/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100;, score=-12.971 total time=   0.1s\n",
    "[CV 3/5; 186/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[20:16:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 186/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100;, score=-15.249 total time=   0.1s\n",
    "[CV 4/5; 186/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[20:16:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 186/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100;, score=-14.542 total time=   0.1s\n",
    "[CV 5/5; 186/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[20:16:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 186/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=6, n_estimators=100;, score=-13.843 total time=   0.1s\n",
    "[CV 1/5; 187/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[20:16:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 187/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50;, score=-36.583 total time=   0.0s\n",
    "[CV 2/5; 187/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[20:16:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 187/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50;, score=-36.832 total time=   0.0s\n",
    "[CV 3/5; 187/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[20:16:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 187/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50;, score=-42.387 total time=   0.0s\n",
    "[CV 4/5; 187/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[20:16:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 187/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50;, score=-40.571 total time=   0.0s\n",
    "[CV 5/5; 187/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[20:16:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 187/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=50;, score=-38.664 total time=   0.0s\n",
    "[CV 1/5; 188/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[20:16:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 188/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75;, score=-21.881 total time=   0.1s\n",
    "[CV 2/5; 188/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[20:16:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 188/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75;, score=-21.966 total time=   0.1s\n",
    "[CV 3/5; 188/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[20:16:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 188/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75;, score=-25.496 total time=   0.1s\n",
    "[CV 4/5; 188/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[20:16:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 188/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75;, score=-24.374 total time=   0.1s\n",
    "[CV 5/5; 188/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[20:16:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 188/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=75;, score=-23.218 total time=   0.1s\n",
    "[CV 1/5; 189/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[20:16:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 189/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100;, score=-12.950 total time=   0.1s\n",
    "[CV 2/5; 189/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[20:16:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 189/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100;, score=-12.971 total time=   0.1s\n",
    "[CV 3/5; 189/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[20:16:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 189/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100;, score=-15.249 total time=   0.1s\n",
    "[CV 4/5; 189/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[20:16:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 189/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100;, score=-14.543 total time=   0.2s\n",
    "[CV 5/5; 189/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[20:17:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 189/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=8, n_estimators=100;, score=-13.843 total time=   0.1s\n",
    "[CV 1/5; 190/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[20:17:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 190/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50;, score=-36.582 total time=   0.0s\n",
    "[CV 2/5; 190/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[20:17:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 190/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50;, score=-36.832 total time=   0.0s\n",
    "[CV 3/5; 190/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[20:17:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 190/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50;, score=-42.387 total time=   0.0s\n",
    "[CV 4/5; 190/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[20:17:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 190/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50;, score=-40.572 total time=   0.0s\n",
    "[CV 5/5; 190/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[20:17:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 190/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=50;, score=-38.664 total time=   0.0s\n",
    "[CV 1/5; 191/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[20:17:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 191/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75;, score=-21.881 total time=   0.1s\n",
    "[CV 2/5; 191/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[20:17:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 191/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75;, score=-21.966 total time=   0.1s\n",
    "[CV 3/5; 191/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[20:17:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 191/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75;, score=-25.496 total time=   0.1s\n",
    "[CV 4/5; 191/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[20:17:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 191/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75;, score=-24.373 total time=   0.1s\n",
    "[CV 5/5; 191/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[20:17:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 191/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=75;, score=-23.218 total time=   0.1s\n",
    "[CV 1/5; 192/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[20:17:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 192/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100;, score=-12.950 total time=   0.2s\n",
    "[CV 2/5; 192/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[20:17:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 192/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100;, score=-12.971 total time=   0.1s\n",
    "[CV 3/5; 192/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[20:17:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 192/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100;, score=-15.249 total time=   0.1s\n",
    "[CV 4/5; 192/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[20:17:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 192/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100;, score=-14.543 total time=   0.1s\n",
    "[CV 5/5; 192/216] START booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[20:17:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 192/216] END booster=gblinear, eta=0.01, gamma=0.1, max_depth=10, n_estimators=100;, score=-13.843 total time=   0.1s\n",
    "[CV 1/5; 193/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[20:17:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 193/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50;, score=0.763 total time=   0.0s\n",
    "[CV 2/5; 193/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[20:17:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 193/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50;, score=0.763 total time=   0.0s\n",
    "[CV 3/5; 193/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[20:17:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 193/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50;, score=0.743 total time=   0.1s\n",
    "[CV 4/5; 193/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[20:17:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 193/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50;, score=0.756 total time=   0.0s\n",
    "[CV 5/5; 193/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50\n",
    "[20:17:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 193/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=50;, score=0.768 total time=   0.1s\n",
    "[CV 1/5; 194/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[20:17:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 194/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75;, score=0.765 total time=   0.1s\n",
    "[CV 2/5; 194/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[20:17:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 194/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75;, score=0.766 total time=   0.1s\n",
    "[CV 3/5; 194/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[20:17:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 194/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75;, score=0.755 total time=   0.1s\n",
    "[CV 4/5; 194/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[20:17:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 194/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75;, score=0.762 total time=   0.1s\n",
    "[CV 5/5; 194/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75\n",
    "[20:17:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 194/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=75;, score=0.779 total time=   0.1s\n",
    "[CV 1/5; 195/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[20:17:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 195/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100;, score=0.766 total time=   0.2s\n",
    "[CV 2/5; 195/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[20:17:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 195/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100;, score=0.767 total time=   0.1s\n",
    "[CV 3/5; 195/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[20:17:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 195/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100;, score=0.758 total time=   0.1s\n",
    "[CV 4/5; 195/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[20:17:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 195/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100;, score=0.764 total time=   0.1s\n",
    "[CV 5/5; 195/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100\n",
    "[20:17:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 195/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=4, n_estimators=100;, score=0.781 total time=   0.1s\n",
    "[CV 1/5; 196/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[20:17:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 196/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50;, score=0.763 total time=   0.0s\n",
    "[CV 2/5; 196/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[20:17:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 196/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50;, score=0.763 total time=   0.0s\n",
    "[CV 3/5; 196/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[20:17:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 196/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50;, score=0.743 total time=   0.0s\n",
    "[CV 4/5; 196/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[20:17:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 196/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50;, score=0.756 total time=   0.0s\n",
    "[CV 5/5; 196/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50\n",
    "[20:17:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 196/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=50;, score=0.768 total time=   0.0s\n",
    "[CV 1/5; 197/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[20:17:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 197/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75;, score=0.765 total time=   0.1s\n",
    "[CV 2/5; 197/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[20:17:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 197/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75;, score=0.766 total time=   0.1s\n",
    "[CV 3/5; 197/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[20:17:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 197/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75;, score=0.755 total time=   0.1s\n",
    "[CV 4/5; 197/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[20:17:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 197/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75;, score=0.762 total time=   0.1s\n",
    "[CV 5/5; 197/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75\n",
    "[20:17:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 197/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=75;, score=0.779 total time=   0.1s\n",
    "[CV 1/5; 198/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[20:17:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 198/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100;, score=0.766 total time=   0.1s\n",
    "[CV 2/5; 198/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[20:17:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 198/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100;, score=0.767 total time=   0.1s\n",
    "[CV 3/5; 198/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[20:17:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 198/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100;, score=0.758 total time=   0.2s\n",
    "[CV 4/5; 198/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[20:17:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 198/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100;, score=0.764 total time=   0.1s\n",
    "[CV 5/5; 198/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100\n",
    "[20:17:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 198/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=6, n_estimators=100;, score=0.781 total time=   0.1s\n",
    "[CV 1/5; 199/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[20:17:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 199/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50;, score=0.763 total time=   0.0s\n",
    "[CV 2/5; 199/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[20:17:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 199/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50;, score=0.763 total time=   0.0s\n",
    "[CV 3/5; 199/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[20:17:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 199/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50;, score=0.743 total time=   0.0s\n",
    "[CV 4/5; 199/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[20:17:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 199/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50;, score=0.756 total time=   0.0s\n",
    "[CV 5/5; 199/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50\n",
    "[20:17:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 199/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=50;, score=0.768 total time=   0.0s\n",
    "[CV 1/5; 200/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[20:17:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 200/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75;, score=0.765 total time=   0.1s\n",
    "[CV 2/5; 200/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[20:17:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 200/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75;, score=0.766 total time=   0.1s\n",
    "[CV 3/5; 200/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[20:17:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 200/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75;, score=0.755 total time=   0.1s\n",
    "[CV 4/5; 200/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[20:17:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 200/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75;, score=0.762 total time=   0.1s\n",
    "[CV 5/5; 200/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75\n",
    "[20:17:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 200/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=75;, score=0.778 total time=   0.1s\n",
    "[CV 1/5; 201/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[20:17:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 201/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100;, score=0.766 total time=   0.1s\n",
    "[CV 2/5; 201/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[20:17:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 201/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100;, score=0.767 total time=   0.1s\n",
    "[CV 3/5; 201/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[20:17:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 201/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100;, score=0.758 total time=   0.1s\n",
    "[CV 4/5; 201/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[20:17:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 201/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100;, score=0.764 total time=   0.1s\n",
    "[CV 5/5; 201/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100\n",
    "[20:17:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 201/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=8, n_estimators=100;, score=0.781 total time=   0.1s\n",
    "[CV 1/5; 202/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[20:17:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 202/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50;, score=0.763 total time=   0.0s\n",
    "[CV 2/5; 202/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[20:17:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 202/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50;, score=0.763 total time=   0.0s\n",
    "[CV 3/5; 202/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[20:17:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 202/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50;, score=0.743 total time=   0.0s\n",
    "[CV 4/5; 202/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[20:17:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 202/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50;, score=0.756 total time=   0.1s\n",
    "[CV 5/5; 202/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50\n",
    "[20:17:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 202/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=50;, score=0.768 total time=   0.1s\n",
    "[CV 1/5; 203/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[20:17:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 203/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75;, score=0.765 total time=   0.1s\n",
    "[CV 2/5; 203/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[20:17:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 203/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75;, score=0.766 total time=   0.1s\n",
    "[CV 3/5; 203/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[20:17:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 203/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75;, score=0.755 total time=   0.1s\n",
    "[CV 4/5; 203/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[20:17:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 203/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75;, score=0.762 total time=   0.1s\n",
    "[CV 5/5; 203/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75\n",
    "[20:17:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 203/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=75;, score=0.779 total time=   0.1s\n",
    "[CV 1/5; 204/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[20:17:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 204/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100;, score=0.766 total time=   0.1s\n",
    "[CV 2/5; 204/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[20:17:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 204/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100;, score=0.767 total time=   0.1s\n",
    "[CV 3/5; 204/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[20:17:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 204/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100;, score=0.758 total time=   0.1s\n",
    "[CV 4/5; 204/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[20:17:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 204/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100;, score=0.764 total time=   0.1s\n",
    "[CV 5/5; 204/216] START booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100\n",
    "[20:17:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 204/216] END booster=gblinear, eta=0.1, gamma=0.0, max_depth=10, n_estimators=100;, score=0.781 total time=   0.1s\n",
    "[CV 1/5; 205/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[20:17:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 205/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50;, score=0.763 total time=   0.1s\n",
    "[CV 2/5; 205/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[20:17:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 205/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50;, score=0.763 total time=   0.0s\n",
    "[CV 3/5; 205/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[20:17:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 205/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50;, score=0.743 total time=   0.0s\n",
    "[CV 4/5; 205/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[20:17:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 205/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50;, score=0.756 total time=   0.0s\n",
    "[CV 5/5; 205/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50\n",
    "[20:17:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 205/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=50;, score=0.768 total time=   0.0s\n",
    "[CV 1/5; 206/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[20:17:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 206/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75;, score=0.765 total time=   0.1s\n",
    "[CV 2/5; 206/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[20:17:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 206/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75;, score=0.766 total time=   0.1s\n",
    "[CV 3/5; 206/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[20:17:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 206/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75;, score=0.755 total time=   0.1s\n",
    "[CV 4/5; 206/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[20:17:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 206/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75;, score=0.762 total time=   0.1s\n",
    "[CV 5/5; 206/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75\n",
    "[20:17:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 206/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=75;, score=0.778 total time=   0.1s\n",
    "[CV 1/5; 207/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[20:17:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 207/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100;, score=0.766 total time=   0.1s\n",
    "[CV 2/5; 207/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[20:17:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 207/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100;, score=0.767 total time=   0.2s\n",
    "[CV 3/5; 207/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[20:17:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 207/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100;, score=0.758 total time=   0.1s\n",
    "[CV 4/5; 207/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[20:17:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 207/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100;, score=0.764 total time=   0.1s\n",
    "[CV 5/5; 207/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100\n",
    "[20:17:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 207/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=4, n_estimators=100;, score=0.781 total time=   0.1s\n",
    "[CV 1/5; 208/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[20:17:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 208/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50;, score=0.763 total time=   0.0s\n",
    "[CV 2/5; 208/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[20:17:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 208/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50;, score=0.763 total time=   0.0s\n",
    "[CV 3/5; 208/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[20:17:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 208/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50;, score=0.742 total time=   0.0s\n",
    "[CV 4/5; 208/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[20:17:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 208/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50;, score=0.756 total time=   0.0s\n",
    "[CV 5/5; 208/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50\n",
    "[20:17:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 208/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=50;, score=0.768 total time=   0.0s\n",
    "[CV 1/5; 209/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[20:17:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 209/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75;, score=0.765 total time=   0.1s\n",
    "[CV 2/5; 209/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[20:17:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 209/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75;, score=0.765 total time=   0.2s\n",
    "[CV 3/5; 209/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[20:17:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 209/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75;, score=0.754 total time=   0.1s\n",
    "[CV 4/5; 209/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[20:17:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 209/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75;, score=0.763 total time=   0.1s\n",
    "[CV 5/5; 209/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75\n",
    "[20:17:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 209/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=75;, score=0.779 total time=   0.1s\n",
    "[CV 1/5; 210/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[20:17:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 210/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100;, score=0.766 total time=   0.1s\n",
    "[CV 2/5; 210/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[20:17:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 210/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100;, score=0.767 total time=   0.1s\n",
    "[CV 3/5; 210/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[20:17:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 210/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100;, score=0.758 total time=   0.1s\n",
    "[CV 4/5; 210/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[20:17:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 210/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100;, score=0.764 total time=   0.1s\n",
    "[CV 5/5; 210/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100\n",
    "[20:17:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 210/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=6, n_estimators=100;, score=0.781 total time=   0.2s\n",
    "[CV 1/5; 211/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[20:17:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 211/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50;, score=0.763 total time=   0.0s\n",
    "[CV 2/5; 211/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[20:17:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 211/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50;, score=0.763 total time=   0.0s\n",
    "[CV 3/5; 211/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[20:17:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 211/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50;, score=0.743 total time=   0.0s\n",
    "[CV 4/5; 211/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[20:17:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 211/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50;, score=0.756 total time=   0.0s\n",
    "[CV 5/5; 211/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50\n",
    "[20:17:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 211/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=50;, score=0.768 total time=   0.0s\n",
    "[CV 1/5; 212/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[20:17:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 212/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75;, score=0.765 total time=   0.1s\n",
    "[CV 2/5; 212/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[20:17:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 212/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75;, score=0.766 total time=   0.1s\n",
    "[CV 3/5; 212/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[20:17:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 212/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75;, score=0.755 total time=   0.1s\n",
    "[CV 4/5; 212/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[20:17:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 212/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75;, score=0.763 total time=   0.1s\n",
    "[CV 5/5; 212/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75\n",
    "[20:17:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 212/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=75;, score=0.778 total time=   0.1s\n",
    "[CV 1/5; 213/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[20:17:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 213/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100;, score=0.766 total time=   0.1s\n",
    "[CV 2/5; 213/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[20:17:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 213/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100;, score=0.767 total time=   0.1s\n",
    "[CV 3/5; 213/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[20:17:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 213/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100;, score=0.758 total time=   0.1s\n",
    "[CV 4/5; 213/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[20:17:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 213/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100;, score=0.764 total time=   0.1s\n",
    "[CV 5/5; 213/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100\n",
    "[20:17:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 213/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=8, n_estimators=100;, score=0.781 total time=   0.1s\n",
    "[CV 1/5; 214/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[20:17:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 214/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50;, score=0.763 total time=   0.0s\n",
    "[CV 2/5; 214/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[20:17:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 214/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50;, score=0.763 total time=   0.0s\n",
    "[CV 3/5; 214/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[20:17:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 214/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50;, score=0.743 total time=   0.0s\n",
    "[CV 4/5; 214/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[20:17:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 214/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50;, score=0.756 total time=   0.0s\n",
    "[CV 5/5; 214/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50\n",
    "[20:17:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 214/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=50;, score=0.768 total time=   0.0s\n",
    "[CV 1/5; 215/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[20:17:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 215/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75;, score=0.765 total time=   0.1s\n",
    "[CV 2/5; 215/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[20:17:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 215/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75;, score=0.766 total time=   0.1s\n",
    "[CV 3/5; 215/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[20:17:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 215/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75;, score=0.755 total time=   0.1s\n",
    "[CV 4/5; 215/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[20:17:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 215/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75;, score=0.763 total time=   0.1s\n",
    "[CV 5/5; 215/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75\n",
    "[20:17:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 215/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=75;, score=0.778 total time=   0.1s\n",
    "[CV 1/5; 216/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[20:17:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 1/5; 216/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100;, score=0.766 total time=   0.2s\n",
    "[CV 2/5; 216/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[20:17:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 2/5; 216/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100;, score=0.767 total time=   0.1s\n",
    "[CV 3/5; 216/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[20:17:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 3/5; 216/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100;, score=0.758 total time=   0.1s\n",
    "[CV 4/5; 216/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[20:17:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 4/5; 216/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100;, score=0.764 total time=   0.1s\n",
    "[CV 5/5; 216/216] START booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100\n",
    "[20:17:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
    "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
    "\n",
    "  This could be a false alarm, with some parameters getting used by language bindings but\n",
    "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
    "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
    "\n",
    "\n",
    "[CV 5/5; 216/216] END booster=gblinear, eta=0.1, gamma=0.1, max_depth=10, n_estimators=100;, score=0.781 total time=   0.1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9154ee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearchCV(estimator=XGBRegressor(base_score=None, booster=None,\n",
    "                                    colsample_bylevel=None,\n",
    "                                    colsample_bynode=None,\n",
    "                                    colsample_bytree=None,\n",
    "                                    enable_categorical=False, gamma=None,\n",
    "                                    gpu_id=None, importance_type=None,\n",
    "                                    interaction_constraints=None,\n",
    "                                    learning_rate=None, max_delta_step=None,\n",
    "                                    max_depth=None, min_child_weight=None,\n",
    "                                    missing=nan, monotone_constraints=None,\n",
    "                                    n_esti...bs=None,\n",
    "                                    num_parallel_tree=None, predictor=None,\n",
    "                                    random_state=None, reg_alpha=None,\n",
    "                                    reg_lambda=None, scale_pos_weight=None,\n",
    "                                    subsample=None, tree_method=None,\n",
    "                                    validate_parameters=None, verbosity=None),\n",
    "             param_grid={'booster': ['gbtree', 'dart', 'gblinear'],\n",
    "                         'eta': [0.001, 0.01, 0.1], 'gamma': array([0. , 0.1]),\n",
    "                         'max_depth': [4, 6, 8, 10],\n",
    "                         'n_estimators': [50, 75, 100]},\n",
    "             verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad4b8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470788b5",
   "metadata": {},
   "source": [
    "{'booster': 'dart',\n",
    " 'eta': 0.1,\n",
    " 'gamma': 0.0,\n",
    " 'max_depth': 10,\n",
    " 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d580127f",
   "metadata": {},
   "source": [
    "## Final Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24889920",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_mod =  XGBRegressor(n_estimators=100 , booster= 'dart', eta= 0.1, max_depth= 10, gamma= 0.0 )\n",
    "Final_mod.fit(X_train,Y_train)\n",
    "y_pred=Final_mod.predict(X_test)\n",
    "print('\\n')                                        \n",
    "print('\\033[1m'+' Error in Final Model :' +'\\033[0m')\n",
    "print('Mean absolute error :', mean_absolute_error(Y_test,y_pred))\n",
    "print('Mean squared error :', mean_squared_error(Y_test,y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(Y_test,y_pred)))\n",
    "print('\\n')\n",
    "print('\\033[1m'+' R2 Score of Final Model :'+'\\033[0m')\n",
    "print(r2_score(Y_test,y_pred)) \n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a408a0ba",
   "metadata": {},
   "source": [
    "Error in Final Model :\n",
    "Mean absolute error : 0.6051252994605963\n",
    "Mean squared error : 0.6360048707273599\n",
    "Root Mean Squared Error: 0.7974991352517944\n",
    "\n",
    "\n",
    " R2 Score of Final Model :\n",
    "0.9278043669026034"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f938c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,9))\n",
    "y_pred=Final_mod.predict(X_test)\n",
    "sns.swarmplot(Y_test.round(2), y_pred)\n",
    "print('\\033[1m'+' True Values Vs Predicted Value plot :' +'\\033[0m')\n",
    "plt.xlabel('True Values' , fontsize=15)\n",
    "plt.ylabel('Predictions', fontsize=15)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ef7ce9",
   "metadata": {},
   "source": [
    "## Final Regression Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662c1239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(Final_mod,'Next_Tmax_Forecast_Final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a15c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "['Next_Tmax_Forecast_Final.pkl']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5352fb4a",
   "metadata": {},
   "source": [
    "### Prediction According Final Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0efe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the saved model\n",
    "Model = joblib.load(\"Next_Tmax_Forecast_Final.pkl\")\n",
    "\n",
    "# prediction  DataFrame\n",
    "actual = np.array(Y_test)\n",
    "predicted = np.array(Model.predict(X_test))\n",
    "df_Predicted = pd.DataFrame({\"Actual Values\":actual,\"Predicted Values\":predicted},index= range(len(actual)))\n",
    "df_Predicted "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6297676",
   "metadata": {},
   "source": [
    "\tActual Values\tPredicted Values\n",
    "0\t32.0\t31.505756\n",
    "1\t30.1\t30.239626\n",
    "2\t27.8\t28.283251\n",
    "3\t27.6\t27.053226\n",
    "4\t29.8\t30.012983\n",
    "...\t...\t...\n",
    "2219\t36.7\t36.390533\n",
    "2220\t35.4\t34.874588\n",
    "2221\t28.4\t27.233887\n",
    "2222\t24.0\t23.988373\n",
    "2223\t32.6\t32.138439\n",
    "2224 rows × 2 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32528889",
   "metadata": {},
   "source": [
    "### Machine Learning Model Building For Next_Tmin\n",
    "Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c79994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data in target and dependent feature\n",
    "X = df.drop(['Next_Tmin'], axis =1)\n",
    "Y = df['Next_Tmin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c2905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler= StandardScaler()\n",
    "X_scale = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24282042",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scale, Y, random_state=42, test_size=.33)\n",
    "print('Training feature matrix size:',X_train.shape)\n",
    "print('Training target vector size:',Y_train.shape)\n",
    "print('Test feature matrix size:',X_test.shape)\n",
    "print('Test target vector size:',Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c590c781",
   "metadata": {},
   "source": [
    "Training feature matrix size: (4515, 28)\n",
    "Training target vector size: (4515,)\n",
    "Test feature matrix size: (2224, 28)\n",
    "Test target vector size: (2224,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf4f303",
   "metadata": {},
   "source": [
    "### Finding best Random state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cd84eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "maxR2_score=0\n",
    "maxRS=0\n",
    "for i in range(1,500):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_scale, Y, random_state=i, test_size=.33)\n",
    "    lin_reg=LinearRegression()\n",
    "    lin_reg.fit(X_train,Y_train)\n",
    "    y_pred=lin_reg.predict(X_test)\n",
    "    R2=r2_score(Y_test,y_pred)\n",
    "    if R2>maxR2_score:\n",
    "        maxR2_score=R2\n",
    "        maxRS=i\n",
    "print('Best R2 Score is', maxR2_score ,'on Random_state', maxRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4366ba79",
   "metadata": {},
   "source": [
    "Best R2 Score is 0.8512433756353852 on Random_state 43"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9265de",
   "metadata": {},
   "source": [
    "### Linear Regression Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa683d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scale, Y, random_state=43, test_size=.33)\n",
    "lin_reg=LinearRegression()\n",
    "lin_reg.fit(X_train,Y_train)\n",
    "lin_reg.score(X_train,Y_train)\n",
    "y_pred=lin_reg.predict(X_test)\n",
    "print('\\033[1m'+'Predicted Wins:'+'\\033[0m\\n',y_pred)\n",
    "print('\\n')\n",
    "print('\\033[1m'+'Actual Wins:'+'\\033[0m\\n',Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95070abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predicted Wins:\n",
    " [23.43531019 24.60008496 23.13605479 ... 22.51619756 26.46938431\n",
    " 25.3600731 ]\n",
    "\n",
    "\n",
    "Actual Wins:\n",
    " 5006    23.0\n",
    "947     25.6\n",
    "3726    23.0\n",
    "715     22.1\n",
    "4242    24.0\n",
    "        ... \n",
    "4097    24.6\n",
    "3186    17.1\n",
    "6641    23.1\n",
    "3854    26.2\n",
    "1190    25.7\n",
    "Name: Next_Tmin, Length: 2224, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cd08a1",
   "metadata": {},
   "source": [
    "### Linear Regression Evaluation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78cbb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\033[1m'+' Error :'+'\\033[0m')\n",
    "print('Mean absolute error :', mean_absolute_error(Y_test,y_pred))\n",
    "print('Mean squared error :', mean_squared_error(Y_test,y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(Y_test,y_pred)))\n",
    "print('\\n')\n",
    "from sklearn.metrics import r2_score\n",
    "print('\\033[1m'+' R2 Score :'+'\\033[0m')\n",
    "print(r2_score(Y_test,y_pred,multioutput='variance_weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2175f9d",
   "metadata": {},
   "source": [
    "Error :\n",
    "Mean absolute error : 0.7363156513377952\n",
    "Mean squared error : 0.8575992359395737\n",
    "Root Mean Squared Error: 0.9260665396933276\n",
    "\n",
    "\n",
    " R2 Score :\n",
    "0.8512433756353851"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc80c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "score = cross_val_score(lin_reg, X_scale, Y, cv =3)\n",
    "print('\\033[1m'+'Cross Validation Score :',lin_reg,\":\"+'\\033[0m\\n')\n",
    "print(\"Mean CV Score :\",score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986f7c44",
   "metadata": {},
   "source": [
    "Cross Validation Score : LinearRegression() :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9eb4bb",
   "metadata": {},
   "source": [
    "Mean CV Score : 0.7878211798605088"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fed2da4",
   "metadata": {},
   "source": [
    "## Applying other ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed8e8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "dtc = DecisionTreeRegressor()\n",
    "XT = ExtraTreesRegressor()\n",
    "BR = BaggingRegressor()\n",
    "adb=AdaBoostRegressor()\n",
    "gradb=GradientBoostingRegressor()\n",
    "xgb=XGBRegressor()\n",
    "model = [rf,XT,dtc,adb,gradb,xgb]\n",
    "\n",
    "for m in model:\n",
    "    m.fit(X_train,Y_train)\n",
    "    m.score(X_train,Y_train)\n",
    "    y_pred = m.predict(X_test)\n",
    "    print('\\n')                                        \n",
    "    print('\\033[1m'+' Error of ', m, ':' +'\\033[0m')\n",
    "    print('Mean absolute error :', mean_absolute_error(Y_test,y_pred))\n",
    "    print('Mean squared error :', mean_squared_error(Y_test,y_pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(mean_squared_error(Y_test,y_pred)))\n",
    "    print('\\n')\n",
    "\n",
    "    print('\\033[1m'+' R2 Score :'+'\\033[0m')\n",
    "    print(r2_score(Y_test,y_pred)) \n",
    "    print('==============================================================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21450f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "Error of  RandomForestRegressor() :\n",
    "Mean absolute error : 0.5565948741007193\n",
    "Mean squared error : 0.5299370220323741\n",
    "Root Mean Squared Error: 0.727967734197316\n",
    "\n",
    "\n",
    " R2 Score :\n",
    "0.9080786931473818\n",
    "==============================================================================================================\n",
    "\n",
    "\n",
    " Error of  ExtraTreesRegressor() :\n",
    "Mean absolute error : 0.5193354316546763\n",
    "Mean squared error : 0.4699468812949641\n",
    "Root Mean Squared Error: 0.6855267181481435\n",
    "\n",
    "\n",
    " R2 Score :\n",
    "0.9184844053463652\n",
    "==============================================================================================================\n",
    "\n",
    "\n",
    " Error of  DecisionTreeRegressor() :\n",
    "Mean absolute error : 0.8201888489208633\n",
    "Mean squared error : 1.2120188848920863\n",
    "Root Mean Squared Error: 1.1009172924848107\n",
    "\n",
    "\n",
    " R2 Score :\n",
    "0.7897667926613976\n",
    "==============================================================================================================\n",
    "\n",
    "\n",
    " Error of  AdaBoostRegressor() :\n",
    "Mean absolute error : 0.8311494194213946\n",
    "Mean squared error : 1.0517152390689015\n",
    "Root Mean Squared Error: 1.0255316860384673\n",
    "\n",
    "\n",
    " R2 Score :\n",
    "0.8175725884534988\n",
    "==============================================================================================================\n",
    "\n",
    "\n",
    " Error of  GradientBoostingRegressor() :\n",
    "Mean absolute error : 0.6050456962809305\n",
    "Mean squared error : 0.5922615885291472\n",
    "Root Mean Squared Error: 0.769585335443151\n",
    "\n",
    "\n",
    " R2 Score :\n",
    "0.8972680583677338\n",
    "==============================================================================================================\n",
    "\n",
    "\n",
    " Error of  XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
    "             gamma=0, gpu_id=-1, importance_type=None,\n",
    "             interaction_constraints='', learning_rate=0.300000012,\n",
    "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
    "             monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
    "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
    "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
    "             validate_parameters=1, verbosity=None) :\n",
    "Mean absolute error : 0.4783428277043131\n",
    "Mean squared error : 0.39889603006697266\n",
    "Root Mean Squared Error: 0.6315821641457053\n",
    "\n",
    "\n",
    " R2 Score :\n",
    "0.9308086756395038\n",
    "=============================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e110f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "model = [rf,XT,dtc,adb,gradb,xgb]\n",
    "\n",
    "for m in model:\n",
    "    score = cross_val_score(m, X_scale, Y, cv =5)\n",
    "    print('\\n')\n",
    "    print('\\033[1m'+'Cross Validation Score :',m,\":\"+'\\033[0m\\n')\n",
    "    print(\"Mean CV Score :\",score.mean())\n",
    "    print('==============================================================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ffed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cross Validation Score : RandomForestRegressor() :\n",
    "\n",
    "Mean CV Score : 0.7920875722550096\n",
    "==============================================================================================================\n",
    "\n",
    "\n",
    "Cross Validation Score : ExtraTreesRegressor() :\n",
    "\n",
    "Mean CV Score : 0.79733099675272\n",
    "==============================================================================================================\n",
    "\n",
    "\n",
    "Cross Validation Score : DecisionTreeRegressor() :\n",
    "\n",
    "Mean CV Score : 0.5985069006355117\n",
    "==============================================================================================================\n",
    "\n",
    "\n",
    "Cross Validation Score : AdaBoostRegressor() :\n",
    "\n",
    "Mean CV Score : 0.7478128088797378\n",
    "==============================================================================================================\n",
    "\n",
    "\n",
    "Cross Validation Score : GradientBoostingRegressor() :\n",
    "\n",
    "Mean CV Score : 0.8030956035893579\n",
    "==============================================================================================================\n",
    "\n",
    "\n",
    "Cross Validation Score : XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
    "             gamma=0, gpu_id=-1, importance_type=None,\n",
    "             interaction_constraints='', learning_rate=0.300000012,\n",
    "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
    "             monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
    "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
    "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
    "             validate_parameters=1, verbosity=None) :\n",
    "\n",
    "Mean CV Score : 0.7737767894470141\n",
    "=============================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16c3ba0",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning : GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab25934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f3793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = {'n_estimators':[50,75,100],'gamma':np.arange(0,0.2,0.1),\n",
    "              'booster' : ['gbtree','dart','gblinear'], 'max_depth':[4,6,8,10],\n",
    "              'eta' : [0.001, 0.01, 0.1] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4f95cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCV = GridSearchCV(XGBRegressor(),parameter,verbose =10)\n",
    "GCV.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89b3b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b2cd43",
   "metadata": {},
   "source": [
    "### Final Regression Model For Next_Tmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e700ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_mod =  XGBRegressor(n_estimators=100 , booster= 'dart', eta= 0.1, max_depth= 8, gamma= 0.0 )\n",
    "Final_mod.fit(X_train,Y_train)\n",
    "y_pred=Final_mod.predict(X_test)\n",
    "print('\\n')                                        \n",
    "print('\\033[1m'+' Error in Final Model :' +'\\033[0m')\n",
    "print('Mean absolute error :', mean_absolute_error(Y_test,y_pred))\n",
    "print('Mean squared error :', mean_squared_error(Y_test,y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(Y_test,y_pred)))\n",
    "print('\\n')\n",
    "print('\\033[1m'+' R2 Score of Final Model :'+'\\033[0m')\n",
    "print(r2_score(Y_test,y_pred)) \n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f52cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "y_pred=Final_mod.predict(X_test)\n",
    "sns.swarmplot(Y_test.round(2), y_pred)\n",
    "print('\\033[1m'+' True Values Vs Predicted Value plot :' +'\\033[0m')\n",
    "plt.xlabel('True Values' , fontsize=15)\n",
    "plt.ylabel('Predictions', fontsize=15)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695ff9a6",
   "metadata": {},
   "source": [
    "## Saving Final Regression Model For Next_Tmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aa8000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(Final_mod,'Next_Tmin_Forecast_Final.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6471c6c",
   "metadata": {},
   "source": [
    "## Prediction According Final Regression Model For Next_Tmin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc96fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the saved model\n",
    "Model = joblib.load(\"Next_Tmin_Forecast_Final.pkl\")\n",
    "\n",
    "# prediction  DataFrame\n",
    "actual = np.array(Y_test)\n",
    "predicted = np.array(Model.predict(X_test))\n",
    "df_Predicted = pd.DataFrame({\"Actual Values\":actual,\"Predicted Values\":predicted},index= range(len(actual)))\n",
    "df_Predicted "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
